{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import helper\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.unicode'] = True\n",
    "\n",
    "# For the notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biwi = pd.read_csv('./data/train/biwi/biwi_hotel.txt', header = None,\n",
    "                 names = ['frameNb','id', 'x','y'],delimiter=' ')\n",
    "id_unique = np.unique(np.array(biwi['id']))\n",
    "\n",
    "init = np.zeros(len(biwi)) \n",
    "biwi['Speed'] = init\n",
    "biwi['Angle'] = init\n",
    "biwi['Vx'] = init\n",
    "biwi['Vy'] = init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None ## Disable StettingWithCopy warning\n",
    "c = 0\n",
    "for i in id_unique:\n",
    "    a = biwi[biwi['id']==i]\n",
    "    ind = a.index\n",
    "    a.index = range(len(a))\n",
    "    dist = a['x'].iloc\n",
    "    dist1 = a.loc[0:len(a)-2,'x':'y']\n",
    "    dist1.index=range(len(dist1))\n",
    "    dist2 = a.loc[1:,'x':'y']\n",
    "    dist2.index=range(len(dist2))\n",
    "    dist = dist2-dist1\n",
    "    b = len(dist)\n",
    "    if c < b:\n",
    "        vector_speed = np.zeros((len(id_unique),b,2))\n",
    "        c=b\n",
    "b = 0\n",
    "for i in id_unique:\n",
    "    a = biwi[biwi['id']==i]\n",
    "    ind = a.index\n",
    "    a.index = range(len(a))\n",
    "    dist = a['x'].iloc\n",
    "    dist1 = a.loc[0:len(a)-2,'x':'y']\n",
    "    dist1.index=range(len(dist1))\n",
    "    dist2 = a.loc[1:,'x':'y']\n",
    "    dist2.index=range(len(dist2))\n",
    "    dist = dist2-dist1\n",
    "    speed = np.array(np.sqrt(dist['x']**2+dist['y']**2)/0.4)\n",
    "    biwi.loc[ind[1:],'Speed'] = speed\n",
    "    angle=np.zeros(len(dist)-1)\n",
    "    vx=np.zeros(len(dist))\n",
    "    vy=np.zeros(len(dist))\n",
    "    for j in range(len(dist)-1):\n",
    "        if norm(dist.loc[j,:])==0 or norm(dist.loc[j+1,:])==0:\n",
    "            angle[j]=0\n",
    "        elif np.cross(dist.loc[j,:],dist.loc[j+1,:])/(norm(dist.loc[j,:])*norm(dist.loc[j+1,:]))>1:\n",
    "            angle[j]=np.arcsin(1)\n",
    "        else:\n",
    "            angle[j]=np.arcsin(np.cross(dist.loc[j,:],dist.loc[j+1,:])/(norm(dist.loc[j,:])*norm(dist.loc[j+1,:])))\n",
    "    \n",
    "    for j in range(len(dist)):\n",
    "        if j == 0:\n",
    "            vx[j] = 0\n",
    "            vy[j] = speed[j]\n",
    "            vector_speed[b][j][0]=vx[j]\n",
    "            vector_speed[b][j][1]=vy[j]\n",
    "        else:\n",
    "            vx[j] = speed[j]*np.sin(sum(angle[:j]))\n",
    "            vy[j] = speed[j]*np.cos(sum(angle[:j]))\n",
    "            vector_speed[b][j][0]=vx[j]\n",
    "            vector_speed[b][j][1]=vy[j]\n",
    "    \n",
    "    biwi.loc[ind[2:],'Angle'] = angle\n",
    "    biwi.loc[ind[1:],'Vx'] = vx\n",
    "    biwi.loc[ind[1:],'Vy'] = vy\n",
    "    b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  torch.Size([125, 1, 9, 2])\n",
      "Train labels shape:  torch.Size([125, 1, 9, 2])\n",
      "Validation data shape:  torch.Size([20, 1, 9, 2])\n",
      "Validation labels shape:  torch.Size([20, 1, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(vector_speed),9,2))\n",
    "y = np.zeros((len(vector_speed),9,2))\n",
    "for i in range(len(vector_speed)):\n",
    "    x[i][:][:] = vector_speed[i][:9][:]\n",
    "    y[i][:][:] = vector_speed[i][10:19][:]\n",
    "\n",
    "mask = list(range(len(vector_speed)-20, len(vector_speed)))\n",
    "x_val = x[mask]\n",
    "y_val = y[mask]\n",
    "mask = list(range(len(vector_speed)-20))\n",
    "x_train = x[mask]\n",
    "y_train = y[mask]\n",
    "\n",
    "x_train,y_train = torch.from_numpy(x_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "x_val,y_val = torch.from_numpy(x_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.FloatTensor)\n",
    "\n",
    "x_train = x_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "y_train = y_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "x_val = x_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "y_val = y_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "traindataset = utils.TensorDataset(x_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(x_val, y_val)\n",
    "valloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=1, n_output=None):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Define 2 or more different layers of the neural network                      #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(n_input_channels,3,5,padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
    "     \n",
    "        self.fc1 = nn.Linear(9*2 * 3, 9*2 * 1)\n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Set up the forward pass that the input data will go through.                 #\n",
    "        # A good activation function betweent the layers is a ReLu function.           #\n",
    "        #                                                                              #\n",
    "        # Note that the output of the last convolution layer should be flattened       #\n",
    "        # before being inputted to the fully connected layer. We can flatten           #\n",
    "        # Variable `x` with `x.view`.                                                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        x = x.view(-1, 9*2 * 3) # in order to reshape the tensor for as many columns we need\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/4romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20.. Loss: 0.4926.. Test accuracy: 0.5460.. 0.0250 s/batch  steps 2.0000\n",
      "Epoch: 1/20.. Loss: 0.8221.. Test accuracy: 0.5460.. 0.0010 s/batch  steps 4.0000\n",
      "Epoch: 1/20.. Loss: 0.6094.. Test accuracy: 0.5459.. 0.0011 s/batch  steps 6.0000\n",
      "Epoch: 1/20.. Loss: 0.7486.. Test accuracy: 0.5460.. 0.0007 s/batch  steps 8.0000\n",
      "Epoch: 1/20.. Loss: 0.7076.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 10.0000\n",
      "Epoch: 1/20.. Loss: 0.4807.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 12.0000\n",
      "Epoch: 1/20.. Loss: 0.5801.. Test accuracy: 0.5460.. 0.0008 s/batch  steps 14.0000\n",
      "Epoch: 1/20.. Loss: 0.2609.. Test accuracy: 0.5460.. 0.0008 s/batch  steps 16.0000\n",
      "Epoch: 1/20.. Loss: 0.2974.. Test accuracy: 0.5460.. 0.0008 s/batch  steps 18.0000\n",
      "Epoch: 1/20.. Loss: 1.2134.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 20.0000\n",
      "Epoch: 1/20.. Loss: 0.7220.. Test accuracy: 0.5460.. 0.0008 s/batch  steps 22.0000\n",
      "Epoch: 1/20.. Loss: 0.3345.. Test accuracy: 0.5459.. 0.0009 s/batch  steps 24.0000\n",
      "Epoch: 2/20.. Loss: 0.6840.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 26.0000\n",
      "Epoch: 2/20.. Loss: 0.8647.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 28.0000\n",
      "Epoch: 2/20.. Loss: 0.7034.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 30.0000\n",
      "Epoch: 2/20.. Loss: 0.7096.. Test accuracy: 0.5459.. 0.0010 s/batch  steps 32.0000\n",
      "Epoch: 2/20.. Loss: 0.4286.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 34.0000\n",
      "Epoch: 2/20.. Loss: 0.4412.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 36.0000\n",
      "Epoch: 2/20.. Loss: 0.9896.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 38.0000\n",
      "Epoch: 2/20.. Loss: 0.3454.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 40.0000\n",
      "Epoch: 2/20.. Loss: 0.4324.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 42.0000\n",
      "Epoch: 2/20.. Loss: 0.7845.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 44.0000\n",
      "Epoch: 2/20.. Loss: 0.5847.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 46.0000\n",
      "Epoch: 2/20.. Loss: 0.6244.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 48.0000\n",
      "Epoch: 2/20.. Loss: 0.8450.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 50.0000\n",
      "Epoch: 3/20.. Loss: 0.7152.. Test accuracy: 0.5459.. 0.0009 s/batch  steps 52.0000\n",
      "Epoch: 3/20.. Loss: 0.1739.. Test accuracy: 0.5459.. 0.0009 s/batch  steps 54.0000\n",
      "Epoch: 3/20.. Loss: 0.8226.. Test accuracy: 0.5458.. 0.0012 s/batch  steps 56.0000\n",
      "Epoch: 3/20.. Loss: 1.1428.. Test accuracy: 0.5459.. 0.0011 s/batch  steps 58.0000\n",
      "Epoch: 3/20.. Loss: 0.5626.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 60.0000\n",
      "Epoch: 3/20.. Loss: 0.4417.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 62.0000\n",
      "Epoch: 3/20.. Loss: 0.5041.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 64.0000\n",
      "Epoch: 3/20.. Loss: 1.2191.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 66.0000\n",
      "Epoch: 3/20.. Loss: 0.2531.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 68.0000\n",
      "Epoch: 3/20.. Loss: 0.4382.. Test accuracy: 0.5459.. 0.0010 s/batch  steps 70.0000\n",
      "Epoch: 3/20.. Loss: 0.3036.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 72.0000\n",
      "Epoch: 3/20.. Loss: 0.3189.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 74.0000\n",
      "Epoch: 4/20.. Loss: 0.5036.. Test accuracy: 0.5457.. 0.0004 s/batch  steps 76.0000\n",
      "Epoch: 4/20.. Loss: 0.3880.. Test accuracy: 0.5459.. 0.0012 s/batch  steps 78.0000\n",
      "Epoch: 4/20.. Loss: 0.3617.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 80.0000\n",
      "Epoch: 4/20.. Loss: 0.6288.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 82.0000\n",
      "Epoch: 4/20.. Loss: 0.9314.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 84.0000\n",
      "Epoch: 4/20.. Loss: 0.4435.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 86.0000\n",
      "Epoch: 4/20.. Loss: 0.4397.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 88.0000\n",
      "Epoch: 4/20.. Loss: 0.6382.. Test accuracy: 0.5459.. 0.0011 s/batch  steps 90.0000\n",
      "Epoch: 4/20.. Loss: 0.7017.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 92.0000\n",
      "Epoch: 4/20.. Loss: 0.2587.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 94.0000\n",
      "Epoch: 4/20.. Loss: 0.7003.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 96.0000\n",
      "Epoch: 4/20.. Loss: 0.8262.. Test accuracy: 0.5459.. 0.0010 s/batch  steps 98.0000\n",
      "Epoch: 4/20.. Loss: 0.7708.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 100.0000\n",
      "Epoch: 5/20.. Loss: 0.5853.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 102.0000\n",
      "Epoch: 5/20.. Loss: 0.8629.. Test accuracy: 0.5460.. 0.0009 s/batch  steps 104.0000\n",
      "Epoch: 5/20.. Loss: 0.3213.. Test accuracy: 0.5458.. 0.0012 s/batch  steps 106.0000\n",
      "Epoch: 5/20.. Loss: 0.2987.. Test accuracy: 0.5459.. 0.0010 s/batch  steps 108.0000\n",
      "Epoch: 5/20.. Loss: 0.8465.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 110.0000\n",
      "Epoch: 5/20.. Loss: 0.1209.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 112.0000\n",
      "Epoch: 5/20.. Loss: 0.6538.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 114.0000\n",
      "Epoch: 5/20.. Loss: 0.8308.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 116.0000\n",
      "Epoch: 5/20.. Loss: 0.6687.. Test accuracy: 0.5457.. 0.0006 s/batch  steps 118.0000\n",
      "Epoch: 5/20.. Loss: 0.4795.. Test accuracy: 0.5457.. 0.0007 s/batch  steps 120.0000\n",
      "Epoch: 5/20.. Loss: 0.8221.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 122.0000\n",
      "Epoch: 5/20.. Loss: 0.7058.. Test accuracy: 0.5460.. 0.0009 s/batch  steps 124.0000\n",
      "Epoch: 6/20.. Loss: 0.6458.. Test accuracy: 0.5459.. 0.0003 s/batch  steps 126.0000\n",
      "Epoch: 6/20.. Loss: 0.5195.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 128.0000\n",
      "Epoch: 6/20.. Loss: 0.6642.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 130.0000\n",
      "Epoch: 6/20.. Loss: 0.3201.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 132.0000\n",
      "Epoch: 6/20.. Loss: 0.8350.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 134.0000\n",
      "Epoch: 6/20.. Loss: 0.5297.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 136.0000\n",
      "Epoch: 6/20.. Loss: 0.1181.. Test accuracy: 0.5459.. 0.0011 s/batch  steps 138.0000\n",
      "Epoch: 6/20.. Loss: 1.1232.. Test accuracy: 0.5459.. 0.0006 s/batch  steps 140.0000\n",
      "Epoch: 6/20.. Loss: 0.5939.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 142.0000\n",
      "Epoch: 6/20.. Loss: 0.7559.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 144.0000\n",
      "Epoch: 6/20.. Loss: 0.0184.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 146.0000\n",
      "Epoch: 6/20.. Loss: 0.5769.. Test accuracy: 0.5457.. 0.0009 s/batch  steps 148.0000\n",
      "Epoch: 6/20.. Loss: 0.7922.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 150.0000\n",
      "Epoch: 7/20.. Loss: 0.9030.. Test accuracy: 0.5458.. 0.0006 s/batch  steps 152.0000\n",
      "Epoch: 7/20.. Loss: 0.1199.. Test accuracy: 0.5458.. 0.0012 s/batch  steps 154.0000\n",
      "Epoch: 7/20.. Loss: 0.4168.. Test accuracy: 0.5457.. 0.0006 s/batch  steps 156.0000\n",
      "Epoch: 7/20.. Loss: 0.5444.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 158.0000\n",
      "Epoch: 7/20.. Loss: 0.4752.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 160.0000\n",
      "Epoch: 7/20.. Loss: 0.5904.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 162.0000\n",
      "Epoch: 7/20.. Loss: 0.2989.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 164.0000\n",
      "Epoch: 7/20.. Loss: 1.0539.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 166.0000\n",
      "Epoch: 7/20.. Loss: 0.8133.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 168.0000\n",
      "Epoch: 7/20.. Loss: 0.6294.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 170.0000\n",
      "Epoch: 7/20.. Loss: 1.1622.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 172.0000\n",
      "Epoch: 7/20.. Loss: 0.7765.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 174.0000\n",
      "Epoch: 8/20.. Loss: 0.3786.. Test accuracy: 0.5457.. 0.0003 s/batch  steps 176.0000\n",
      "Epoch: 8/20.. Loss: 0.1395.. Test accuracy: 0.5457.. 0.0007 s/batch  steps 178.0000\n",
      "Epoch: 8/20.. Loss: 0.3686.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 180.0000\n",
      "Epoch: 8/20.. Loss: 0.2791.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 182.0000\n",
      "Epoch: 8/20.. Loss: 1.1144.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 184.0000\n",
      "Epoch: 8/20.. Loss: 0.6470.. Test accuracy: 0.5457.. 0.0007 s/batch  steps 186.0000\n",
      "Epoch: 8/20.. Loss: 0.7753.. Test accuracy: 0.5457.. 0.0007 s/batch  steps 188.0000\n",
      "Epoch: 8/20.. Loss: 1.0987.. Test accuracy: 0.5457.. 0.0012 s/batch  steps 190.0000\n",
      "Epoch: 8/20.. Loss: 0.0215.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 192.0000\n",
      "Epoch: 8/20.. Loss: 0.6791.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 194.0000\n",
      "Epoch: 8/20.. Loss: 1.2331.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 196.0000\n",
      "Epoch: 8/20.. Loss: 0.8320.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 198.0000\n",
      "Epoch: 8/20.. Loss: 0.5848.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 200.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20.. Loss: 0.6050.. Test accuracy: 0.5459.. 0.0007 s/batch  steps 202.0000\n",
      "Epoch: 9/20.. Loss: 0.7336.. Test accuracy: 0.5457.. 0.0011 s/batch  steps 204.0000\n",
      "Epoch: 9/20.. Loss: 0.5753.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 206.0000\n",
      "Epoch: 9/20.. Loss: 0.6529.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 208.0000\n",
      "Epoch: 9/20.. Loss: 0.8261.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 210.0000\n",
      "Epoch: 9/20.. Loss: 1.1260.. Test accuracy: 0.5459.. 0.0008 s/batch  steps 212.0000\n",
      "Epoch: 9/20.. Loss: 0.9995.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 214.0000\n",
      "Epoch: 9/20.. Loss: 0.9612.. Test accuracy: 0.5458.. 0.0007 s/batch  steps 216.0000\n",
      "Epoch: 9/20.. Loss: 0.0708.. Test accuracy: 0.5457.. 0.0006 s/batch  steps 218.0000\n",
      "Epoch: 9/20.. Loss: 0.4200.. Test accuracy: 0.5456.. 0.0007 s/batch  steps 220.0000\n",
      "Epoch: 9/20.. Loss: 0.6721.. Test accuracy: 0.5458.. 0.0006 s/batch  steps 222.0000\n",
      "Epoch: 9/20.. Loss: 0.2869.. Test accuracy: 0.5456.. 0.0007 s/batch  steps 224.0000\n",
      "Epoch: 10/20.. Loss: 1.0160.. Test accuracy: 0.5457.. 0.0004 s/batch  steps 226.0000\n",
      "Epoch: 10/20.. Loss: 0.9331.. Test accuracy: 0.5457.. 0.0007 s/batch  steps 228.0000\n",
      "Epoch: 10/20.. Loss: 0.7594.. Test accuracy: 0.5457.. 0.0007 s/batch  steps 230.0000\n",
      "Epoch: 10/20.. Loss: 0.4168.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 232.0000\n",
      "Epoch: 10/20.. Loss: 0.3925.. Test accuracy: 0.5457.. 0.0012 s/batch  steps 234.0000\n",
      "Epoch: 10/20.. Loss: 0.1733.. Test accuracy: 0.5457.. 0.0022 s/batch  steps 236.0000\n",
      "Epoch: 10/20.. Loss: 0.5346.. Test accuracy: 0.5457.. 0.0016 s/batch  steps 238.0000\n",
      "Epoch: 10/20.. Loss: 0.1854.. Test accuracy: 0.5457.. 0.0011 s/batch  steps 240.0000\n",
      "Epoch: 10/20.. Loss: 0.7438.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 242.0000\n",
      "Epoch: 10/20.. Loss: 0.8903.. Test accuracy: 0.5457.. 0.0014 s/batch  steps 244.0000\n",
      "Epoch: 10/20.. Loss: 0.3547.. Test accuracy: 0.5456.. 0.0014 s/batch  steps 246.0000\n",
      "Epoch: 10/20.. Loss: 0.7280.. Test accuracy: 0.5458.. 0.0014 s/batch  steps 248.0000\n",
      "Epoch: 10/20.. Loss: 0.8303.. Test accuracy: 0.5457.. 0.0015 s/batch  steps 250.0000\n",
      "Epoch: 11/20.. Loss: 1.1394.. Test accuracy: 0.5457.. 0.0022 s/batch  steps 252.0000\n",
      "Epoch: 11/20.. Loss: 0.5137.. Test accuracy: 0.5457.. 0.0015 s/batch  steps 254.0000\n",
      "Epoch: 11/20.. Loss: 0.5567.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 256.0000\n",
      "Epoch: 11/20.. Loss: 0.9855.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 258.0000\n",
      "Epoch: 11/20.. Loss: 0.5729.. Test accuracy: 0.5458.. 0.0017 s/batch  steps 260.0000\n",
      "Epoch: 11/20.. Loss: 0.6615.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 262.0000\n",
      "Epoch: 11/20.. Loss: 0.4966.. Test accuracy: 0.5457.. 0.0012 s/batch  steps 264.0000\n",
      "Epoch: 11/20.. Loss: 0.4788.. Test accuracy: 0.5457.. 0.0015 s/batch  steps 266.0000\n",
      "Epoch: 11/20.. Loss: 1.0532.. Test accuracy: 0.5457.. 0.0011 s/batch  steps 268.0000\n",
      "Epoch: 11/20.. Loss: 0.6925.. Test accuracy: 0.5457.. 0.0007 s/batch  steps 270.0000\n",
      "Epoch: 11/20.. Loss: 0.4582.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 272.0000\n",
      "Epoch: 11/20.. Loss: 1.1362.. Test accuracy: 0.5457.. 0.0012 s/batch  steps 274.0000\n",
      "Epoch: 12/20.. Loss: 0.3973.. Test accuracy: 0.5456.. 0.0005 s/batch  steps 276.0000\n",
      "Epoch: 12/20.. Loss: 0.5783.. Test accuracy: 0.5457.. 0.0011 s/batch  steps 278.0000\n",
      "Epoch: 12/20.. Loss: 0.9493.. Test accuracy: 0.5456.. 0.0017 s/batch  steps 280.0000\n",
      "Epoch: 12/20.. Loss: 0.3716.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 282.0000\n",
      "Epoch: 12/20.. Loss: 0.3071.. Test accuracy: 0.5458.. 0.0013 s/batch  steps 284.0000\n",
      "Epoch: 12/20.. Loss: 0.9344.. Test accuracy: 0.5456.. 0.0017 s/batch  steps 286.0000\n",
      "Epoch: 12/20.. Loss: 0.2268.. Test accuracy: 0.5457.. 0.0010 s/batch  steps 288.0000\n",
      "Epoch: 12/20.. Loss: 0.8163.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 290.0000\n",
      "Epoch: 12/20.. Loss: 0.9752.. Test accuracy: 0.5457.. 0.0017 s/batch  steps 292.0000\n",
      "Epoch: 12/20.. Loss: 0.4608.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 294.0000\n",
      "Epoch: 12/20.. Loss: 0.2386.. Test accuracy: 0.5456.. 0.0017 s/batch  steps 296.0000\n",
      "Epoch: 12/20.. Loss: 0.6019.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 298.0000\n",
      "Epoch: 12/20.. Loss: 1.2785.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 300.0000\n",
      "Epoch: 13/20.. Loss: 1.0403.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 302.0000\n",
      "Epoch: 13/20.. Loss: 0.7986.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 304.0000\n",
      "Epoch: 13/20.. Loss: 0.5355.. Test accuracy: 0.5456.. 0.0014 s/batch  steps 306.0000\n",
      "Epoch: 13/20.. Loss: 0.3720.. Test accuracy: 0.5458.. 0.0011 s/batch  steps 308.0000\n",
      "Epoch: 13/20.. Loss: 0.7220.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 310.0000\n",
      "Epoch: 13/20.. Loss: 0.9317.. Test accuracy: 0.5456.. 0.0013 s/batch  steps 312.0000\n",
      "Epoch: 13/20.. Loss: 0.6921.. Test accuracy: 0.5456.. 0.0008 s/batch  steps 314.0000\n",
      "Epoch: 13/20.. Loss: 0.3197.. Test accuracy: 0.5457.. 0.0014 s/batch  steps 316.0000\n",
      "Epoch: 13/20.. Loss: 0.7957.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 318.0000\n",
      "Epoch: 13/20.. Loss: 0.5045.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 320.0000\n",
      "Epoch: 13/20.. Loss: 0.2160.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 322.0000\n",
      "Epoch: 13/20.. Loss: 0.7880.. Test accuracy: 0.5457.. 0.0009 s/batch  steps 324.0000\n",
      "Epoch: 14/20.. Loss: 0.3867.. Test accuracy: 0.5458.. 0.0010 s/batch  steps 326.0000\n",
      "Epoch: 14/20.. Loss: 0.6531.. Test accuracy: 0.5458.. 0.0015 s/batch  steps 328.0000\n",
      "Epoch: 14/20.. Loss: 0.8219.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 330.0000\n",
      "Epoch: 14/20.. Loss: 0.7433.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 332.0000\n",
      "Epoch: 14/20.. Loss: 0.6399.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 334.0000\n",
      "Epoch: 14/20.. Loss: 0.7008.. Test accuracy: 0.5458.. 0.0008 s/batch  steps 336.0000\n",
      "Epoch: 14/20.. Loss: 0.4776.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 338.0000\n",
      "Epoch: 14/20.. Loss: 0.7265.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 340.0000\n",
      "Epoch: 14/20.. Loss: 0.1214.. Test accuracy: 0.5455.. 0.0006 s/batch  steps 342.0000\n",
      "Epoch: 14/20.. Loss: 0.3277.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 344.0000\n",
      "Epoch: 14/20.. Loss: 0.2535.. Test accuracy: 0.5456.. 0.0008 s/batch  steps 346.0000\n",
      "Epoch: 14/20.. Loss: 1.1840.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 348.0000\n",
      "Epoch: 14/20.. Loss: 0.7525.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 350.0000\n",
      "Epoch: 15/20.. Loss: 0.7481.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 352.0000\n",
      "Epoch: 15/20.. Loss: 0.3578.. Test accuracy: 0.5457.. 0.0009 s/batch  steps 354.0000\n",
      "Epoch: 15/20.. Loss: 0.7432.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 356.0000\n",
      "Epoch: 15/20.. Loss: 0.1266.. Test accuracy: 0.5456.. 0.0008 s/batch  steps 358.0000\n",
      "Epoch: 15/20.. Loss: 0.8825.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 360.0000\n",
      "Epoch: 15/20.. Loss: 0.8333.. Test accuracy: 0.5457.. 0.0008 s/batch  steps 362.0000\n",
      "Epoch: 15/20.. Loss: 0.7841.. Test accuracy: 0.5458.. 0.0009 s/batch  steps 364.0000\n",
      "Epoch: 15/20.. Loss: 0.3198.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 366.0000\n",
      "Epoch: 15/20.. Loss: 1.1127.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 368.0000\n",
      "Epoch: 15/20.. Loss: 0.9940.. Test accuracy: 0.5457.. 0.0010 s/batch  steps 370.0000\n",
      "Epoch: 15/20.. Loss: 0.3281.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 372.0000\n",
      "Epoch: 15/20.. Loss: 1.1870.. Test accuracy: 0.5457.. 0.0011 s/batch  steps 374.0000\n",
      "Epoch: 16/20.. Loss: 0.6156.. Test accuracy: 0.5456.. 0.0007 s/batch  steps 376.0000\n",
      "Epoch: 16/20.. Loss: 0.7462.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 378.0000\n",
      "Epoch: 16/20.. Loss: 0.3042.. Test accuracy: 0.5455.. 0.0010 s/batch  steps 380.0000\n",
      "Epoch: 16/20.. Loss: 0.6078.. Test accuracy: 0.5456.. 0.0008 s/batch  steps 382.0000\n",
      "Epoch: 16/20.. Loss: 0.6541.. Test accuracy: 0.5456.. 0.0008 s/batch  steps 384.0000\n",
      "Epoch: 16/20.. Loss: 0.8151.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 386.0000\n",
      "Epoch: 16/20.. Loss: 0.2311.. Test accuracy: 0.5456.. 0.0007 s/batch  steps 388.0000\n",
      "Epoch: 16/20.. Loss: 1.2293.. Test accuracy: 0.5456.. 0.0007 s/batch  steps 390.0000\n",
      "Epoch: 16/20.. Loss: 0.7338.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 392.0000\n",
      "Epoch: 16/20.. Loss: 0.6082.. Test accuracy: 0.5456.. 0.0009 s/batch  steps 394.0000\n",
      "Epoch: 16/20.. Loss: 0.2127.. Test accuracy: 0.5456.. 0.0006 s/batch  steps 396.0000\n",
      "Epoch: 16/20.. Loss: 0.7206.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 398.0000\n",
      "Epoch: 16/20.. Loss: 0.2769.. Test accuracy: 0.5456.. 0.0007 s/batch  steps 400.0000\n",
      "Epoch: 17/20.. Loss: 1.1646.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 402.0000\n",
      "Epoch: 17/20.. Loss: 0.4213.. Test accuracy: 0.5455.. 0.0010 s/batch  steps 404.0000\n",
      "Epoch: 17/20.. Loss: 0.6018.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 406.0000\n",
      "Epoch: 17/20.. Loss: 0.1902.. Test accuracy: 0.5456.. 0.0008 s/batch  steps 408.0000\n",
      "Epoch: 17/20.. Loss: 0.8878.. Test accuracy: 0.5456.. 0.0013 s/batch  steps 410.0000\n",
      "Epoch: 17/20.. Loss: 0.4787.. Test accuracy: 0.5455.. 0.0011 s/batch  steps 412.0000\n",
      "Epoch: 17/20.. Loss: 0.6193.. Test accuracy: 0.5455.. 0.0008 s/batch  steps 414.0000\n",
      "Epoch: 17/20.. Loss: 0.3669.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 416.0000\n",
      "Epoch: 17/20.. Loss: 0.7148.. Test accuracy: 0.5455.. 0.0008 s/batch  steps 418.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20.. Loss: 0.6159.. Test accuracy: 0.5455.. 0.0008 s/batch  steps 420.0000\n",
      "Epoch: 17/20.. Loss: 0.9007.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 422.0000\n",
      "Epoch: 17/20.. Loss: 0.9882.. Test accuracy: 0.5456.. 0.0013 s/batch  steps 424.0000\n",
      "Epoch: 18/20.. Loss: 0.1764.. Test accuracy: 0.5455.. 0.0007 s/batch  steps 426.0000\n",
      "Epoch: 18/20.. Loss: 0.8824.. Test accuracy: 0.5456.. 0.0012 s/batch  steps 428.0000\n",
      "Epoch: 18/20.. Loss: 0.2140.. Test accuracy: 0.5455.. 0.0016 s/batch  steps 430.0000\n",
      "Epoch: 18/20.. Loss: 0.8348.. Test accuracy: 0.5455.. 0.0012 s/batch  steps 432.0000\n",
      "Epoch: 18/20.. Loss: 0.7488.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 434.0000\n",
      "Epoch: 18/20.. Loss: 1.1871.. Test accuracy: 0.5455.. 0.0013 s/batch  steps 436.0000\n",
      "Epoch: 18/20.. Loss: 0.2698.. Test accuracy: 0.5455.. 0.0013 s/batch  steps 438.0000\n",
      "Epoch: 18/20.. Loss: 0.6701.. Test accuracy: 0.5455.. 0.0010 s/batch  steps 440.0000\n",
      "Epoch: 18/20.. Loss: 0.4906.. Test accuracy: 0.5455.. 0.0010 s/batch  steps 442.0000\n",
      "Epoch: 18/20.. Loss: 0.5890.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 444.0000\n",
      "Epoch: 18/20.. Loss: 0.3625.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 446.0000\n",
      "Epoch: 18/20.. Loss: 0.9185.. Test accuracy: 0.5455.. 0.0007 s/batch  steps 448.0000\n",
      "Epoch: 18/20.. Loss: 0.4012.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 450.0000\n",
      "Epoch: 19/20.. Loss: 0.5687.. Test accuracy: 0.5455.. 0.0008 s/batch  steps 452.0000\n",
      "Epoch: 19/20.. Loss: 0.2252.. Test accuracy: 0.5455.. 0.0007 s/batch  steps 454.0000\n",
      "Epoch: 19/20.. Loss: 0.7969.. Test accuracy: 0.5456.. 0.0008 s/batch  steps 456.0000\n",
      "Epoch: 19/20.. Loss: 0.4108.. Test accuracy: 0.5456.. 0.0007 s/batch  steps 458.0000\n",
      "Epoch: 19/20.. Loss: 0.9544.. Test accuracy: 0.5455.. 0.0010 s/batch  steps 460.0000\n",
      "Epoch: 19/20.. Loss: 0.8389.. Test accuracy: 0.5455.. 0.0010 s/batch  steps 462.0000\n",
      "Epoch: 19/20.. Loss: 0.7042.. Test accuracy: 0.5454.. 0.0007 s/batch  steps 464.0000\n",
      "Epoch: 19/20.. Loss: 0.8068.. Test accuracy: 0.5455.. 0.0012 s/batch  steps 466.0000\n",
      "Epoch: 19/20.. Loss: 0.3152.. Test accuracy: 0.5455.. 0.0015 s/batch  steps 468.0000\n",
      "Epoch: 19/20.. Loss: 0.7488.. Test accuracy: 0.5454.. 0.0009 s/batch  steps 470.0000\n",
      "Epoch: 19/20.. Loss: 0.0111.. Test accuracy: 0.5455.. 0.0012 s/batch  steps 472.0000\n",
      "Epoch: 19/20.. Loss: 0.7488.. Test accuracy: 0.5455.. 0.0016 s/batch  steps 474.0000\n",
      "Epoch: 20/20.. Loss: 0.5640.. Test accuracy: 0.5455.. 0.0006 s/batch  steps 476.0000\n",
      "Epoch: 20/20.. Loss: 0.5787.. Test accuracy: 0.5454.. 0.0016 s/batch  steps 478.0000\n",
      "Epoch: 20/20.. Loss: 0.7693.. Test accuracy: 0.5455.. 0.0011 s/batch  steps 480.0000\n",
      "Epoch: 20/20.. Loss: 0.4228.. Test accuracy: 0.5455.. 0.0015 s/batch  steps 482.0000\n",
      "Epoch: 20/20.. Loss: 0.2661.. Test accuracy: 0.5455.. 0.0008 s/batch  steps 484.0000\n",
      "Epoch: 20/20.. Loss: 0.4702.. Test accuracy: 0.5455.. 0.0008 s/batch  steps 486.0000\n",
      "Epoch: 20/20.. Loss: 0.3504.. Test accuracy: 0.5454.. 0.0008 s/batch  steps 488.0000\n",
      "Epoch: 20/20.. Loss: 0.6682.. Test accuracy: 0.5455.. 0.0007 s/batch  steps 490.0000\n",
      "Epoch: 20/20.. Loss: 0.9758.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 492.0000\n",
      "Epoch: 20/20.. Loss: 0.4670.. Test accuracy: 0.5455.. 0.0011 s/batch  steps 494.0000\n",
      "Epoch: 20/20.. Loss: 0.2369.. Test accuracy: 0.5454.. 0.0009 s/batch  steps 496.0000\n",
      "Epoch: 20/20.. Loss: 0.7165.. Test accuracy: 0.5456.. 0.0010 s/batch  steps 498.0000\n",
      "Epoch: 20/20.. Loss: 0.6590.. Test accuracy: 0.5455.. 0.0009 s/batch  steps 500.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAHyCAYAAABbIyCJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8THOgcEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dff2f60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 375
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.00001, weight_decay=1e-4)\n",
    "epochs = 20\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 2\n",
    "vec_acc_ = np.zeros(epochs*25)\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Do not forget to transform the inputs and outputs into Variable        #\n",
    "        # which pytorch uses.                                                          #\n",
    "        ################################################################################\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        output = net.forward(inputs)\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        grad = loss.backward()\n",
    "        optimizer.step()\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            sum_accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                inputs = Variable(images)\n",
    "                targets = Variable(labels)\n",
    "                predicted = net.predict(inputs)\n",
    "                accuracy = criterion(predicted, targets)\n",
    "                accuracy = accuracy.data.numpy().tolist()[0]\n",
    "                vec_acc_[steps-1] = accuracy/(ii+1)\n",
    "                sum_accuracy += accuracy\n",
    "                \n",
    "                #inputs = Variable(images, volatile=True)\n",
    "                #predicted = net.predict(inputs)\n",
    "                #equality = (labels == predicted.max(1)[1])\n",
    "                #accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "                \n",
    "                \n",
    "                #im = Variable(images)\n",
    "                #out = net.predict(im)\n",
    "                #_,prediction = torch.max(out, 1)\n",
    "                #pred_y = prediction.data.numpy().squeeze()\n",
    "                #target_y = labels.numpy()\n",
    "                #accuracy = np.mean(predicted == inputs)\n",
    "                #print(pred_y.shape,target_y.shape)\n",
    "                \n",
    "                \n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(loss.data[0]),\n",
    "                  \"Test accuracy: {:.4f}..\".format(sum_accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch \".format((stop - start)/print_every),\n",
    "                  \"steps {:.4f}\".format(steps)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()\n",
    "\n",
    "plt.plot(range(epochs*25),vec_acc_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eq received an invalid combination of arguments - got (Variable), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n * (torch.FloatTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-e42f0e93ca01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eq received an invalid combination of arguments - got (Variable), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n * (torch.FloatTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predicted == inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vector_create = np.random.rand(1000,19,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  torch.Size([950, 1, 9, 2])\n",
      "Train labels shape:  torch.Size([950, 1, 9, 2])\n",
      "Validation data shape:  torch.Size([50, 1, 9, 2])\n",
      "Validation labels shape:  torch.Size([50, 1, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(Vector_create),9,2))\n",
    "y = np.zeros((len(Vector_create),9,2))\n",
    "for i in range(len(Vector_create)):\n",
    "    x[i][:][:] = Vector_create[i][:9][:]\n",
    "    y[i][:][:] = Vector_create[i][10:19][:]\n",
    "\n",
    "mask = list(range(len(Vector_create)-50, len(Vector_create)))\n",
    "x_val = x[mask]\n",
    "y_val = y[mask]\n",
    "mask = list(range(len(Vector_create)-50))\n",
    "x_train = x[mask]\n",
    "y_train = y[mask]\n",
    "\n",
    "x_train,y_train = torch.from_numpy(x_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "x_val,y_val = torch.from_numpy(x_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.FloatTensor)\n",
    "\n",
    "x_train = x_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "y_train = y_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "x_val = x_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "y_val = y_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "traindataset = utils.TensorDataset(x_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(x_val, y_val)\n",
    "valloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNetcreate(nn.Module):\n",
    "    def __init__(self, n_input_channels=1, n_output=None):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Define 2 or more different layers of the neural network                      #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(n_input_channels,3,5,padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
    "     \n",
    "        self.fc1 = nn.Linear(9*2 * 3, 9*2 * 1)\n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Set up the forward pass that the input data will go through.                 #\n",
    "        # A good activation function betweent the layers is a ReLu function.           #\n",
    "        #                                                                              #\n",
    "        # Note that the output of the last convolution layer should be flattened       #\n",
    "        # before being inputted to the fully connected layer. We can flatten           #\n",
    "        # Variable `x` with `x.view`.                                                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        x = x.view(-1, 9*2 * 3) # in order to reshape the tensor for as many columns we need\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/4romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20.. Loss: 0.2787.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2.0000\n",
      "Epoch: 1/20.. Loss: 0.2637.. Test accuracy: 0.2802.. 0.0009 s/batch  steps 4.0000\n",
      "Epoch: 1/20.. Loss: 0.2871.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 6.0000\n",
      "Epoch: 1/20.. Loss: 0.2638.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 8.0000\n",
      "Epoch: 1/20.. Loss: 0.2765.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 10.0000\n",
      "Epoch: 1/20.. Loss: 0.2986.. Test accuracy: 0.2802.. 0.0011 s/batch  steps 12.0000\n",
      "Epoch: 1/20.. Loss: 0.3309.. Test accuracy: 0.2802.. 0.0008 s/batch  steps 14.0000\n",
      "Epoch: 1/20.. Loss: 0.3209.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 16.0000\n",
      "Epoch: 1/20.. Loss: 0.2813.. Test accuracy: 0.2802.. 0.0011 s/batch  steps 18.0000\n",
      "Epoch: 1/20.. Loss: 0.2972.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 20.0000\n",
      "Epoch: 1/20.. Loss: 0.2977.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 22.0000\n",
      "Epoch: 1/20.. Loss: 0.3520.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 24.0000\n",
      "Epoch: 1/20.. Loss: 0.3034.. Test accuracy: 0.2802.. 0.0008 s/batch  steps 26.0000\n",
      "Epoch: 1/20.. Loss: 0.2783.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 28.0000\n",
      "Epoch: 1/20.. Loss: 0.2688.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 30.0000\n",
      "Epoch: 1/20.. Loss: 0.3022.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 32.0000\n",
      "Epoch: 1/20.. Loss: 0.3118.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 34.0000\n",
      "Epoch: 1/20.. Loss: 0.3249.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 36.0000\n",
      "Epoch: 1/20.. Loss: 0.3487.. Test accuracy: 0.2802.. 0.0008 s/batch  steps 38.0000\n",
      "Epoch: 1/20.. Loss: 0.3002.. Test accuracy: 0.2802.. 0.0007 s/batch  steps 40.0000\n",
      "Epoch: 1/20.. Loss: 0.2226.. Test accuracy: 0.2802.. 0.0009 s/batch  steps 42.0000\n",
      "Epoch: 1/20.. Loss: 0.3289.. Test accuracy: 0.2802.. 0.0008 s/batch  steps 44.0000\n",
      "Epoch: 1/20.. Loss: 0.3072.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 46.0000\n",
      "Epoch: 1/20.. Loss: 0.2893.. Test accuracy: 0.2802.. 0.0011 s/batch  steps 48.0000\n",
      "Epoch: 1/20.. Loss: 0.2911.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 50.0000\n",
      "Epoch: 1/20.. Loss: 0.2559.. Test accuracy: 0.2802.. 0.0007 s/batch  steps 52.0000\n",
      "Epoch: 1/20.. Loss: 0.2817.. Test accuracy: 0.2802.. 0.0009 s/batch  steps 54.0000\n",
      "Epoch: 1/20.. Loss: 0.2490.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 56.0000\n",
      "Epoch: 1/20.. Loss: 0.2922.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 58.0000\n",
      "Epoch: 1/20.. Loss: 0.3066.. Test accuracy: 0.2802.. 0.0008 s/batch  steps 60.0000\n",
      "Epoch: 1/20.. Loss: 0.3268.. Test accuracy: 0.2802.. 0.0007 s/batch  steps 62.0000\n",
      "Epoch: 1/20.. Loss: 0.2798.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 64.0000\n",
      "Epoch: 1/20.. Loss: 0.2967.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 66.0000\n",
      "Epoch: 1/20.. Loss: 0.2946.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 68.0000\n",
      "Epoch: 1/20.. Loss: 0.3010.. Test accuracy: 0.2802.. 0.0015 s/batch  steps 70.0000\n",
      "Epoch: 1/20.. Loss: 0.3049.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 72.0000\n",
      "Epoch: 1/20.. Loss: 0.3275.. Test accuracy: 0.2802.. 0.0007 s/batch  steps 74.0000\n",
      "Epoch: 1/20.. Loss: 0.3668.. Test accuracy: 0.2802.. 0.0008 s/batch  steps 76.0000\n",
      "Epoch: 1/20.. Loss: 0.3266.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 78.0000\n",
      "Epoch: 1/20.. Loss: 0.2979.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 80.0000\n",
      "Epoch: 1/20.. Loss: 0.2926.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 82.0000\n",
      "Epoch: 1/20.. Loss: 0.2813.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 84.0000\n",
      "Epoch: 1/20.. Loss: 0.2716.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 86.0000\n",
      "Epoch: 1/20.. Loss: 0.2786.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 88.0000\n",
      "Epoch: 1/20.. Loss: 0.2554.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 90.0000\n",
      "Epoch: 1/20.. Loss: 0.2761.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 92.0000\n",
      "Epoch: 1/20.. Loss: 0.2215.. Test accuracy: 0.2802.. 0.0018 s/batch  steps 94.0000\n",
      "Epoch: 1/20.. Loss: 0.2953.. Test accuracy: 0.2802.. 0.0014 s/batch  steps 96.0000\n",
      "Epoch: 1/20.. Loss: 0.2575.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 98.0000\n",
      "Epoch: 1/20.. Loss: 0.3564.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 100.0000\n",
      "Epoch: 1/20.. Loss: 0.3320.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 102.0000\n",
      "Epoch: 1/20.. Loss: 0.3199.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 104.0000\n",
      "Epoch: 1/20.. Loss: 0.3140.. Test accuracy: 0.2802.. 0.0009 s/batch  steps 106.0000\n",
      "Epoch: 1/20.. Loss: 0.3085.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 108.0000\n",
      "Epoch: 1/20.. Loss: 0.2756.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 110.0000\n",
      "Epoch: 1/20.. Loss: 0.2537.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 112.0000\n",
      "Epoch: 1/20.. Loss: 0.3626.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 114.0000\n",
      "Epoch: 1/20.. Loss: 0.3927.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 116.0000\n",
      "Epoch: 1/20.. Loss: 0.2901.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 118.0000\n",
      "Epoch: 1/20.. Loss: 0.3245.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 120.0000\n",
      "Epoch: 1/20.. Loss: 0.2893.. Test accuracy: 0.2802.. 0.0013 s/batch  steps 122.0000\n",
      "Epoch: 1/20.. Loss: 0.2514.. Test accuracy: 0.2802.. 0.0012 s/batch  steps 124.0000\n",
      "Epoch: 1/20.. Loss: 0.2780.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 126.0000\n",
      "Epoch: 1/20.. Loss: 0.2759.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 128.0000\n",
      "Epoch: 1/20.. Loss: 0.3625.. Test accuracy: 0.2802.. 0.0017 s/batch  steps 130.0000\n",
      "Epoch: 1/20.. Loss: 0.3200.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 132.0000\n",
      "Epoch: 1/20.. Loss: 0.2964.. Test accuracy: 0.2802.. 0.0011 s/batch  steps 134.0000\n",
      "Epoch: 1/20.. Loss: 0.3643.. Test accuracy: 0.2802.. 0.0012 s/batch  steps 136.0000\n",
      "Epoch: 1/20.. Loss: 0.3173.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 138.0000\n",
      "Epoch: 1/20.. Loss: 0.2559.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 140.0000\n",
      "Epoch: 1/20.. Loss: 0.2755.. Test accuracy: 0.2802.. 0.0009 s/batch  steps 142.0000\n",
      "Epoch: 1/20.. Loss: 0.3071.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 144.0000\n",
      "Epoch: 1/20.. Loss: 0.2872.. Test accuracy: 0.2802.. 0.0010 s/batch  steps 146.0000\n",
      "Epoch: 1/20.. Loss: 0.2724.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 148.0000\n",
      "Epoch: 1/20.. Loss: 0.3330.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 150.0000\n",
      "Epoch: 1/20.. Loss: 0.3288.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 152.0000\n",
      "Epoch: 1/20.. Loss: 0.3019.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 154.0000\n",
      "Epoch: 1/20.. Loss: 0.3255.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 156.0000\n",
      "Epoch: 1/20.. Loss: 0.2981.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 158.0000\n",
      "Epoch: 1/20.. Loss: 0.3445.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 160.0000\n",
      "Epoch: 1/20.. Loss: 0.2671.. Test accuracy: 0.2801.. 0.0020 s/batch  steps 162.0000\n",
      "Epoch: 1/20.. Loss: 0.3061.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 164.0000\n",
      "Epoch: 1/20.. Loss: 0.2684.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 166.0000\n",
      "Epoch: 1/20.. Loss: 0.2549.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 168.0000\n",
      "Epoch: 1/20.. Loss: 0.2836.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 170.0000\n",
      "Epoch: 1/20.. Loss: 0.2528.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 172.0000\n",
      "Epoch: 1/20.. Loss: 0.2720.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 174.0000\n",
      "Epoch: 1/20.. Loss: 0.2609.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 176.0000\n",
      "Epoch: 1/20.. Loss: 0.2849.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 178.0000\n",
      "Epoch: 1/20.. Loss: 0.2765.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 180.0000\n",
      "Epoch: 1/20.. Loss: 0.2704.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 182.0000\n",
      "Epoch: 1/20.. Loss: 0.2808.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 184.0000\n",
      "Epoch: 1/20.. Loss: 0.3853.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 186.0000\n",
      "Epoch: 1/20.. Loss: 0.3045.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 188.0000\n",
      "Epoch: 1/20.. Loss: 0.3337.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 190.0000\n",
      "Epoch: 2/20.. Loss: 0.2597.. Test accuracy: 0.2801.. 0.0019 s/batch  steps 192.0000\n",
      "Epoch: 2/20.. Loss: 0.3303.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 194.0000\n",
      "Epoch: 2/20.. Loss: 0.3061.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 196.0000\n",
      "Epoch: 2/20.. Loss: 0.2797.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 198.0000\n",
      "Epoch: 2/20.. Loss: 0.3064.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 200.0000\n",
      "Epoch: 2/20.. Loss: 0.2641.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 202.0000\n",
      "Epoch: 2/20.. Loss: 0.3277.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 204.0000\n",
      "Epoch: 2/20.. Loss: 0.3767.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 206.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20.. Loss: 0.2549.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 208.0000\n",
      "Epoch: 2/20.. Loss: 0.3390.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 210.0000\n",
      "Epoch: 2/20.. Loss: 0.2437.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 212.0000\n",
      "Epoch: 2/20.. Loss: 0.3352.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 214.0000\n",
      "Epoch: 2/20.. Loss: 0.2678.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 216.0000\n",
      "Epoch: 2/20.. Loss: 0.3210.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 218.0000\n",
      "Epoch: 2/20.. Loss: 0.2527.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 220.0000\n",
      "Epoch: 2/20.. Loss: 0.2384.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 222.0000\n",
      "Epoch: 2/20.. Loss: 0.3110.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 224.0000\n",
      "Epoch: 2/20.. Loss: 0.3212.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 226.0000\n",
      "Epoch: 2/20.. Loss: 0.2945.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 228.0000\n",
      "Epoch: 2/20.. Loss: 0.3124.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 230.0000\n",
      "Epoch: 2/20.. Loss: 0.2813.. Test accuracy: 0.2802.. 0.0013 s/batch  steps 232.0000\n",
      "Epoch: 2/20.. Loss: 0.2600.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 234.0000\n",
      "Epoch: 2/20.. Loss: 0.3108.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 236.0000\n",
      "Epoch: 2/20.. Loss: 0.2970.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 238.0000\n",
      "Epoch: 2/20.. Loss: 0.2941.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 240.0000\n",
      "Epoch: 2/20.. Loss: 0.3177.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 242.0000\n",
      "Epoch: 2/20.. Loss: 0.2897.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 244.0000\n",
      "Epoch: 2/20.. Loss: 0.2958.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 246.0000\n",
      "Epoch: 2/20.. Loss: 0.3639.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 248.0000\n",
      "Epoch: 2/20.. Loss: 0.2741.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 250.0000\n",
      "Epoch: 2/20.. Loss: 0.2618.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 252.0000\n",
      "Epoch: 2/20.. Loss: 0.2864.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 254.0000\n",
      "Epoch: 2/20.. Loss: 0.3333.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 256.0000\n",
      "Epoch: 2/20.. Loss: 0.2849.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 258.0000\n",
      "Epoch: 2/20.. Loss: 0.2904.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 260.0000\n",
      "Epoch: 2/20.. Loss: 0.2600.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 262.0000\n",
      "Epoch: 2/20.. Loss: 0.3046.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 264.0000\n",
      "Epoch: 2/20.. Loss: 0.3235.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 266.0000\n",
      "Epoch: 2/20.. Loss: 0.2846.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 268.0000\n",
      "Epoch: 2/20.. Loss: 0.2858.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 270.0000\n",
      "Epoch: 2/20.. Loss: 0.2827.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 272.0000\n",
      "Epoch: 2/20.. Loss: 0.2870.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 274.0000\n",
      "Epoch: 2/20.. Loss: 0.3119.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 276.0000\n",
      "Epoch: 2/20.. Loss: 0.2588.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 278.0000\n",
      "Epoch: 2/20.. Loss: 0.3115.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 280.0000\n",
      "Epoch: 2/20.. Loss: 0.3181.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 282.0000\n",
      "Epoch: 2/20.. Loss: 0.2900.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 284.0000\n",
      "Epoch: 2/20.. Loss: 0.2052.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 286.0000\n",
      "Epoch: 2/20.. Loss: 0.2744.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 288.0000\n",
      "Epoch: 2/20.. Loss: 0.2529.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 290.0000\n",
      "Epoch: 2/20.. Loss: 0.2700.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 292.0000\n",
      "Epoch: 2/20.. Loss: 0.3212.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 294.0000\n",
      "Epoch: 2/20.. Loss: 0.2335.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 296.0000\n",
      "Epoch: 2/20.. Loss: 0.3854.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 298.0000\n",
      "Epoch: 2/20.. Loss: 0.2631.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 300.0000\n",
      "Epoch: 2/20.. Loss: 0.3112.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 302.0000\n",
      "Epoch: 2/20.. Loss: 0.2970.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 304.0000\n",
      "Epoch: 2/20.. Loss: 0.3091.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 306.0000\n",
      "Epoch: 2/20.. Loss: 0.3071.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 308.0000\n",
      "Epoch: 2/20.. Loss: 0.3047.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 310.0000\n",
      "Epoch: 2/20.. Loss: 0.2656.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 312.0000\n",
      "Epoch: 2/20.. Loss: 0.2999.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 314.0000\n",
      "Epoch: 2/20.. Loss: 0.2771.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 316.0000\n",
      "Epoch: 2/20.. Loss: 0.3091.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 318.0000\n",
      "Epoch: 2/20.. Loss: 0.2725.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 320.0000\n",
      "Epoch: 2/20.. Loss: 0.2427.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 322.0000\n",
      "Epoch: 2/20.. Loss: 0.2639.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 324.0000\n",
      "Epoch: 2/20.. Loss: 0.2822.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 326.0000\n",
      "Epoch: 2/20.. Loss: 0.2419.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 328.0000\n",
      "Epoch: 2/20.. Loss: 0.2837.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 330.0000\n",
      "Epoch: 2/20.. Loss: 0.2622.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 332.0000\n",
      "Epoch: 2/20.. Loss: 0.3005.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 334.0000\n",
      "Epoch: 2/20.. Loss: 0.2800.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 336.0000\n",
      "Epoch: 2/20.. Loss: 0.2545.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 338.0000\n",
      "Epoch: 2/20.. Loss: 0.2442.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 340.0000\n",
      "Epoch: 2/20.. Loss: 0.3148.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 342.0000\n",
      "Epoch: 2/20.. Loss: 0.2275.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 344.0000\n",
      "Epoch: 2/20.. Loss: 0.2701.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 346.0000\n",
      "Epoch: 2/20.. Loss: 0.2934.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 348.0000\n",
      "Epoch: 2/20.. Loss: 0.2399.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 350.0000\n",
      "Epoch: 2/20.. Loss: 0.2675.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 352.0000\n",
      "Epoch: 2/20.. Loss: 0.3470.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 354.0000\n",
      "Epoch: 2/20.. Loss: 0.2987.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 356.0000\n",
      "Epoch: 2/20.. Loss: 0.2943.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 358.0000\n",
      "Epoch: 2/20.. Loss: 0.2662.. Test accuracy: 0.2802.. 0.0008 s/batch  steps 360.0000\n",
      "Epoch: 2/20.. Loss: 0.2651.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 362.0000\n",
      "Epoch: 2/20.. Loss: 0.2645.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 364.0000\n",
      "Epoch: 2/20.. Loss: 0.2803.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 366.0000\n",
      "Epoch: 2/20.. Loss: 0.2679.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 368.0000\n",
      "Epoch: 2/20.. Loss: 0.2407.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 370.0000\n",
      "Epoch: 2/20.. Loss: 0.2181.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 372.0000\n",
      "Epoch: 2/20.. Loss: 0.2603.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 374.0000\n",
      "Epoch: 2/20.. Loss: 0.3200.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 376.0000\n",
      "Epoch: 2/20.. Loss: 0.2746.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 378.0000\n",
      "Epoch: 2/20.. Loss: 0.2790.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 380.0000\n",
      "Epoch: 3/20.. Loss: 0.2228.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 382.0000\n",
      "Epoch: 3/20.. Loss: 0.2947.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 384.0000\n",
      "Epoch: 3/20.. Loss: 0.2972.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 386.0000\n",
      "Epoch: 3/20.. Loss: 0.2707.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 388.0000\n",
      "Epoch: 3/20.. Loss: 0.2741.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 390.0000\n",
      "Epoch: 3/20.. Loss: 0.2950.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 392.0000\n",
      "Epoch: 3/20.. Loss: 0.2929.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 394.0000\n",
      "Epoch: 3/20.. Loss: 0.2594.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 396.0000\n",
      "Epoch: 3/20.. Loss: 0.2119.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 398.0000\n",
      "Epoch: 3/20.. Loss: 0.2627.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 400.0000\n",
      "Epoch: 3/20.. Loss: 0.2679.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 402.0000\n",
      "Epoch: 3/20.. Loss: 0.2956.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 404.0000\n",
      "Epoch: 3/20.. Loss: 0.2798.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 406.0000\n",
      "Epoch: 3/20.. Loss: 0.2735.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 408.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20.. Loss: 0.2904.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 410.0000\n",
      "Epoch: 3/20.. Loss: 0.2900.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 412.0000\n",
      "Epoch: 3/20.. Loss: 0.2561.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 414.0000\n",
      "Epoch: 3/20.. Loss: 0.2660.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 416.0000\n",
      "Epoch: 3/20.. Loss: 0.2657.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 418.0000\n",
      "Epoch: 3/20.. Loss: 0.2692.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 420.0000\n",
      "Epoch: 3/20.. Loss: 0.2272.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 422.0000\n",
      "Epoch: 3/20.. Loss: 0.3085.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 424.0000\n",
      "Epoch: 3/20.. Loss: 0.3915.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 426.0000\n",
      "Epoch: 3/20.. Loss: 0.3358.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 428.0000\n",
      "Epoch: 3/20.. Loss: 0.2407.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 430.0000\n",
      "Epoch: 3/20.. Loss: 0.2707.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 432.0000\n",
      "Epoch: 3/20.. Loss: 0.2427.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 434.0000\n",
      "Epoch: 3/20.. Loss: 0.2844.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 436.0000\n",
      "Epoch: 3/20.. Loss: 0.3373.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 438.0000\n",
      "Epoch: 3/20.. Loss: 0.2915.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 440.0000\n",
      "Epoch: 3/20.. Loss: 0.3064.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 442.0000\n",
      "Epoch: 3/20.. Loss: 0.2646.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 444.0000\n",
      "Epoch: 3/20.. Loss: 0.2482.. Test accuracy: 0.2801.. 0.0020 s/batch  steps 446.0000\n",
      "Epoch: 3/20.. Loss: 0.2898.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 448.0000\n",
      "Epoch: 3/20.. Loss: 0.2086.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 450.0000\n",
      "Epoch: 3/20.. Loss: 0.2945.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 452.0000\n",
      "Epoch: 3/20.. Loss: 0.2516.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 454.0000\n",
      "Epoch: 3/20.. Loss: 0.2409.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 456.0000\n",
      "Epoch: 3/20.. Loss: 0.2990.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 458.0000\n",
      "Epoch: 3/20.. Loss: 0.2797.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 460.0000\n",
      "Epoch: 3/20.. Loss: 0.3272.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 462.0000\n",
      "Epoch: 3/20.. Loss: 0.2713.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 464.0000\n",
      "Epoch: 3/20.. Loss: 0.2794.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 466.0000\n",
      "Epoch: 3/20.. Loss: 0.2975.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 468.0000\n",
      "Epoch: 3/20.. Loss: 0.2972.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 470.0000\n",
      "Epoch: 3/20.. Loss: 0.2992.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 472.0000\n",
      "Epoch: 3/20.. Loss: 0.3137.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 474.0000\n",
      "Epoch: 3/20.. Loss: 0.2603.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 476.0000\n",
      "Epoch: 3/20.. Loss: 0.2264.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 478.0000\n",
      "Epoch: 3/20.. Loss: 0.3048.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 480.0000\n",
      "Epoch: 3/20.. Loss: 0.3274.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 482.0000\n",
      "Epoch: 3/20.. Loss: 0.2515.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 484.0000\n",
      "Epoch: 3/20.. Loss: 0.2692.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 486.0000\n",
      "Epoch: 3/20.. Loss: 0.3044.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 488.0000\n",
      "Epoch: 3/20.. Loss: 0.2296.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 490.0000\n",
      "Epoch: 3/20.. Loss: 0.2671.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 492.0000\n",
      "Epoch: 3/20.. Loss: 0.2858.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 494.0000\n",
      "Epoch: 3/20.. Loss: 0.2580.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 496.0000\n",
      "Epoch: 3/20.. Loss: 0.2582.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 498.0000\n",
      "Epoch: 3/20.. Loss: 0.2846.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 500.0000\n",
      "Epoch: 3/20.. Loss: 0.2621.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 502.0000\n",
      "Epoch: 3/20.. Loss: 0.2384.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 504.0000\n",
      "Epoch: 3/20.. Loss: 0.2059.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 506.0000\n",
      "Epoch: 3/20.. Loss: 0.2949.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 508.0000\n",
      "Epoch: 3/20.. Loss: 0.2437.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 510.0000\n",
      "Epoch: 3/20.. Loss: 0.2431.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 512.0000\n",
      "Epoch: 3/20.. Loss: 0.2489.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 514.0000\n",
      "Epoch: 3/20.. Loss: 0.2536.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 516.0000\n",
      "Epoch: 3/20.. Loss: 0.2596.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 518.0000\n",
      "Epoch: 3/20.. Loss: 0.2669.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 520.0000\n",
      "Epoch: 3/20.. Loss: 0.2903.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 522.0000\n",
      "Epoch: 3/20.. Loss: 0.2868.. Test accuracy: 0.2801.. 0.0024 s/batch  steps 524.0000\n",
      "Epoch: 3/20.. Loss: 0.2537.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 526.0000\n",
      "Epoch: 3/20.. Loss: 0.2495.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 528.0000\n",
      "Epoch: 3/20.. Loss: 0.3128.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 530.0000\n",
      "Epoch: 3/20.. Loss: 0.2966.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 532.0000\n",
      "Epoch: 3/20.. Loss: 0.2622.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 534.0000\n",
      "Epoch: 3/20.. Loss: 0.2605.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 536.0000\n",
      "Epoch: 3/20.. Loss: 0.2243.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 538.0000\n",
      "Epoch: 3/20.. Loss: 0.2029.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 540.0000\n",
      "Epoch: 3/20.. Loss: 0.2670.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 542.0000\n",
      "Epoch: 3/20.. Loss: 0.2462.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 544.0000\n",
      "Epoch: 3/20.. Loss: 0.2928.. Test accuracy: 0.2801.. 0.0022 s/batch  steps 546.0000\n",
      "Epoch: 3/20.. Loss: 0.2312.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 548.0000\n",
      "Epoch: 3/20.. Loss: 0.2725.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 550.0000\n",
      "Epoch: 3/20.. Loss: 0.2930.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 552.0000\n",
      "Epoch: 3/20.. Loss: 0.2611.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 554.0000\n",
      "Epoch: 3/20.. Loss: 0.2351.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 556.0000\n",
      "Epoch: 3/20.. Loss: 0.2077.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 558.0000\n",
      "Epoch: 3/20.. Loss: 0.2814.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 560.0000\n",
      "Epoch: 3/20.. Loss: 0.3085.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 562.0000\n",
      "Epoch: 3/20.. Loss: 0.2566.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 564.0000\n",
      "Epoch: 3/20.. Loss: 0.2907.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 566.0000\n",
      "Epoch: 3/20.. Loss: 0.2851.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 568.0000\n",
      "Epoch: 3/20.. Loss: 0.2656.. Test accuracy: 0.2801.. 0.0018 s/batch  steps 570.0000\n",
      "Epoch: 4/20.. Loss: 0.2680.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 572.0000\n",
      "Epoch: 4/20.. Loss: 0.3094.. Test accuracy: 0.2801.. 0.0027 s/batch  steps 574.0000\n",
      "Epoch: 4/20.. Loss: 0.2535.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 576.0000\n",
      "Epoch: 4/20.. Loss: 0.2382.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 578.0000\n",
      "Epoch: 4/20.. Loss: 0.2535.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 580.0000\n",
      "Epoch: 4/20.. Loss: 0.2207.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 582.0000\n",
      "Epoch: 4/20.. Loss: 0.2730.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 584.0000\n",
      "Epoch: 4/20.. Loss: 0.2657.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 586.0000\n",
      "Epoch: 4/20.. Loss: 0.2510.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 588.0000\n",
      "Epoch: 4/20.. Loss: 0.2297.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 590.0000\n",
      "Epoch: 4/20.. Loss: 0.2983.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 592.0000\n",
      "Epoch: 4/20.. Loss: 0.3030.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 594.0000\n",
      "Epoch: 4/20.. Loss: 0.2405.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 596.0000\n",
      "Epoch: 4/20.. Loss: 0.2478.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 598.0000\n",
      "Epoch: 4/20.. Loss: 0.2541.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 600.0000\n",
      "Epoch: 4/20.. Loss: 0.2563.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 602.0000\n",
      "Epoch: 4/20.. Loss: 0.2982.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 604.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20.. Loss: 0.2856.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 606.0000\n",
      "Epoch: 4/20.. Loss: 0.2462.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 608.0000\n",
      "Epoch: 4/20.. Loss: 0.2605.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 610.0000\n",
      "Epoch: 4/20.. Loss: 0.2728.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 612.0000\n",
      "Epoch: 4/20.. Loss: 0.2452.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 614.0000\n",
      "Epoch: 4/20.. Loss: 0.2519.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 616.0000\n",
      "Epoch: 4/20.. Loss: 0.2980.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 618.0000\n",
      "Epoch: 4/20.. Loss: 0.2496.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 620.0000\n",
      "Epoch: 4/20.. Loss: 0.2767.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 622.0000\n",
      "Epoch: 4/20.. Loss: 0.2545.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 624.0000\n",
      "Epoch: 4/20.. Loss: 0.2270.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 626.0000\n",
      "Epoch: 4/20.. Loss: 0.2133.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 628.0000\n",
      "Epoch: 4/20.. Loss: 0.2524.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 630.0000\n",
      "Epoch: 4/20.. Loss: 0.2518.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 632.0000\n",
      "Epoch: 4/20.. Loss: 0.2649.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 634.0000\n",
      "Epoch: 4/20.. Loss: 0.2053.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 636.0000\n",
      "Epoch: 4/20.. Loss: 0.2787.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 638.0000\n",
      "Epoch: 4/20.. Loss: 0.2563.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 640.0000\n",
      "Epoch: 4/20.. Loss: 0.2655.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 642.0000\n",
      "Epoch: 4/20.. Loss: 0.2401.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 644.0000\n",
      "Epoch: 4/20.. Loss: 0.2609.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 646.0000\n",
      "Epoch: 4/20.. Loss: 0.2530.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 648.0000\n",
      "Epoch: 4/20.. Loss: 0.3027.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 650.0000\n",
      "Epoch: 4/20.. Loss: 0.2268.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 652.0000\n",
      "Epoch: 4/20.. Loss: 0.2388.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 654.0000\n",
      "Epoch: 4/20.. Loss: 0.2748.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 656.0000\n",
      "Epoch: 4/20.. Loss: 0.2899.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 658.0000\n",
      "Epoch: 4/20.. Loss: 0.2681.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 660.0000\n",
      "Epoch: 4/20.. Loss: 0.2260.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 662.0000\n",
      "Epoch: 4/20.. Loss: 0.2732.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 664.0000\n",
      "Epoch: 4/20.. Loss: 0.3118.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 666.0000\n",
      "Epoch: 4/20.. Loss: 0.2451.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 668.0000\n",
      "Epoch: 4/20.. Loss: 0.2774.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 670.0000\n",
      "Epoch: 4/20.. Loss: 0.2403.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 672.0000\n",
      "Epoch: 4/20.. Loss: 0.2698.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 674.0000\n",
      "Epoch: 4/20.. Loss: 0.2983.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 676.0000\n",
      "Epoch: 4/20.. Loss: 0.2150.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 678.0000\n",
      "Epoch: 4/20.. Loss: 0.2325.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 680.0000\n",
      "Epoch: 4/20.. Loss: 0.2385.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 682.0000\n",
      "Epoch: 4/20.. Loss: 0.2236.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 684.0000\n",
      "Epoch: 4/20.. Loss: 0.2754.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 686.0000\n",
      "Epoch: 4/20.. Loss: 0.2760.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 688.0000\n",
      "Epoch: 4/20.. Loss: 0.2703.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 690.0000\n",
      "Epoch: 4/20.. Loss: 0.2633.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 692.0000\n",
      "Epoch: 4/20.. Loss: 0.2780.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 694.0000\n",
      "Epoch: 4/20.. Loss: 0.3186.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 696.0000\n",
      "Epoch: 4/20.. Loss: 0.2880.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 698.0000\n",
      "Epoch: 4/20.. Loss: 0.2322.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 700.0000\n",
      "Epoch: 4/20.. Loss: 0.2234.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 702.0000\n",
      "Epoch: 4/20.. Loss: 0.2750.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 704.0000\n",
      "Epoch: 4/20.. Loss: 0.2459.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 706.0000\n",
      "Epoch: 4/20.. Loss: 0.2472.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 708.0000\n",
      "Epoch: 4/20.. Loss: 0.2550.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 710.0000\n",
      "Epoch: 4/20.. Loss: 0.2669.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 712.0000\n",
      "Epoch: 4/20.. Loss: 0.2660.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 714.0000\n",
      "Epoch: 4/20.. Loss: 0.2601.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 716.0000\n",
      "Epoch: 4/20.. Loss: 0.2602.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 718.0000\n",
      "Epoch: 4/20.. Loss: 0.2608.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 720.0000\n",
      "Epoch: 4/20.. Loss: 0.2533.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 722.0000\n",
      "Epoch: 4/20.. Loss: 0.2377.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 724.0000\n",
      "Epoch: 4/20.. Loss: 0.2663.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 726.0000\n",
      "Epoch: 4/20.. Loss: 0.2227.. Test accuracy: 0.2801.. 0.0018 s/batch  steps 728.0000\n",
      "Epoch: 4/20.. Loss: 0.1786.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 730.0000\n",
      "Epoch: 4/20.. Loss: 0.2831.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 732.0000\n",
      "Epoch: 4/20.. Loss: 0.2773.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 734.0000\n",
      "Epoch: 4/20.. Loss: 0.2577.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 736.0000\n",
      "Epoch: 4/20.. Loss: 0.2087.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 738.0000\n",
      "Epoch: 4/20.. Loss: 0.2931.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 740.0000\n",
      "Epoch: 4/20.. Loss: 0.2530.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 742.0000\n",
      "Epoch: 4/20.. Loss: 0.3034.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 744.0000\n",
      "Epoch: 4/20.. Loss: 0.2680.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 746.0000\n",
      "Epoch: 4/20.. Loss: 0.2794.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 748.0000\n",
      "Epoch: 4/20.. Loss: 0.2121.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 750.0000\n",
      "Epoch: 4/20.. Loss: 0.2548.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 752.0000\n",
      "Epoch: 4/20.. Loss: 0.1977.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 754.0000\n",
      "Epoch: 4/20.. Loss: 0.2406.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 756.0000\n",
      "Epoch: 4/20.. Loss: 0.2628.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 758.0000\n",
      "Epoch: 4/20.. Loss: 0.2525.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 760.0000\n",
      "Epoch: 5/20.. Loss: 0.2456.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 762.0000\n",
      "Epoch: 5/20.. Loss: 0.2335.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 764.0000\n",
      "Epoch: 5/20.. Loss: 0.2376.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 766.0000\n",
      "Epoch: 5/20.. Loss: 0.1837.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 768.0000\n",
      "Epoch: 5/20.. Loss: 0.2448.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 770.0000\n",
      "Epoch: 5/20.. Loss: 0.2741.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 772.0000\n",
      "Epoch: 5/20.. Loss: 0.2508.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 774.0000\n",
      "Epoch: 5/20.. Loss: 0.2405.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 776.0000\n",
      "Epoch: 5/20.. Loss: 0.2163.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 778.0000\n",
      "Epoch: 5/20.. Loss: 0.2507.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 780.0000\n",
      "Epoch: 5/20.. Loss: 0.2691.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 782.0000\n",
      "Epoch: 5/20.. Loss: 0.2805.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 784.0000\n",
      "Epoch: 5/20.. Loss: 0.2413.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 786.0000\n",
      "Epoch: 5/20.. Loss: 0.2755.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 788.0000\n",
      "Epoch: 5/20.. Loss: 0.2799.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 790.0000\n",
      "Epoch: 5/20.. Loss: 0.2435.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 792.0000\n",
      "Epoch: 5/20.. Loss: 0.2571.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 794.0000\n",
      "Epoch: 5/20.. Loss: 0.3230.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 796.0000\n",
      "Epoch: 5/20.. Loss: 0.2473.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 798.0000\n",
      "Epoch: 5/20.. Loss: 0.2246.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 800.0000\n",
      "Epoch: 5/20.. Loss: 0.2573.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 802.0000\n",
      "Epoch: 5/20.. Loss: 0.2337.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 804.0000\n",
      "Epoch: 5/20.. Loss: 0.2693.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 806.0000\n",
      "Epoch: 5/20.. Loss: 0.2802.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 808.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20.. Loss: 0.2484.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 810.0000\n",
      "Epoch: 5/20.. Loss: 0.1948.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 812.0000\n",
      "Epoch: 5/20.. Loss: 0.2328.. Test accuracy: 0.2801.. 0.0020 s/batch  steps 814.0000\n",
      "Epoch: 5/20.. Loss: 0.2659.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 816.0000\n",
      "Epoch: 5/20.. Loss: 0.2485.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 818.0000\n",
      "Epoch: 5/20.. Loss: 0.2678.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 820.0000\n",
      "Epoch: 5/20.. Loss: 0.2374.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 822.0000\n",
      "Epoch: 5/20.. Loss: 0.1921.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 824.0000\n",
      "Epoch: 5/20.. Loss: 0.2378.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 826.0000\n",
      "Epoch: 5/20.. Loss: 0.2534.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 828.0000\n",
      "Epoch: 5/20.. Loss: 0.2046.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 830.0000\n",
      "Epoch: 5/20.. Loss: 0.2918.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 832.0000\n",
      "Epoch: 5/20.. Loss: 0.2621.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 834.0000\n",
      "Epoch: 5/20.. Loss: 0.2244.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 836.0000\n",
      "Epoch: 5/20.. Loss: 0.2388.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 838.0000\n",
      "Epoch: 5/20.. Loss: 0.2169.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 840.0000\n",
      "Epoch: 5/20.. Loss: 0.2465.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 842.0000\n",
      "Epoch: 5/20.. Loss: 0.2513.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 844.0000\n",
      "Epoch: 5/20.. Loss: 0.2099.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 846.0000\n",
      "Epoch: 5/20.. Loss: 0.2311.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 848.0000\n",
      "Epoch: 5/20.. Loss: 0.2431.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 850.0000\n",
      "Epoch: 5/20.. Loss: 0.1751.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 852.0000\n",
      "Epoch: 5/20.. Loss: 0.2380.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 854.0000\n",
      "Epoch: 5/20.. Loss: 0.2782.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 856.0000\n",
      "Epoch: 5/20.. Loss: 0.2387.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 858.0000\n",
      "Epoch: 5/20.. Loss: 0.2196.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 860.0000\n",
      "Epoch: 5/20.. Loss: 0.2188.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 862.0000\n",
      "Epoch: 5/20.. Loss: 0.2026.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 864.0000\n",
      "Epoch: 5/20.. Loss: 0.2092.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 866.0000\n",
      "Epoch: 5/20.. Loss: 0.2550.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 868.0000\n",
      "Epoch: 5/20.. Loss: 0.2656.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 870.0000\n",
      "Epoch: 5/20.. Loss: 0.2679.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 872.0000\n",
      "Epoch: 5/20.. Loss: 0.2046.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 874.0000\n",
      "Epoch: 5/20.. Loss: 0.2158.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 876.0000\n",
      "Epoch: 5/20.. Loss: 0.2892.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 878.0000\n",
      "Epoch: 5/20.. Loss: 0.2441.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 880.0000\n",
      "Epoch: 5/20.. Loss: 0.2512.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 882.0000\n",
      "Epoch: 5/20.. Loss: 0.2712.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 884.0000\n",
      "Epoch: 5/20.. Loss: 0.2612.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 886.0000\n",
      "Epoch: 5/20.. Loss: 0.2276.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 888.0000\n",
      "Epoch: 5/20.. Loss: 0.2391.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 890.0000\n",
      "Epoch: 5/20.. Loss: 0.2276.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 892.0000\n",
      "Epoch: 5/20.. Loss: 0.2072.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 894.0000\n",
      "Epoch: 5/20.. Loss: 0.2515.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 896.0000\n",
      "Epoch: 5/20.. Loss: 0.2493.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 898.0000\n",
      "Epoch: 5/20.. Loss: 0.2024.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 900.0000\n",
      "Epoch: 5/20.. Loss: 0.2638.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 902.0000\n",
      "Epoch: 5/20.. Loss: 0.2550.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 904.0000\n",
      "Epoch: 5/20.. Loss: 0.2697.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 906.0000\n",
      "Epoch: 5/20.. Loss: 0.2450.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 908.0000\n",
      "Epoch: 5/20.. Loss: 0.2219.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 910.0000\n",
      "Epoch: 5/20.. Loss: 0.2911.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 912.0000\n",
      "Epoch: 5/20.. Loss: 0.2240.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 914.0000\n",
      "Epoch: 5/20.. Loss: 0.2760.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 916.0000\n",
      "Epoch: 5/20.. Loss: 0.2631.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 918.0000\n",
      "Epoch: 5/20.. Loss: 0.2447.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 920.0000\n",
      "Epoch: 5/20.. Loss: 0.2544.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 922.0000\n",
      "Epoch: 5/20.. Loss: 0.2471.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 924.0000\n",
      "Epoch: 5/20.. Loss: 0.1789.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 926.0000\n",
      "Epoch: 5/20.. Loss: 0.2154.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 928.0000\n",
      "Epoch: 5/20.. Loss: 0.1761.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 930.0000\n",
      "Epoch: 5/20.. Loss: 0.2324.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 932.0000\n",
      "Epoch: 5/20.. Loss: 0.2245.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 934.0000\n",
      "Epoch: 5/20.. Loss: 0.2737.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 936.0000\n",
      "Epoch: 5/20.. Loss: 0.2203.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 938.0000\n",
      "Epoch: 5/20.. Loss: 0.2013.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 940.0000\n",
      "Epoch: 5/20.. Loss: 0.2471.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 942.0000\n",
      "Epoch: 5/20.. Loss: 0.2531.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 944.0000\n",
      "Epoch: 5/20.. Loss: 0.2142.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 946.0000\n",
      "Epoch: 5/20.. Loss: 0.2199.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 948.0000\n",
      "Epoch: 5/20.. Loss: 0.2364.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 950.0000\n",
      "Epoch: 6/20.. Loss: 0.1939.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 952.0000\n",
      "Epoch: 6/20.. Loss: 0.2060.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 954.0000\n",
      "Epoch: 6/20.. Loss: 0.2007.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 956.0000\n",
      "Epoch: 6/20.. Loss: 0.2529.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 958.0000\n",
      "Epoch: 6/20.. Loss: 0.2424.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 960.0000\n",
      "Epoch: 6/20.. Loss: 0.2231.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 962.0000\n",
      "Epoch: 6/20.. Loss: 0.2151.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 964.0000\n",
      "Epoch: 6/20.. Loss: 0.2455.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 966.0000\n",
      "Epoch: 6/20.. Loss: 0.2514.. Test accuracy: 0.2801.. 0.0019 s/batch  steps 968.0000\n",
      "Epoch: 6/20.. Loss: 0.1897.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 970.0000\n",
      "Epoch: 6/20.. Loss: 0.2159.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 972.0000\n",
      "Epoch: 6/20.. Loss: 0.2431.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 974.0000\n",
      "Epoch: 6/20.. Loss: 0.2196.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 976.0000\n",
      "Epoch: 6/20.. Loss: 0.2455.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 978.0000\n",
      "Epoch: 6/20.. Loss: 0.2521.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 980.0000\n",
      "Epoch: 6/20.. Loss: 0.2137.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 982.0000\n",
      "Epoch: 6/20.. Loss: 0.2082.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 984.0000\n",
      "Epoch: 6/20.. Loss: 0.1741.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 986.0000\n",
      "Epoch: 6/20.. Loss: 0.1733.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 988.0000\n",
      "Epoch: 6/20.. Loss: 0.2446.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 990.0000\n",
      "Epoch: 6/20.. Loss: 0.2604.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 992.0000\n",
      "Epoch: 6/20.. Loss: 0.2082.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 994.0000\n",
      "Epoch: 6/20.. Loss: 0.2266.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 996.0000\n",
      "Epoch: 6/20.. Loss: 0.2308.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 998.0000\n",
      "Epoch: 6/20.. Loss: 0.2015.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1000.0000\n",
      "Epoch: 6/20.. Loss: 0.2592.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1002.0000\n",
      "Epoch: 6/20.. Loss: 0.3071.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1004.0000\n",
      "Epoch: 6/20.. Loss: 0.2383.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1006.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20.. Loss: 0.2383.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1008.0000\n",
      "Epoch: 6/20.. Loss: 0.1987.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1010.0000\n",
      "Epoch: 6/20.. Loss: 0.2204.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1012.0000\n",
      "Epoch: 6/20.. Loss: 0.2270.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1014.0000\n",
      "Epoch: 6/20.. Loss: 0.2281.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1016.0000\n",
      "Epoch: 6/20.. Loss: 0.1863.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1018.0000\n",
      "Epoch: 6/20.. Loss: 0.2232.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1020.0000\n",
      "Epoch: 6/20.. Loss: 0.3196.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1022.0000\n",
      "Epoch: 6/20.. Loss: 0.2641.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1024.0000\n",
      "Epoch: 6/20.. Loss: 0.2020.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1026.0000\n",
      "Epoch: 6/20.. Loss: 0.2268.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1028.0000\n",
      "Epoch: 6/20.. Loss: 0.2799.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1030.0000\n",
      "Epoch: 6/20.. Loss: 0.2546.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1032.0000\n",
      "Epoch: 6/20.. Loss: 0.2262.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1034.0000\n",
      "Epoch: 6/20.. Loss: 0.2293.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1036.0000\n",
      "Epoch: 6/20.. Loss: 0.2313.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1038.0000\n",
      "Epoch: 6/20.. Loss: 0.2539.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1040.0000\n",
      "Epoch: 6/20.. Loss: 0.2183.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1042.0000\n",
      "Epoch: 6/20.. Loss: 0.1867.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 1044.0000\n",
      "Epoch: 6/20.. Loss: 0.3064.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1046.0000\n",
      "Epoch: 6/20.. Loss: 0.2299.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1048.0000\n",
      "Epoch: 6/20.. Loss: 0.2708.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1050.0000\n",
      "Epoch: 6/20.. Loss: 0.2129.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1052.0000\n",
      "Epoch: 6/20.. Loss: 0.2641.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1054.0000\n",
      "Epoch: 6/20.. Loss: 0.2294.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1056.0000\n",
      "Epoch: 6/20.. Loss: 0.2222.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1058.0000\n",
      "Epoch: 6/20.. Loss: 0.2160.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1060.0000\n",
      "Epoch: 6/20.. Loss: 0.2348.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1062.0000\n",
      "Epoch: 6/20.. Loss: 0.2152.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1064.0000\n",
      "Epoch: 6/20.. Loss: 0.2499.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1066.0000\n",
      "Epoch: 6/20.. Loss: 0.2147.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1068.0000\n",
      "Epoch: 6/20.. Loss: 0.2171.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1070.0000\n",
      "Epoch: 6/20.. Loss: 0.2387.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1072.0000\n",
      "Epoch: 6/20.. Loss: 0.2924.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1074.0000\n",
      "Epoch: 6/20.. Loss: 0.2347.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1076.0000\n",
      "Epoch: 6/20.. Loss: 0.2096.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1078.0000\n",
      "Epoch: 6/20.. Loss: 0.1920.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1080.0000\n",
      "Epoch: 6/20.. Loss: 0.2157.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1082.0000\n",
      "Epoch: 6/20.. Loss: 0.2130.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1084.0000\n",
      "Epoch: 6/20.. Loss: 0.2065.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1086.0000\n",
      "Epoch: 6/20.. Loss: 0.2714.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1088.0000\n",
      "Epoch: 6/20.. Loss: 0.2657.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1090.0000\n",
      "Epoch: 6/20.. Loss: 0.1873.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1092.0000\n",
      "Epoch: 6/20.. Loss: 0.2572.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1094.0000\n",
      "Epoch: 6/20.. Loss: 0.2213.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1096.0000\n",
      "Epoch: 6/20.. Loss: 0.2051.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1098.0000\n",
      "Epoch: 6/20.. Loss: 0.2215.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1100.0000\n",
      "Epoch: 6/20.. Loss: 0.2271.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1102.0000\n",
      "Epoch: 6/20.. Loss: 0.2150.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1104.0000\n",
      "Epoch: 6/20.. Loss: 0.2514.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1106.0000\n",
      "Epoch: 6/20.. Loss: 0.2325.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1108.0000\n",
      "Epoch: 6/20.. Loss: 0.2390.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1110.0000\n",
      "Epoch: 6/20.. Loss: 0.2325.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1112.0000\n",
      "Epoch: 6/20.. Loss: 0.2319.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1114.0000\n",
      "Epoch: 6/20.. Loss: 0.2264.. Test accuracy: 0.2801.. 0.0021 s/batch  steps 1116.0000\n",
      "Epoch: 6/20.. Loss: 0.1986.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1118.0000\n",
      "Epoch: 6/20.. Loss: 0.2625.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1120.0000\n",
      "Epoch: 6/20.. Loss: 0.2630.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1122.0000\n",
      "Epoch: 6/20.. Loss: 0.2579.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1124.0000\n",
      "Epoch: 6/20.. Loss: 0.2467.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1126.0000\n",
      "Epoch: 6/20.. Loss: 0.2567.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1128.0000\n",
      "Epoch: 6/20.. Loss: 0.2378.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1130.0000\n",
      "Epoch: 6/20.. Loss: 0.2169.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1132.0000\n",
      "Epoch: 6/20.. Loss: 0.1493.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1134.0000\n",
      "Epoch: 6/20.. Loss: 0.2355.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1136.0000\n",
      "Epoch: 6/20.. Loss: 0.2258.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1138.0000\n",
      "Epoch: 6/20.. Loss: 0.1925.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1140.0000\n",
      "Epoch: 7/20.. Loss: 0.1869.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 1142.0000\n",
      "Epoch: 7/20.. Loss: 0.2223.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1144.0000\n",
      "Epoch: 7/20.. Loss: 0.2438.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1146.0000\n",
      "Epoch: 7/20.. Loss: 0.2484.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1148.0000\n",
      "Epoch: 7/20.. Loss: 0.2204.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1150.0000\n",
      "Epoch: 7/20.. Loss: 0.1892.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1152.0000\n",
      "Epoch: 7/20.. Loss: 0.2342.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1154.0000\n",
      "Epoch: 7/20.. Loss: 0.1916.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1156.0000\n",
      "Epoch: 7/20.. Loss: 0.2436.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1158.0000\n",
      "Epoch: 7/20.. Loss: 0.2327.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1160.0000\n",
      "Epoch: 7/20.. Loss: 0.3129.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1162.0000\n",
      "Epoch: 7/20.. Loss: 0.2091.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1164.0000\n",
      "Epoch: 7/20.. Loss: 0.2507.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1166.0000\n",
      "Epoch: 7/20.. Loss: 0.2727.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1168.0000\n",
      "Epoch: 7/20.. Loss: 0.2416.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1170.0000\n",
      "Epoch: 7/20.. Loss: 0.1866.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1172.0000\n",
      "Epoch: 7/20.. Loss: 0.2349.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1174.0000\n",
      "Epoch: 7/20.. Loss: 0.1978.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1176.0000\n",
      "Epoch: 7/20.. Loss: 0.2530.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1178.0000\n",
      "Epoch: 7/20.. Loss: 0.2226.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1180.0000\n",
      "Epoch: 7/20.. Loss: 0.2363.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1182.0000\n",
      "Epoch: 7/20.. Loss: 0.2085.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1184.0000\n",
      "Epoch: 7/20.. Loss: 0.2255.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1186.0000\n",
      "Epoch: 7/20.. Loss: 0.2123.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1188.0000\n",
      "Epoch: 7/20.. Loss: 0.2514.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1190.0000\n",
      "Epoch: 7/20.. Loss: 0.2395.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1192.0000\n",
      "Epoch: 7/20.. Loss: 0.2162.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1194.0000\n",
      "Epoch: 7/20.. Loss: 0.2253.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1196.0000\n",
      "Epoch: 7/20.. Loss: 0.2429.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1198.0000\n",
      "Epoch: 7/20.. Loss: 0.2076.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1200.0000\n",
      "Epoch: 7/20.. Loss: 0.2246.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1202.0000\n",
      "Epoch: 7/20.. Loss: 0.1998.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1204.0000\n",
      "Epoch: 7/20.. Loss: 0.2388.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1206.0000\n",
      "Epoch: 7/20.. Loss: 0.2168.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1208.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20.. Loss: 0.2354.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1210.0000\n",
      "Epoch: 7/20.. Loss: 0.1963.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1212.0000\n",
      "Epoch: 7/20.. Loss: 0.2521.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1214.0000\n",
      "Epoch: 7/20.. Loss: 0.2226.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1216.0000\n",
      "Epoch: 7/20.. Loss: 0.2090.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1218.0000\n",
      "Epoch: 7/20.. Loss: 0.2024.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1220.0000\n",
      "Epoch: 7/20.. Loss: 0.2144.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1222.0000\n",
      "Epoch: 7/20.. Loss: 0.2572.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1224.0000\n",
      "Epoch: 7/20.. Loss: 0.2004.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1226.0000\n",
      "Epoch: 7/20.. Loss: 0.1999.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1228.0000\n",
      "Epoch: 7/20.. Loss: 0.1951.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1230.0000\n",
      "Epoch: 7/20.. Loss: 0.2393.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1232.0000\n",
      "Epoch: 7/20.. Loss: 0.2303.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1234.0000\n",
      "Epoch: 7/20.. Loss: 0.2400.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1236.0000\n",
      "Epoch: 7/20.. Loss: 0.2186.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1238.0000\n",
      "Epoch: 7/20.. Loss: 0.2687.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1240.0000\n",
      "Epoch: 7/20.. Loss: 0.2221.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1242.0000\n",
      "Epoch: 7/20.. Loss: 0.2481.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1244.0000\n",
      "Epoch: 7/20.. Loss: 0.2040.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1246.0000\n",
      "Epoch: 7/20.. Loss: 0.2413.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1248.0000\n",
      "Epoch: 7/20.. Loss: 0.2311.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1250.0000\n",
      "Epoch: 7/20.. Loss: 0.1780.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1252.0000\n",
      "Epoch: 7/20.. Loss: 0.2586.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1254.0000\n",
      "Epoch: 7/20.. Loss: 0.2035.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1256.0000\n",
      "Epoch: 7/20.. Loss: 0.2516.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1258.0000\n",
      "Epoch: 7/20.. Loss: 0.1687.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1260.0000\n",
      "Epoch: 7/20.. Loss: 0.2136.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1262.0000\n",
      "Epoch: 7/20.. Loss: 0.2210.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1264.0000\n",
      "Epoch: 7/20.. Loss: 0.2259.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1266.0000\n",
      "Epoch: 7/20.. Loss: 0.2124.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1268.0000\n",
      "Epoch: 7/20.. Loss: 0.2180.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1270.0000\n",
      "Epoch: 7/20.. Loss: 0.2133.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1272.0000\n",
      "Epoch: 7/20.. Loss: 0.2202.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1274.0000\n",
      "Epoch: 7/20.. Loss: 0.2212.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1276.0000\n",
      "Epoch: 7/20.. Loss: 0.2581.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1278.0000\n",
      "Epoch: 7/20.. Loss: 0.2308.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1280.0000\n",
      "Epoch: 7/20.. Loss: 0.1451.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1282.0000\n",
      "Epoch: 7/20.. Loss: 0.1695.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1284.0000\n",
      "Epoch: 7/20.. Loss: 0.2107.. Test accuracy: 0.2801.. 0.0020 s/batch  steps 1286.0000\n",
      "Epoch: 7/20.. Loss: 0.2007.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1288.0000\n",
      "Epoch: 7/20.. Loss: 0.2437.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1290.0000\n",
      "Epoch: 7/20.. Loss: 0.1932.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1292.0000\n",
      "Epoch: 7/20.. Loss: 0.2337.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1294.0000\n",
      "Epoch: 7/20.. Loss: 0.2391.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1296.0000\n",
      "Epoch: 7/20.. Loss: 0.2048.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1298.0000\n",
      "Epoch: 7/20.. Loss: 0.1985.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1300.0000\n",
      "Epoch: 7/20.. Loss: 0.2112.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1302.0000\n",
      "Epoch: 7/20.. Loss: 0.2353.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1304.0000\n",
      "Epoch: 7/20.. Loss: 0.1847.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1306.0000\n",
      "Epoch: 7/20.. Loss: 0.1986.. Test accuracy: 0.2801.. 0.0021 s/batch  steps 1308.0000\n",
      "Epoch: 7/20.. Loss: 0.2195.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1310.0000\n",
      "Epoch: 7/20.. Loss: 0.2349.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1312.0000\n",
      "Epoch: 7/20.. Loss: 0.1973.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1314.0000\n",
      "Epoch: 7/20.. Loss: 0.2272.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1316.0000\n",
      "Epoch: 7/20.. Loss: 0.1667.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1318.0000\n",
      "Epoch: 7/20.. Loss: 0.1865.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1320.0000\n",
      "Epoch: 7/20.. Loss: 0.2748.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1322.0000\n",
      "Epoch: 7/20.. Loss: 0.2440.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1324.0000\n",
      "Epoch: 7/20.. Loss: 0.1669.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 1326.0000\n",
      "Epoch: 7/20.. Loss: 0.2059.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1328.0000\n",
      "Epoch: 7/20.. Loss: 0.2422.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1330.0000\n",
      "Epoch: 8/20.. Loss: 0.1996.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1332.0000\n",
      "Epoch: 8/20.. Loss: 0.1753.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1334.0000\n",
      "Epoch: 8/20.. Loss: 0.2042.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1336.0000\n",
      "Epoch: 8/20.. Loss: 0.1761.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1338.0000\n",
      "Epoch: 8/20.. Loss: 0.1988.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1340.0000\n",
      "Epoch: 8/20.. Loss: 0.2458.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1342.0000\n",
      "Epoch: 8/20.. Loss: 0.2184.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1344.0000\n",
      "Epoch: 8/20.. Loss: 0.2557.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1346.0000\n",
      "Epoch: 8/20.. Loss: 0.2031.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1348.0000\n",
      "Epoch: 8/20.. Loss: 0.1754.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1350.0000\n",
      "Epoch: 8/20.. Loss: 0.2067.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1352.0000\n",
      "Epoch: 8/20.. Loss: 0.1791.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1354.0000\n",
      "Epoch: 8/20.. Loss: 0.1949.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1356.0000\n",
      "Epoch: 8/20.. Loss: 0.2070.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1358.0000\n",
      "Epoch: 8/20.. Loss: 0.2150.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1360.0000\n",
      "Epoch: 8/20.. Loss: 0.2115.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1362.0000\n",
      "Epoch: 8/20.. Loss: 0.1814.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1364.0000\n",
      "Epoch: 8/20.. Loss: 0.2190.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1366.0000\n",
      "Epoch: 8/20.. Loss: 0.2554.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1368.0000\n",
      "Epoch: 8/20.. Loss: 0.1522.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1370.0000\n",
      "Epoch: 8/20.. Loss: 0.1926.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1372.0000\n",
      "Epoch: 8/20.. Loss: 0.1724.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1374.0000\n",
      "Epoch: 8/20.. Loss: 0.2550.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1376.0000\n",
      "Epoch: 8/20.. Loss: 0.2022.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1378.0000\n",
      "Epoch: 8/20.. Loss: 0.2132.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1380.0000\n",
      "Epoch: 8/20.. Loss: 0.1715.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1382.0000\n",
      "Epoch: 8/20.. Loss: 0.1771.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1384.0000\n",
      "Epoch: 8/20.. Loss: 0.2286.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1386.0000\n",
      "Epoch: 8/20.. Loss: 0.2106.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1388.0000\n",
      "Epoch: 8/20.. Loss: 0.1897.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1390.0000\n",
      "Epoch: 8/20.. Loss: 0.2325.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1392.0000\n",
      "Epoch: 8/20.. Loss: 0.2390.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1394.0000\n",
      "Epoch: 8/20.. Loss: 0.1608.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1396.0000\n",
      "Epoch: 8/20.. Loss: 0.2431.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1398.0000\n",
      "Epoch: 8/20.. Loss: 0.2239.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1400.0000\n",
      "Epoch: 8/20.. Loss: 0.2113.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1402.0000\n",
      "Epoch: 8/20.. Loss: 0.1791.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1404.0000\n",
      "Epoch: 8/20.. Loss: 0.2348.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1406.0000\n",
      "Epoch: 8/20.. Loss: 0.2218.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1408.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20.. Loss: 0.2130.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1410.0000\n",
      "Epoch: 8/20.. Loss: 0.2009.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1412.0000\n",
      "Epoch: 8/20.. Loss: 0.2277.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1414.0000\n",
      "Epoch: 8/20.. Loss: 0.2751.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1416.0000\n",
      "Epoch: 8/20.. Loss: 0.2090.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1418.0000\n",
      "Epoch: 8/20.. Loss: 0.1961.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1420.0000\n",
      "Epoch: 8/20.. Loss: 0.2048.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1422.0000\n",
      "Epoch: 8/20.. Loss: 0.2232.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1424.0000\n",
      "Epoch: 8/20.. Loss: 0.2214.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1426.0000\n",
      "Epoch: 8/20.. Loss: 0.2626.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1428.0000\n",
      "Epoch: 8/20.. Loss: 0.2065.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1430.0000\n",
      "Epoch: 8/20.. Loss: 0.1973.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1432.0000\n",
      "Epoch: 8/20.. Loss: 0.2036.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1434.0000\n",
      "Epoch: 8/20.. Loss: 0.2265.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1436.0000\n",
      "Epoch: 8/20.. Loss: 0.2005.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1438.0000\n",
      "Epoch: 8/20.. Loss: 0.2056.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1440.0000\n",
      "Epoch: 8/20.. Loss: 0.1793.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1442.0000\n",
      "Epoch: 8/20.. Loss: 0.2015.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1444.0000\n",
      "Epoch: 8/20.. Loss: 0.2115.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1446.0000\n",
      "Epoch: 8/20.. Loss: 0.2005.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1448.0000\n",
      "Epoch: 8/20.. Loss: 0.2102.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1450.0000\n",
      "Epoch: 8/20.. Loss: 0.2419.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1452.0000\n",
      "Epoch: 8/20.. Loss: 0.2634.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1454.0000\n",
      "Epoch: 8/20.. Loss: 0.1953.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1456.0000\n",
      "Epoch: 8/20.. Loss: 0.1998.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1458.0000\n",
      "Epoch: 8/20.. Loss: 0.2239.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1460.0000\n",
      "Epoch: 8/20.. Loss: 0.2177.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1462.0000\n",
      "Epoch: 8/20.. Loss: 0.2243.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1464.0000\n",
      "Epoch: 8/20.. Loss: 0.2079.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1466.0000\n",
      "Epoch: 8/20.. Loss: 0.1921.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1468.0000\n",
      "Epoch: 8/20.. Loss: 0.2247.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1470.0000\n",
      "Epoch: 8/20.. Loss: 0.1902.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1472.0000\n",
      "Epoch: 8/20.. Loss: 0.1707.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1474.0000\n",
      "Epoch: 8/20.. Loss: 0.2079.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1476.0000\n",
      "Epoch: 8/20.. Loss: 0.2039.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1478.0000\n",
      "Epoch: 8/20.. Loss: 0.2291.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1480.0000\n",
      "Epoch: 8/20.. Loss: 0.2150.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1482.0000\n",
      "Epoch: 8/20.. Loss: 0.1794.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1484.0000\n",
      "Epoch: 8/20.. Loss: 0.2251.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1486.0000\n",
      "Epoch: 8/20.. Loss: 0.1639.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1488.0000\n",
      "Epoch: 8/20.. Loss: 0.2305.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1490.0000\n",
      "Epoch: 8/20.. Loss: 0.2065.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1492.0000\n",
      "Epoch: 8/20.. Loss: 0.1733.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1494.0000\n",
      "Epoch: 8/20.. Loss: 0.2348.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1496.0000\n",
      "Epoch: 8/20.. Loss: 0.2233.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1498.0000\n",
      "Epoch: 8/20.. Loss: 0.2434.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1500.0000\n",
      "Epoch: 8/20.. Loss: 0.1679.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1502.0000\n",
      "Epoch: 8/20.. Loss: 0.1675.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1504.0000\n",
      "Epoch: 8/20.. Loss: 0.2160.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1506.0000\n",
      "Epoch: 8/20.. Loss: 0.1365.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1508.0000\n",
      "Epoch: 8/20.. Loss: 0.1514.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1510.0000\n",
      "Epoch: 8/20.. Loss: 0.2261.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1512.0000\n",
      "Epoch: 8/20.. Loss: 0.2159.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1514.0000\n",
      "Epoch: 8/20.. Loss: 0.1942.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1516.0000\n",
      "Epoch: 8/20.. Loss: 0.1978.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1518.0000\n",
      "Epoch: 8/20.. Loss: 0.1922.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1520.0000\n",
      "Epoch: 9/20.. Loss: 0.1752.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1522.0000\n",
      "Epoch: 9/20.. Loss: 0.1900.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1524.0000\n",
      "Epoch: 9/20.. Loss: 0.2282.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1526.0000\n",
      "Epoch: 9/20.. Loss: 0.2067.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1528.0000\n",
      "Epoch: 9/20.. Loss: 0.2344.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1530.0000\n",
      "Epoch: 9/20.. Loss: 0.1685.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1532.0000\n",
      "Epoch: 9/20.. Loss: 0.2052.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1534.0000\n",
      "Epoch: 9/20.. Loss: 0.1875.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1536.0000\n",
      "Epoch: 9/20.. Loss: 0.2074.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1538.0000\n",
      "Epoch: 9/20.. Loss: 0.2030.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1540.0000\n",
      "Epoch: 9/20.. Loss: 0.1928.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1542.0000\n",
      "Epoch: 9/20.. Loss: 0.1948.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1544.0000\n",
      "Epoch: 9/20.. Loss: 0.2011.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1546.0000\n",
      "Epoch: 9/20.. Loss: 0.2094.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1548.0000\n",
      "Epoch: 9/20.. Loss: 0.2127.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1550.0000\n",
      "Epoch: 9/20.. Loss: 0.1771.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1552.0000\n",
      "Epoch: 9/20.. Loss: 0.2144.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1554.0000\n",
      "Epoch: 9/20.. Loss: 0.2291.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1556.0000\n",
      "Epoch: 9/20.. Loss: 0.2283.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1558.0000\n",
      "Epoch: 9/20.. Loss: 0.2101.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1560.0000\n",
      "Epoch: 9/20.. Loss: 0.1907.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1562.0000\n",
      "Epoch: 9/20.. Loss: 0.1753.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1564.0000\n",
      "Epoch: 9/20.. Loss: 0.1709.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1566.0000\n",
      "Epoch: 9/20.. Loss: 0.1868.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1568.0000\n",
      "Epoch: 9/20.. Loss: 0.2383.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1570.0000\n",
      "Epoch: 9/20.. Loss: 0.2280.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1572.0000\n",
      "Epoch: 9/20.. Loss: 0.2042.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1574.0000\n",
      "Epoch: 9/20.. Loss: 0.1915.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1576.0000\n",
      "Epoch: 9/20.. Loss: 0.1781.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1578.0000\n",
      "Epoch: 9/20.. Loss: 0.2063.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1580.0000\n",
      "Epoch: 9/20.. Loss: 0.1887.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1582.0000\n",
      "Epoch: 9/20.. Loss: 0.1986.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1584.0000\n",
      "Epoch: 9/20.. Loss: 0.1917.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1586.0000\n",
      "Epoch: 9/20.. Loss: 0.2273.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1588.0000\n",
      "Epoch: 9/20.. Loss: 0.2045.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1590.0000\n",
      "Epoch: 9/20.. Loss: 0.1651.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1592.0000\n",
      "Epoch: 9/20.. Loss: 0.2037.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1594.0000\n",
      "Epoch: 9/20.. Loss: 0.2222.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1596.0000\n",
      "Epoch: 9/20.. Loss: 0.2118.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1598.0000\n",
      "Epoch: 9/20.. Loss: 0.2170.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1600.0000\n",
      "Epoch: 9/20.. Loss: 0.2115.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1602.0000\n",
      "Epoch: 9/20.. Loss: 0.2004.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1604.0000\n",
      "Epoch: 9/20.. Loss: 0.1564.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1606.0000\n",
      "Epoch: 9/20.. Loss: 0.1517.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1608.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20.. Loss: 0.2238.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1610.0000\n",
      "Epoch: 9/20.. Loss: 0.1938.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1612.0000\n",
      "Epoch: 9/20.. Loss: 0.2315.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1614.0000\n",
      "Epoch: 9/20.. Loss: 0.1924.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1616.0000\n",
      "Epoch: 9/20.. Loss: 0.2176.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1618.0000\n",
      "Epoch: 9/20.. Loss: 0.2182.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1620.0000\n",
      "Epoch: 9/20.. Loss: 0.1825.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1622.0000\n",
      "Epoch: 9/20.. Loss: 0.1640.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1624.0000\n",
      "Epoch: 9/20.. Loss: 0.1961.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1626.0000\n",
      "Epoch: 9/20.. Loss: 0.1904.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1628.0000\n",
      "Epoch: 9/20.. Loss: 0.2102.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1630.0000\n",
      "Epoch: 9/20.. Loss: 0.2056.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1632.0000\n",
      "Epoch: 9/20.. Loss: 0.2121.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1634.0000\n",
      "Epoch: 9/20.. Loss: 0.1995.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1636.0000\n",
      "Epoch: 9/20.. Loss: 0.1942.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1638.0000\n",
      "Epoch: 9/20.. Loss: 0.2026.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1640.0000\n",
      "Epoch: 9/20.. Loss: 0.1736.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1642.0000\n",
      "Epoch: 9/20.. Loss: 0.2067.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1644.0000\n",
      "Epoch: 9/20.. Loss: 0.1683.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1646.0000\n",
      "Epoch: 9/20.. Loss: 0.1682.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1648.0000\n",
      "Epoch: 9/20.. Loss: 0.2323.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1650.0000\n",
      "Epoch: 9/20.. Loss: 0.1943.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1652.0000\n",
      "Epoch: 9/20.. Loss: 0.1980.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1654.0000\n",
      "Epoch: 9/20.. Loss: 0.1915.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1656.0000\n",
      "Epoch: 9/20.. Loss: 0.1947.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1658.0000\n",
      "Epoch: 9/20.. Loss: 0.2420.. Test accuracy: 0.2801.. 0.0021 s/batch  steps 1660.0000\n",
      "Epoch: 9/20.. Loss: 0.1749.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1662.0000\n",
      "Epoch: 9/20.. Loss: 0.2089.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1664.0000\n",
      "Epoch: 9/20.. Loss: 0.1850.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1666.0000\n",
      "Epoch: 9/20.. Loss: 0.2245.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1668.0000\n",
      "Epoch: 9/20.. Loss: 0.1745.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1670.0000\n",
      "Epoch: 9/20.. Loss: 0.2040.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1672.0000\n",
      "Epoch: 9/20.. Loss: 0.1965.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1674.0000\n",
      "Epoch: 9/20.. Loss: 0.1606.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1676.0000\n",
      "Epoch: 9/20.. Loss: 0.1791.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1678.0000\n",
      "Epoch: 9/20.. Loss: 0.1889.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1680.0000\n",
      "Epoch: 9/20.. Loss: 0.2343.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1682.0000\n",
      "Epoch: 9/20.. Loss: 0.1819.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1684.0000\n",
      "Epoch: 9/20.. Loss: 0.1959.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1686.0000\n",
      "Epoch: 9/20.. Loss: 0.1897.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1688.0000\n",
      "Epoch: 9/20.. Loss: 0.1580.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1690.0000\n",
      "Epoch: 9/20.. Loss: 0.1586.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1692.0000\n",
      "Epoch: 9/20.. Loss: 0.1712.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1694.0000\n",
      "Epoch: 9/20.. Loss: 0.2100.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1696.0000\n",
      "Epoch: 9/20.. Loss: 0.2073.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1698.0000\n",
      "Epoch: 9/20.. Loss: 0.2003.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1700.0000\n",
      "Epoch: 9/20.. Loss: 0.1788.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1702.0000\n",
      "Epoch: 9/20.. Loss: 0.1736.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1704.0000\n",
      "Epoch: 9/20.. Loss: 0.1820.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1706.0000\n",
      "Epoch: 9/20.. Loss: 0.2030.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1708.0000\n",
      "Epoch: 9/20.. Loss: 0.1725.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1710.0000\n",
      "Epoch: 10/20.. Loss: 0.2224.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1712.0000\n",
      "Epoch: 10/20.. Loss: 0.1854.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1714.0000\n",
      "Epoch: 10/20.. Loss: 0.1772.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1716.0000\n",
      "Epoch: 10/20.. Loss: 0.1822.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1718.0000\n",
      "Epoch: 10/20.. Loss: 0.1947.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1720.0000\n",
      "Epoch: 10/20.. Loss: 0.1871.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1722.0000\n",
      "Epoch: 10/20.. Loss: 0.1838.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1724.0000\n",
      "Epoch: 10/20.. Loss: 0.1872.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1726.0000\n",
      "Epoch: 10/20.. Loss: 0.2006.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1728.0000\n",
      "Epoch: 10/20.. Loss: 0.1662.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1730.0000\n",
      "Epoch: 10/20.. Loss: 0.1920.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1732.0000\n",
      "Epoch: 10/20.. Loss: 0.1453.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1734.0000\n",
      "Epoch: 10/20.. Loss: 0.1767.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1736.0000\n",
      "Epoch: 10/20.. Loss: 0.1951.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1738.0000\n",
      "Epoch: 10/20.. Loss: 0.2381.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1740.0000\n",
      "Epoch: 10/20.. Loss: 0.1736.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1742.0000\n",
      "Epoch: 10/20.. Loss: 0.1682.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1744.0000\n",
      "Epoch: 10/20.. Loss: 0.2071.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1746.0000\n",
      "Epoch: 10/20.. Loss: 0.1608.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1748.0000\n",
      "Epoch: 10/20.. Loss: 0.2098.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1750.0000\n",
      "Epoch: 10/20.. Loss: 0.2067.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1752.0000\n",
      "Epoch: 10/20.. Loss: 0.1859.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1754.0000\n",
      "Epoch: 10/20.. Loss: 0.2119.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1756.0000\n",
      "Epoch: 10/20.. Loss: 0.1893.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1758.0000\n",
      "Epoch: 10/20.. Loss: 0.1655.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1760.0000\n",
      "Epoch: 10/20.. Loss: 0.2023.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1762.0000\n",
      "Epoch: 10/20.. Loss: 0.1735.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1764.0000\n",
      "Epoch: 10/20.. Loss: 0.1930.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1766.0000\n",
      "Epoch: 10/20.. Loss: 0.1993.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1768.0000\n",
      "Epoch: 10/20.. Loss: 0.2014.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1770.0000\n",
      "Epoch: 10/20.. Loss: 0.1660.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1772.0000\n",
      "Epoch: 10/20.. Loss: 0.2231.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1774.0000\n",
      "Epoch: 10/20.. Loss: 0.1853.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1776.0000\n",
      "Epoch: 10/20.. Loss: 0.2347.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1778.0000\n",
      "Epoch: 10/20.. Loss: 0.1823.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1780.0000\n",
      "Epoch: 10/20.. Loss: 0.1614.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1782.0000\n",
      "Epoch: 10/20.. Loss: 0.1968.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1784.0000\n",
      "Epoch: 10/20.. Loss: 0.1910.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1786.0000\n",
      "Epoch: 10/20.. Loss: 0.1961.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1788.0000\n",
      "Epoch: 10/20.. Loss: 0.2086.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 1790.0000\n",
      "Epoch: 10/20.. Loss: 0.2093.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1792.0000\n",
      "Epoch: 10/20.. Loss: 0.2273.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1794.0000\n",
      "Epoch: 10/20.. Loss: 0.1695.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1796.0000\n",
      "Epoch: 10/20.. Loss: 0.1683.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1798.0000\n",
      "Epoch: 10/20.. Loss: 0.1322.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1800.0000\n",
      "Epoch: 10/20.. Loss: 0.2007.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1802.0000\n",
      "Epoch: 10/20.. Loss: 0.1772.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1804.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20.. Loss: 0.1401.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1806.0000\n",
      "Epoch: 10/20.. Loss: 0.1672.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1808.0000\n",
      "Epoch: 10/20.. Loss: 0.1822.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1810.0000\n",
      "Epoch: 10/20.. Loss: 0.1528.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1812.0000\n",
      "Epoch: 10/20.. Loss: 0.2101.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1814.0000\n",
      "Epoch: 10/20.. Loss: 0.2029.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1816.0000\n",
      "Epoch: 10/20.. Loss: 0.1708.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1818.0000\n",
      "Epoch: 10/20.. Loss: 0.1402.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1820.0000\n",
      "Epoch: 10/20.. Loss: 0.1669.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1822.0000\n",
      "Epoch: 10/20.. Loss: 0.1871.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1824.0000\n",
      "Epoch: 10/20.. Loss: 0.1880.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1826.0000\n",
      "Epoch: 10/20.. Loss: 0.2077.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1828.0000\n",
      "Epoch: 10/20.. Loss: 0.1874.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1830.0000\n",
      "Epoch: 10/20.. Loss: 0.1763.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1832.0000\n",
      "Epoch: 10/20.. Loss: 0.1967.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1834.0000\n",
      "Epoch: 10/20.. Loss: 0.1884.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1836.0000\n",
      "Epoch: 10/20.. Loss: 0.2503.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1838.0000\n",
      "Epoch: 10/20.. Loss: 0.1729.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1840.0000\n",
      "Epoch: 10/20.. Loss: 0.2064.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1842.0000\n",
      "Epoch: 10/20.. Loss: 0.1513.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1844.0000\n",
      "Epoch: 10/20.. Loss: 0.1759.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1846.0000\n",
      "Epoch: 10/20.. Loss: 0.1949.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1848.0000\n",
      "Epoch: 10/20.. Loss: 0.1559.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1850.0000\n",
      "Epoch: 10/20.. Loss: 0.1864.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1852.0000\n",
      "Epoch: 10/20.. Loss: 0.1712.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1854.0000\n",
      "Epoch: 10/20.. Loss: 0.2064.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1856.0000\n",
      "Epoch: 10/20.. Loss: 0.1520.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1858.0000\n",
      "Epoch: 10/20.. Loss: 0.1752.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1860.0000\n",
      "Epoch: 10/20.. Loss: 0.1759.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1862.0000\n",
      "Epoch: 10/20.. Loss: 0.2158.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1864.0000\n",
      "Epoch: 10/20.. Loss: 0.2053.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1866.0000\n",
      "Epoch: 10/20.. Loss: 0.2106.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1868.0000\n",
      "Epoch: 10/20.. Loss: 0.1982.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1870.0000\n",
      "Epoch: 10/20.. Loss: 0.2157.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1872.0000\n",
      "Epoch: 10/20.. Loss: 0.2112.. Test accuracy: 0.2801.. 0.0018 s/batch  steps 1874.0000\n",
      "Epoch: 10/20.. Loss: 0.1721.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1876.0000\n",
      "Epoch: 10/20.. Loss: 0.2079.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1878.0000\n",
      "Epoch: 10/20.. Loss: 0.1904.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1880.0000\n",
      "Epoch: 10/20.. Loss: 0.1881.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1882.0000\n",
      "Epoch: 10/20.. Loss: 0.1787.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1884.0000\n",
      "Epoch: 10/20.. Loss: 0.1838.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1886.0000\n",
      "Epoch: 10/20.. Loss: 0.2136.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1888.0000\n",
      "Epoch: 10/20.. Loss: 0.1803.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1890.0000\n",
      "Epoch: 10/20.. Loss: 0.1707.. Test accuracy: 0.2801.. 0.0020 s/batch  steps 1892.0000\n",
      "Epoch: 10/20.. Loss: 0.1913.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1894.0000\n",
      "Epoch: 10/20.. Loss: 0.1796.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1896.0000\n",
      "Epoch: 10/20.. Loss: 0.1833.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1898.0000\n",
      "Epoch: 10/20.. Loss: 0.1637.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1900.0000\n",
      "Epoch: 11/20.. Loss: 0.1773.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1902.0000\n",
      "Epoch: 11/20.. Loss: 0.1900.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1904.0000\n",
      "Epoch: 11/20.. Loss: 0.1807.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1906.0000\n",
      "Epoch: 11/20.. Loss: 0.1943.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1908.0000\n",
      "Epoch: 11/20.. Loss: 0.1750.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1910.0000\n",
      "Epoch: 11/20.. Loss: 0.1584.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 1912.0000\n",
      "Epoch: 11/20.. Loss: 0.1900.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1914.0000\n",
      "Epoch: 11/20.. Loss: 0.1556.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1916.0000\n",
      "Epoch: 11/20.. Loss: 0.1951.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1918.0000\n",
      "Epoch: 11/20.. Loss: 0.2096.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1920.0000\n",
      "Epoch: 11/20.. Loss: 0.1787.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1922.0000\n",
      "Epoch: 11/20.. Loss: 0.2147.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1924.0000\n",
      "Epoch: 11/20.. Loss: 0.1688.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1926.0000\n",
      "Epoch: 11/20.. Loss: 0.1797.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1928.0000\n",
      "Epoch: 11/20.. Loss: 0.1994.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1930.0000\n",
      "Epoch: 11/20.. Loss: 0.1820.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1932.0000\n",
      "Epoch: 11/20.. Loss: 0.1787.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1934.0000\n",
      "Epoch: 11/20.. Loss: 0.1530.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1936.0000\n",
      "Epoch: 11/20.. Loss: 0.1604.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1938.0000\n",
      "Epoch: 11/20.. Loss: 0.1641.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1940.0000\n",
      "Epoch: 11/20.. Loss: 0.1690.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1942.0000\n",
      "Epoch: 11/20.. Loss: 0.1726.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1944.0000\n",
      "Epoch: 11/20.. Loss: 0.1629.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 1946.0000\n",
      "Epoch: 11/20.. Loss: 0.1716.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1948.0000\n",
      "Epoch: 11/20.. Loss: 0.1685.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1950.0000\n",
      "Epoch: 11/20.. Loss: 0.2107.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 1952.0000\n",
      "Epoch: 11/20.. Loss: 0.1865.. Test accuracy: 0.2801.. 0.0018 s/batch  steps 1954.0000\n",
      "Epoch: 11/20.. Loss: 0.1760.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1956.0000\n",
      "Epoch: 11/20.. Loss: 0.1629.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1958.0000\n",
      "Epoch: 11/20.. Loss: 0.1878.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1960.0000\n",
      "Epoch: 11/20.. Loss: 0.2106.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1962.0000\n",
      "Epoch: 11/20.. Loss: 0.1770.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1964.0000\n",
      "Epoch: 11/20.. Loss: 0.1865.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1966.0000\n",
      "Epoch: 11/20.. Loss: 0.2002.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 1968.0000\n",
      "Epoch: 11/20.. Loss: 0.2057.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1970.0000\n",
      "Epoch: 11/20.. Loss: 0.1973.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1972.0000\n",
      "Epoch: 11/20.. Loss: 0.1962.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 1974.0000\n",
      "Epoch: 11/20.. Loss: 0.1707.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1976.0000\n",
      "Epoch: 11/20.. Loss: 0.1875.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 1978.0000\n",
      "Epoch: 11/20.. Loss: 0.1841.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1980.0000\n",
      "Epoch: 11/20.. Loss: 0.1978.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1982.0000\n",
      "Epoch: 11/20.. Loss: 0.1881.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 1984.0000\n",
      "Epoch: 11/20.. Loss: 0.1708.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1986.0000\n",
      "Epoch: 11/20.. Loss: 0.1857.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 1988.0000\n",
      "Epoch: 11/20.. Loss: 0.2000.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1990.0000\n",
      "Epoch: 11/20.. Loss: 0.1691.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 1992.0000\n",
      "Epoch: 11/20.. Loss: 0.1709.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 1994.0000\n",
      "Epoch: 11/20.. Loss: 0.1968.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1996.0000\n",
      "Epoch: 11/20.. Loss: 0.1826.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 1998.0000\n",
      "Epoch: 11/20.. Loss: 0.1886.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2000.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20.. Loss: 0.1631.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2002.0000\n",
      "Epoch: 11/20.. Loss: 0.2089.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2004.0000\n",
      "Epoch: 11/20.. Loss: 0.1812.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2006.0000\n",
      "Epoch: 11/20.. Loss: 0.1685.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2008.0000\n",
      "Epoch: 11/20.. Loss: 0.1513.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2010.0000\n",
      "Epoch: 11/20.. Loss: 0.1508.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2012.0000\n",
      "Epoch: 11/20.. Loss: 0.1658.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2014.0000\n",
      "Epoch: 11/20.. Loss: 0.1311.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2016.0000\n",
      "Epoch: 11/20.. Loss: 0.1868.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2018.0000\n",
      "Epoch: 11/20.. Loss: 0.1658.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2020.0000\n",
      "Epoch: 11/20.. Loss: 0.2074.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2022.0000\n",
      "Epoch: 11/20.. Loss: 0.1911.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2024.0000\n",
      "Epoch: 11/20.. Loss: 0.1940.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2026.0000\n",
      "Epoch: 11/20.. Loss: 0.1820.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2028.0000\n",
      "Epoch: 11/20.. Loss: 0.1464.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2030.0000\n",
      "Epoch: 11/20.. Loss: 0.1965.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2032.0000\n",
      "Epoch: 11/20.. Loss: 0.1721.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2034.0000\n",
      "Epoch: 11/20.. Loss: 0.2146.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2036.0000\n",
      "Epoch: 11/20.. Loss: 0.1648.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2038.0000\n",
      "Epoch: 11/20.. Loss: 0.1313.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2040.0000\n",
      "Epoch: 11/20.. Loss: 0.1477.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2042.0000\n",
      "Epoch: 11/20.. Loss: 0.1693.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 2044.0000\n",
      "Epoch: 11/20.. Loss: 0.1811.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2046.0000\n",
      "Epoch: 11/20.. Loss: 0.1742.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2048.0000\n",
      "Epoch: 11/20.. Loss: 0.1515.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2050.0000\n",
      "Epoch: 11/20.. Loss: 0.1728.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2052.0000\n",
      "Epoch: 11/20.. Loss: 0.1760.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2054.0000\n",
      "Epoch: 11/20.. Loss: 0.1586.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2056.0000\n",
      "Epoch: 11/20.. Loss: 0.1536.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2058.0000\n",
      "Epoch: 11/20.. Loss: 0.1230.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2060.0000\n",
      "Epoch: 11/20.. Loss: 0.1935.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2062.0000\n",
      "Epoch: 11/20.. Loss: 0.1563.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2064.0000\n",
      "Epoch: 11/20.. Loss: 0.1397.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2066.0000\n",
      "Epoch: 11/20.. Loss: 0.1774.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2068.0000\n",
      "Epoch: 11/20.. Loss: 0.1555.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2070.0000\n",
      "Epoch: 11/20.. Loss: 0.1889.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 2072.0000\n",
      "Epoch: 11/20.. Loss: 0.1535.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2074.0000\n",
      "Epoch: 11/20.. Loss: 0.1643.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2076.0000\n",
      "Epoch: 11/20.. Loss: 0.1536.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2078.0000\n",
      "Epoch: 11/20.. Loss: 0.2049.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2080.0000\n",
      "Epoch: 11/20.. Loss: 0.1704.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2082.0000\n",
      "Epoch: 11/20.. Loss: 0.1206.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2084.0000\n",
      "Epoch: 11/20.. Loss: 0.1626.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2086.0000\n",
      "Epoch: 11/20.. Loss: 0.2010.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2088.0000\n",
      "Epoch: 11/20.. Loss: 0.1438.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2090.0000\n",
      "Epoch: 12/20.. Loss: 0.1406.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 2092.0000\n",
      "Epoch: 12/20.. Loss: 0.1413.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2094.0000\n",
      "Epoch: 12/20.. Loss: 0.1801.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2096.0000\n",
      "Epoch: 12/20.. Loss: 0.1588.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2098.0000\n",
      "Epoch: 12/20.. Loss: 0.1339.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2100.0000\n",
      "Epoch: 12/20.. Loss: 0.1816.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2102.0000\n",
      "Epoch: 12/20.. Loss: 0.1898.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2104.0000\n",
      "Epoch: 12/20.. Loss: 0.2165.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2106.0000\n",
      "Epoch: 12/20.. Loss: 0.1814.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2108.0000\n",
      "Epoch: 12/20.. Loss: 0.1681.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2110.0000\n",
      "Epoch: 12/20.. Loss: 0.1572.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2112.0000\n",
      "Epoch: 12/20.. Loss: 0.1549.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2114.0000\n",
      "Epoch: 12/20.. Loss: 0.1568.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2116.0000\n",
      "Epoch: 12/20.. Loss: 0.2218.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2118.0000\n",
      "Epoch: 12/20.. Loss: 0.2100.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2120.0000\n",
      "Epoch: 12/20.. Loss: 0.1474.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2122.0000\n",
      "Epoch: 12/20.. Loss: 0.1565.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2124.0000\n",
      "Epoch: 12/20.. Loss: 0.1544.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2126.0000\n",
      "Epoch: 12/20.. Loss: 0.1822.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2128.0000\n",
      "Epoch: 12/20.. Loss: 0.1769.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2130.0000\n",
      "Epoch: 12/20.. Loss: 0.1645.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2132.0000\n",
      "Epoch: 12/20.. Loss: 0.1612.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2134.0000\n",
      "Epoch: 12/20.. Loss: 0.1730.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 2136.0000\n",
      "Epoch: 12/20.. Loss: 0.1524.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2138.0000\n",
      "Epoch: 12/20.. Loss: 0.1442.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2140.0000\n",
      "Epoch: 12/20.. Loss: 0.1361.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2142.0000\n",
      "Epoch: 12/20.. Loss: 0.1951.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2144.0000\n",
      "Epoch: 12/20.. Loss: 0.1604.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2146.0000\n",
      "Epoch: 12/20.. Loss: 0.1739.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 2148.0000\n",
      "Epoch: 12/20.. Loss: 0.2107.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2150.0000\n",
      "Epoch: 12/20.. Loss: 0.1715.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2152.0000\n",
      "Epoch: 12/20.. Loss: 0.1649.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2154.0000\n",
      "Epoch: 12/20.. Loss: 0.1593.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2156.0000\n",
      "Epoch: 12/20.. Loss: 0.1664.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2158.0000\n",
      "Epoch: 12/20.. Loss: 0.1932.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2160.0000\n",
      "Epoch: 12/20.. Loss: 0.1670.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2162.0000\n",
      "Epoch: 12/20.. Loss: 0.1989.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2164.0000\n",
      "Epoch: 12/20.. Loss: 0.1728.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2166.0000\n",
      "Epoch: 12/20.. Loss: 0.1363.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2168.0000\n",
      "Epoch: 12/20.. Loss: 0.1574.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2170.0000\n",
      "Epoch: 12/20.. Loss: 0.1968.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 2172.0000\n",
      "Epoch: 12/20.. Loss: 0.1514.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2174.0000\n",
      "Epoch: 12/20.. Loss: 0.1919.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2176.0000\n",
      "Epoch: 12/20.. Loss: 0.1455.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2178.0000\n",
      "Epoch: 12/20.. Loss: 0.1608.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2180.0000\n",
      "Epoch: 12/20.. Loss: 0.1281.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2182.0000\n",
      "Epoch: 12/20.. Loss: 0.1813.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2184.0000\n",
      "Epoch: 12/20.. Loss: 0.1634.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2186.0000\n",
      "Epoch: 12/20.. Loss: 0.1510.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2188.0000\n",
      "Epoch: 12/20.. Loss: 0.1850.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2190.0000\n",
      "Epoch: 12/20.. Loss: 0.1522.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2192.0000\n",
      "Epoch: 12/20.. Loss: 0.1728.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2194.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20.. Loss: 0.1907.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2196.0000\n",
      "Epoch: 12/20.. Loss: 0.1638.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2198.0000\n",
      "Epoch: 12/20.. Loss: 0.1570.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2200.0000\n",
      "Epoch: 12/20.. Loss: 0.1416.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2202.0000\n",
      "Epoch: 12/20.. Loss: 0.1688.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2204.0000\n",
      "Epoch: 12/20.. Loss: 0.1652.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2206.0000\n",
      "Epoch: 12/20.. Loss: 0.1669.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2208.0000\n",
      "Epoch: 12/20.. Loss: 0.1787.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2210.0000\n",
      "Epoch: 12/20.. Loss: 0.1488.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2212.0000\n",
      "Epoch: 12/20.. Loss: 0.1669.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2214.0000\n",
      "Epoch: 12/20.. Loss: 0.1768.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2216.0000\n",
      "Epoch: 12/20.. Loss: 0.1753.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2218.0000\n",
      "Epoch: 12/20.. Loss: 0.1668.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2220.0000\n",
      "Epoch: 12/20.. Loss: 0.1430.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2222.0000\n",
      "Epoch: 12/20.. Loss: 0.1875.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2224.0000\n",
      "Epoch: 12/20.. Loss: 0.1736.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2226.0000\n",
      "Epoch: 12/20.. Loss: 0.1327.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2228.0000\n",
      "Epoch: 12/20.. Loss: 0.1839.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2230.0000\n",
      "Epoch: 12/20.. Loss: 0.1524.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2232.0000\n",
      "Epoch: 12/20.. Loss: 0.1988.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2234.0000\n",
      "Epoch: 12/20.. Loss: 0.1555.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2236.0000\n",
      "Epoch: 12/20.. Loss: 0.1466.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2238.0000\n",
      "Epoch: 12/20.. Loss: 0.1296.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2240.0000\n",
      "Epoch: 12/20.. Loss: 0.1424.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2242.0000\n",
      "Epoch: 12/20.. Loss: 0.1939.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2244.0000\n",
      "Epoch: 12/20.. Loss: 0.1759.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2246.0000\n",
      "Epoch: 12/20.. Loss: 0.2168.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2248.0000\n",
      "Epoch: 12/20.. Loss: 0.2197.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2250.0000\n",
      "Epoch: 12/20.. Loss: 0.1489.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2252.0000\n",
      "Epoch: 12/20.. Loss: 0.1720.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2254.0000\n",
      "Epoch: 12/20.. Loss: 0.1222.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2256.0000\n",
      "Epoch: 12/20.. Loss: 0.1729.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2258.0000\n",
      "Epoch: 12/20.. Loss: 0.1436.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2260.0000\n",
      "Epoch: 12/20.. Loss: 0.1801.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2262.0000\n",
      "Epoch: 12/20.. Loss: 0.1556.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2264.0000\n",
      "Epoch: 12/20.. Loss: 0.1594.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2266.0000\n",
      "Epoch: 12/20.. Loss: 0.1506.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2268.0000\n",
      "Epoch: 12/20.. Loss: 0.1414.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2270.0000\n",
      "Epoch: 12/20.. Loss: 0.1508.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2272.0000\n",
      "Epoch: 12/20.. Loss: 0.1543.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2274.0000\n",
      "Epoch: 12/20.. Loss: 0.1819.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2276.0000\n",
      "Epoch: 12/20.. Loss: 0.1440.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2278.0000\n",
      "Epoch: 12/20.. Loss: 0.1689.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2280.0000\n",
      "Epoch: 13/20.. Loss: 0.1451.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2282.0000\n",
      "Epoch: 13/20.. Loss: 0.1333.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2284.0000\n",
      "Epoch: 13/20.. Loss: 0.1525.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2286.0000\n",
      "Epoch: 13/20.. Loss: 0.1649.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2288.0000\n",
      "Epoch: 13/20.. Loss: 0.2241.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2290.0000\n",
      "Epoch: 13/20.. Loss: 0.1373.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2292.0000\n",
      "Epoch: 13/20.. Loss: 0.1621.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2294.0000\n",
      "Epoch: 13/20.. Loss: 0.1828.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 2296.0000\n",
      "Epoch: 13/20.. Loss: 0.1707.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2298.0000\n",
      "Epoch: 13/20.. Loss: 0.1542.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2300.0000\n",
      "Epoch: 13/20.. Loss: 0.1808.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2302.0000\n",
      "Epoch: 13/20.. Loss: 0.1730.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2304.0000\n",
      "Epoch: 13/20.. Loss: 0.1777.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2306.0000\n",
      "Epoch: 13/20.. Loss: 0.1807.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2308.0000\n",
      "Epoch: 13/20.. Loss: 0.1776.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2310.0000\n",
      "Epoch: 13/20.. Loss: 0.1829.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2312.0000\n",
      "Epoch: 13/20.. Loss: 0.1705.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2314.0000\n",
      "Epoch: 13/20.. Loss: 0.1473.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2316.0000\n",
      "Epoch: 13/20.. Loss: 0.1662.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2318.0000\n",
      "Epoch: 13/20.. Loss: 0.1753.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2320.0000\n",
      "Epoch: 13/20.. Loss: 0.1703.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2322.0000\n",
      "Epoch: 13/20.. Loss: 0.2080.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2324.0000\n",
      "Epoch: 13/20.. Loss: 0.1748.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2326.0000\n",
      "Epoch: 13/20.. Loss: 0.1621.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2328.0000\n",
      "Epoch: 13/20.. Loss: 0.1613.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2330.0000\n",
      "Epoch: 13/20.. Loss: 0.1731.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2332.0000\n",
      "Epoch: 13/20.. Loss: 0.1548.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2334.0000\n",
      "Epoch: 13/20.. Loss: 0.1683.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2336.0000\n",
      "Epoch: 13/20.. Loss: 0.1648.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2338.0000\n",
      "Epoch: 13/20.. Loss: 0.1460.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2340.0000\n",
      "Epoch: 13/20.. Loss: 0.1750.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2342.0000\n",
      "Epoch: 13/20.. Loss: 0.1236.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2344.0000\n",
      "Epoch: 13/20.. Loss: 0.1349.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2346.0000\n",
      "Epoch: 13/20.. Loss: 0.1162.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2348.0000\n",
      "Epoch: 13/20.. Loss: 0.1337.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2350.0000\n",
      "Epoch: 13/20.. Loss: 0.1580.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2352.0000\n",
      "Epoch: 13/20.. Loss: 0.2094.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2354.0000\n",
      "Epoch: 13/20.. Loss: 0.1352.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2356.0000\n",
      "Epoch: 13/20.. Loss: 0.1611.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2358.0000\n",
      "Epoch: 13/20.. Loss: 0.2094.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2360.0000\n",
      "Epoch: 13/20.. Loss: 0.1189.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2362.0000\n",
      "Epoch: 13/20.. Loss: 0.1456.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2364.0000\n",
      "Epoch: 13/20.. Loss: 0.1703.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2366.0000\n",
      "Epoch: 13/20.. Loss: 0.1211.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2368.0000\n",
      "Epoch: 13/20.. Loss: 0.1689.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2370.0000\n",
      "Epoch: 13/20.. Loss: 0.1664.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2372.0000\n",
      "Epoch: 13/20.. Loss: 0.1801.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2374.0000\n",
      "Epoch: 13/20.. Loss: 0.1552.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2376.0000\n",
      "Epoch: 13/20.. Loss: 0.1716.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2378.0000\n",
      "Epoch: 13/20.. Loss: 0.1748.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2380.0000\n",
      "Epoch: 13/20.. Loss: 0.1658.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2382.0000\n",
      "Epoch: 13/20.. Loss: 0.1515.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2384.0000\n",
      "Epoch: 13/20.. Loss: 0.1682.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2386.0000\n",
      "Epoch: 13/20.. Loss: 0.1829.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2388.0000\n",
      "Epoch: 13/20.. Loss: 0.1378.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2390.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20.. Loss: 0.1482.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2392.0000\n",
      "Epoch: 13/20.. Loss: 0.1807.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2394.0000\n",
      "Epoch: 13/20.. Loss: 0.1282.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2396.0000\n",
      "Epoch: 13/20.. Loss: 0.1536.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2398.0000\n",
      "Epoch: 13/20.. Loss: 0.1742.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2400.0000\n",
      "Epoch: 13/20.. Loss: 0.1416.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2402.0000\n",
      "Epoch: 13/20.. Loss: 0.1504.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2404.0000\n",
      "Epoch: 13/20.. Loss: 0.1630.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2406.0000\n",
      "Epoch: 13/20.. Loss: 0.1542.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2408.0000\n",
      "Epoch: 13/20.. Loss: 0.1823.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2410.0000\n",
      "Epoch: 13/20.. Loss: 0.1460.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2412.0000\n",
      "Epoch: 13/20.. Loss: 0.1611.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2414.0000\n",
      "Epoch: 13/20.. Loss: 0.1475.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2416.0000\n",
      "Epoch: 13/20.. Loss: 0.1516.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2418.0000\n",
      "Epoch: 13/20.. Loss: 0.1709.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2420.0000\n",
      "Epoch: 13/20.. Loss: 0.1409.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2422.0000\n",
      "Epoch: 13/20.. Loss: 0.1631.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2424.0000\n",
      "Epoch: 13/20.. Loss: 0.1605.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2426.0000\n",
      "Epoch: 13/20.. Loss: 0.1705.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2428.0000\n",
      "Epoch: 13/20.. Loss: 0.1376.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2430.0000\n",
      "Epoch: 13/20.. Loss: 0.1361.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 2432.0000\n",
      "Epoch: 13/20.. Loss: 0.1523.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2434.0000\n",
      "Epoch: 13/20.. Loss: 0.1826.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2436.0000\n",
      "Epoch: 13/20.. Loss: 0.1747.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2438.0000\n",
      "Epoch: 13/20.. Loss: 0.1626.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2440.0000\n",
      "Epoch: 13/20.. Loss: 0.1527.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2442.0000\n",
      "Epoch: 13/20.. Loss: 0.1681.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2444.0000\n",
      "Epoch: 13/20.. Loss: 0.1685.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 2446.0000\n",
      "Epoch: 13/20.. Loss: 0.1786.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2448.0000\n",
      "Epoch: 13/20.. Loss: 0.1329.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2450.0000\n",
      "Epoch: 13/20.. Loss: 0.1420.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2452.0000\n",
      "Epoch: 13/20.. Loss: 0.1353.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2454.0000\n",
      "Epoch: 13/20.. Loss: 0.1637.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2456.0000\n",
      "Epoch: 13/20.. Loss: 0.2063.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2458.0000\n",
      "Epoch: 13/20.. Loss: 0.1654.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2460.0000\n",
      "Epoch: 13/20.. Loss: 0.1534.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2462.0000\n",
      "Epoch: 13/20.. Loss: 0.1426.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2464.0000\n",
      "Epoch: 13/20.. Loss: 0.1523.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2466.0000\n",
      "Epoch: 13/20.. Loss: 0.1776.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2468.0000\n",
      "Epoch: 13/20.. Loss: 0.1340.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2470.0000\n",
      "Epoch: 14/20.. Loss: 0.2005.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2472.0000\n",
      "Epoch: 14/20.. Loss: 0.1440.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2474.0000\n",
      "Epoch: 14/20.. Loss: 0.1763.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2476.0000\n",
      "Epoch: 14/20.. Loss: 0.1471.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2478.0000\n",
      "Epoch: 14/20.. Loss: 0.1423.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2480.0000\n",
      "Epoch: 14/20.. Loss: 0.1360.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2482.0000\n",
      "Epoch: 14/20.. Loss: 0.1267.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2484.0000\n",
      "Epoch: 14/20.. Loss: 0.1885.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2486.0000\n",
      "Epoch: 14/20.. Loss: 0.1700.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2488.0000\n",
      "Epoch: 14/20.. Loss: 0.1707.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2490.0000\n",
      "Epoch: 14/20.. Loss: 0.1858.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2492.0000\n",
      "Epoch: 14/20.. Loss: 0.1247.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2494.0000\n",
      "Epoch: 14/20.. Loss: 0.1913.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2496.0000\n",
      "Epoch: 14/20.. Loss: 0.1388.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2498.0000\n",
      "Epoch: 14/20.. Loss: 0.1661.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2500.0000\n",
      "Epoch: 14/20.. Loss: 0.1572.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2502.0000\n",
      "Epoch: 14/20.. Loss: 0.1361.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2504.0000\n",
      "Epoch: 14/20.. Loss: 0.1275.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2506.0000\n",
      "Epoch: 14/20.. Loss: 0.1565.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2508.0000\n",
      "Epoch: 14/20.. Loss: 0.1569.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2510.0000\n",
      "Epoch: 14/20.. Loss: 0.1530.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2512.0000\n",
      "Epoch: 14/20.. Loss: 0.1597.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2514.0000\n",
      "Epoch: 14/20.. Loss: 0.1468.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2516.0000\n",
      "Epoch: 14/20.. Loss: 0.1499.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2518.0000\n",
      "Epoch: 14/20.. Loss: 0.1628.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2520.0000\n",
      "Epoch: 14/20.. Loss: 0.1521.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2522.0000\n",
      "Epoch: 14/20.. Loss: 0.1450.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2524.0000\n",
      "Epoch: 14/20.. Loss: 0.1491.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2526.0000\n",
      "Epoch: 14/20.. Loss: 0.1714.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2528.0000\n",
      "Epoch: 14/20.. Loss: 0.1562.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2530.0000\n",
      "Epoch: 14/20.. Loss: 0.1712.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2532.0000\n",
      "Epoch: 14/20.. Loss: 0.1591.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2534.0000\n",
      "Epoch: 14/20.. Loss: 0.1407.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2536.0000\n",
      "Epoch: 14/20.. Loss: 0.1372.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2538.0000\n",
      "Epoch: 14/20.. Loss: 0.1264.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2540.0000\n",
      "Epoch: 14/20.. Loss: 0.1686.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2542.0000\n",
      "Epoch: 14/20.. Loss: 0.1320.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2544.0000\n",
      "Epoch: 14/20.. Loss: 0.1930.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2546.0000\n",
      "Epoch: 14/20.. Loss: 0.1623.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2548.0000\n",
      "Epoch: 14/20.. Loss: 0.1219.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2550.0000\n",
      "Epoch: 14/20.. Loss: 0.1423.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2552.0000\n",
      "Epoch: 14/20.. Loss: 0.1729.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2554.0000\n",
      "Epoch: 14/20.. Loss: 0.1801.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2556.0000\n",
      "Epoch: 14/20.. Loss: 0.1330.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2558.0000\n",
      "Epoch: 14/20.. Loss: 0.1537.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2560.0000\n",
      "Epoch: 14/20.. Loss: 0.1418.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2562.0000\n",
      "Epoch: 14/20.. Loss: 0.1391.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2564.0000\n",
      "Epoch: 14/20.. Loss: 0.1581.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2566.0000\n",
      "Epoch: 14/20.. Loss: 0.1927.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2568.0000\n",
      "Epoch: 14/20.. Loss: 0.1835.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2570.0000\n",
      "Epoch: 14/20.. Loss: 0.1391.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2572.0000\n",
      "Epoch: 14/20.. Loss: 0.1766.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2574.0000\n",
      "Epoch: 14/20.. Loss: 0.1862.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2576.0000\n",
      "Epoch: 14/20.. Loss: 0.1651.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2578.0000\n",
      "Epoch: 14/20.. Loss: 0.1694.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2580.0000\n",
      "Epoch: 14/20.. Loss: 0.1237.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2582.0000\n",
      "Epoch: 14/20.. Loss: 0.1358.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2584.0000\n",
      "Epoch: 14/20.. Loss: 0.1856.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2586.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20.. Loss: 0.1347.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2588.0000\n",
      "Epoch: 14/20.. Loss: 0.1296.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2590.0000\n",
      "Epoch: 14/20.. Loss: 0.1299.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2592.0000\n",
      "Epoch: 14/20.. Loss: 0.1518.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2594.0000\n",
      "Epoch: 14/20.. Loss: 0.1817.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2596.0000\n",
      "Epoch: 14/20.. Loss: 0.1829.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2598.0000\n",
      "Epoch: 14/20.. Loss: 0.1479.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2600.0000\n",
      "Epoch: 14/20.. Loss: 0.1570.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2602.0000\n",
      "Epoch: 14/20.. Loss: 0.1548.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2604.0000\n",
      "Epoch: 14/20.. Loss: 0.1395.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2606.0000\n",
      "Epoch: 14/20.. Loss: 0.1593.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2608.0000\n",
      "Epoch: 14/20.. Loss: 0.1624.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2610.0000\n",
      "Epoch: 14/20.. Loss: 0.1449.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2612.0000\n",
      "Epoch: 14/20.. Loss: 0.1988.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2614.0000\n",
      "Epoch: 14/20.. Loss: 0.1493.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2616.0000\n",
      "Epoch: 14/20.. Loss: 0.1507.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2618.0000\n",
      "Epoch: 14/20.. Loss: 0.1312.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2620.0000\n",
      "Epoch: 14/20.. Loss: 0.1457.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2622.0000\n",
      "Epoch: 14/20.. Loss: 0.1344.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2624.0000\n",
      "Epoch: 14/20.. Loss: 0.1408.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2626.0000\n",
      "Epoch: 14/20.. Loss: 0.1481.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2628.0000\n",
      "Epoch: 14/20.. Loss: 0.1601.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2630.0000\n",
      "Epoch: 14/20.. Loss: 0.1185.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2632.0000\n",
      "Epoch: 14/20.. Loss: 0.1718.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2634.0000\n",
      "Epoch: 14/20.. Loss: 0.1154.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2636.0000\n",
      "Epoch: 14/20.. Loss: 0.1527.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2638.0000\n",
      "Epoch: 14/20.. Loss: 0.1518.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2640.0000\n",
      "Epoch: 14/20.. Loss: 0.1425.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2642.0000\n",
      "Epoch: 14/20.. Loss: 0.1378.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2644.0000\n",
      "Epoch: 14/20.. Loss: 0.1292.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2646.0000\n",
      "Epoch: 14/20.. Loss: 0.1441.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2648.0000\n",
      "Epoch: 14/20.. Loss: 0.1795.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2650.0000\n",
      "Epoch: 14/20.. Loss: 0.1591.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2652.0000\n",
      "Epoch: 14/20.. Loss: 0.1193.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2654.0000\n",
      "Epoch: 14/20.. Loss: 0.1854.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2656.0000\n",
      "Epoch: 14/20.. Loss: 0.1806.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2658.0000\n",
      "Epoch: 14/20.. Loss: 0.1404.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2660.0000\n",
      "Epoch: 15/20.. Loss: 0.1639.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2662.0000\n",
      "Epoch: 15/20.. Loss: 0.1762.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2664.0000\n",
      "Epoch: 15/20.. Loss: 0.1088.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2666.0000\n",
      "Epoch: 15/20.. Loss: 0.1583.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2668.0000\n",
      "Epoch: 15/20.. Loss: 0.1534.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2670.0000\n",
      "Epoch: 15/20.. Loss: 0.1520.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2672.0000\n",
      "Epoch: 15/20.. Loss: 0.1162.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2674.0000\n",
      "Epoch: 15/20.. Loss: 0.1777.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2676.0000\n",
      "Epoch: 15/20.. Loss: 0.1713.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2678.0000\n",
      "Epoch: 15/20.. Loss: 0.1626.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2680.0000\n",
      "Epoch: 15/20.. Loss: 0.1329.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2682.0000\n",
      "Epoch: 15/20.. Loss: 0.1695.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2684.0000\n",
      "Epoch: 15/20.. Loss: 0.1505.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2686.0000\n",
      "Epoch: 15/20.. Loss: 0.1587.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2688.0000\n",
      "Epoch: 15/20.. Loss: 0.1143.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2690.0000\n",
      "Epoch: 15/20.. Loss: 0.1356.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2692.0000\n",
      "Epoch: 15/20.. Loss: 0.1289.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 2694.0000\n",
      "Epoch: 15/20.. Loss: 0.1426.. Test accuracy: 0.2801.. 0.0021 s/batch  steps 2696.0000\n",
      "Epoch: 15/20.. Loss: 0.1502.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2698.0000\n",
      "Epoch: 15/20.. Loss: 0.1505.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2700.0000\n",
      "Epoch: 15/20.. Loss: 0.1830.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2702.0000\n",
      "Epoch: 15/20.. Loss: 0.1722.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 2704.0000\n",
      "Epoch: 15/20.. Loss: 0.1393.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2706.0000\n",
      "Epoch: 15/20.. Loss: 0.1353.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2708.0000\n",
      "Epoch: 15/20.. Loss: 0.1541.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 2710.0000\n",
      "Epoch: 15/20.. Loss: 0.1676.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2712.0000\n",
      "Epoch: 15/20.. Loss: 0.1423.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 2714.0000\n",
      "Epoch: 15/20.. Loss: 0.1542.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2716.0000\n",
      "Epoch: 15/20.. Loss: 0.1493.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 2718.0000\n",
      "Epoch: 15/20.. Loss: 0.1269.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2720.0000\n",
      "Epoch: 15/20.. Loss: 0.1427.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2722.0000\n",
      "Epoch: 15/20.. Loss: 0.1616.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2724.0000\n",
      "Epoch: 15/20.. Loss: 0.1550.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2726.0000\n",
      "Epoch: 15/20.. Loss: 0.1570.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2728.0000\n",
      "Epoch: 15/20.. Loss: 0.1703.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2730.0000\n",
      "Epoch: 15/20.. Loss: 0.1594.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2732.0000\n",
      "Epoch: 15/20.. Loss: 0.1655.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2734.0000\n",
      "Epoch: 15/20.. Loss: 0.1553.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2736.0000\n",
      "Epoch: 15/20.. Loss: 0.1519.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2738.0000\n",
      "Epoch: 15/20.. Loss: 0.1513.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2740.0000\n",
      "Epoch: 15/20.. Loss: 0.1646.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2742.0000\n",
      "Epoch: 15/20.. Loss: 0.1353.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2744.0000\n",
      "Epoch: 15/20.. Loss: 0.1554.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2746.0000\n",
      "Epoch: 15/20.. Loss: 0.1574.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2748.0000\n",
      "Epoch: 15/20.. Loss: 0.1487.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2750.0000\n",
      "Epoch: 15/20.. Loss: 0.1888.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2752.0000\n",
      "Epoch: 15/20.. Loss: 0.1508.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2754.0000\n",
      "Epoch: 15/20.. Loss: 0.1338.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2756.0000\n",
      "Epoch: 15/20.. Loss: 0.1102.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2758.0000\n",
      "Epoch: 15/20.. Loss: 0.1395.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2760.0000\n",
      "Epoch: 15/20.. Loss: 0.1213.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2762.0000\n",
      "Epoch: 15/20.. Loss: 0.1470.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2764.0000\n",
      "Epoch: 15/20.. Loss: 0.1491.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2766.0000\n",
      "Epoch: 15/20.. Loss: 0.1503.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2768.0000\n",
      "Epoch: 15/20.. Loss: 0.1471.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2770.0000\n",
      "Epoch: 15/20.. Loss: 0.1411.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2772.0000\n",
      "Epoch: 15/20.. Loss: 0.1721.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2774.0000\n",
      "Epoch: 15/20.. Loss: 0.1600.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2776.0000\n",
      "Epoch: 15/20.. Loss: 0.1306.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2778.0000\n",
      "Epoch: 15/20.. Loss: 0.1376.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2780.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20.. Loss: 0.1961.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2782.0000\n",
      "Epoch: 15/20.. Loss: 0.1496.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2784.0000\n",
      "Epoch: 15/20.. Loss: 0.1380.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2786.0000\n",
      "Epoch: 15/20.. Loss: 0.1303.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2788.0000\n",
      "Epoch: 15/20.. Loss: 0.1159.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2790.0000\n",
      "Epoch: 15/20.. Loss: 0.1268.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2792.0000\n",
      "Epoch: 15/20.. Loss: 0.1341.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2794.0000\n",
      "Epoch: 15/20.. Loss: 0.1656.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2796.0000\n",
      "Epoch: 15/20.. Loss: 0.1473.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2798.0000\n",
      "Epoch: 15/20.. Loss: 0.1528.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2800.0000\n",
      "Epoch: 15/20.. Loss: 0.1449.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2802.0000\n",
      "Epoch: 15/20.. Loss: 0.1421.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2804.0000\n",
      "Epoch: 15/20.. Loss: 0.1609.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2806.0000\n",
      "Epoch: 15/20.. Loss: 0.1706.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2808.0000\n",
      "Epoch: 15/20.. Loss: 0.1310.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2810.0000\n",
      "Epoch: 15/20.. Loss: 0.1486.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2812.0000\n",
      "Epoch: 15/20.. Loss: 0.1369.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2814.0000\n",
      "Epoch: 15/20.. Loss: 0.1243.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2816.0000\n",
      "Epoch: 15/20.. Loss: 0.1289.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2818.0000\n",
      "Epoch: 15/20.. Loss: 0.1546.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2820.0000\n",
      "Epoch: 15/20.. Loss: 0.1356.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2822.0000\n",
      "Epoch: 15/20.. Loss: 0.1494.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2824.0000\n",
      "Epoch: 15/20.. Loss: 0.1649.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2826.0000\n",
      "Epoch: 15/20.. Loss: 0.1279.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2828.0000\n",
      "Epoch: 15/20.. Loss: 0.1420.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2830.0000\n",
      "Epoch: 15/20.. Loss: 0.1183.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2832.0000\n",
      "Epoch: 15/20.. Loss: 0.1199.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2834.0000\n",
      "Epoch: 15/20.. Loss: 0.1319.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2836.0000\n",
      "Epoch: 15/20.. Loss: 0.1596.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2838.0000\n",
      "Epoch: 15/20.. Loss: 0.1650.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2840.0000\n",
      "Epoch: 15/20.. Loss: 0.1214.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2842.0000\n",
      "Epoch: 15/20.. Loss: 0.1360.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2844.0000\n",
      "Epoch: 15/20.. Loss: 0.1571.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2846.0000\n",
      "Epoch: 15/20.. Loss: 0.1339.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2848.0000\n",
      "Epoch: 15/20.. Loss: 0.1478.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2850.0000\n",
      "Epoch: 16/20.. Loss: 0.1138.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2852.0000\n",
      "Epoch: 16/20.. Loss: 0.1419.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2854.0000\n",
      "Epoch: 16/20.. Loss: 0.1393.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2856.0000\n",
      "Epoch: 16/20.. Loss: 0.1287.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 2858.0000\n",
      "Epoch: 16/20.. Loss: 0.1554.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2860.0000\n",
      "Epoch: 16/20.. Loss: 0.1683.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2862.0000\n",
      "Epoch: 16/20.. Loss: 0.1491.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2864.0000\n",
      "Epoch: 16/20.. Loss: 0.1112.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2866.0000\n",
      "Epoch: 16/20.. Loss: 0.1443.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2868.0000\n",
      "Epoch: 16/20.. Loss: 0.1431.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2870.0000\n",
      "Epoch: 16/20.. Loss: 0.1392.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2872.0000\n",
      "Epoch: 16/20.. Loss: 0.1643.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 2874.0000\n",
      "Epoch: 16/20.. Loss: 0.1484.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2876.0000\n",
      "Epoch: 16/20.. Loss: 0.1329.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2878.0000\n",
      "Epoch: 16/20.. Loss: 0.1282.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2880.0000\n",
      "Epoch: 16/20.. Loss: 0.1404.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2882.0000\n",
      "Epoch: 16/20.. Loss: 0.1148.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2884.0000\n",
      "Epoch: 16/20.. Loss: 0.1524.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2886.0000\n",
      "Epoch: 16/20.. Loss: 0.1575.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2888.0000\n",
      "Epoch: 16/20.. Loss: 0.1436.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2890.0000\n",
      "Epoch: 16/20.. Loss: 0.1412.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2892.0000\n",
      "Epoch: 16/20.. Loss: 0.1409.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2894.0000\n",
      "Epoch: 16/20.. Loss: 0.1299.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2896.0000\n",
      "Epoch: 16/20.. Loss: 0.1402.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2898.0000\n",
      "Epoch: 16/20.. Loss: 0.1746.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2900.0000\n",
      "Epoch: 16/20.. Loss: 0.1265.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2902.0000\n",
      "Epoch: 16/20.. Loss: 0.1253.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2904.0000\n",
      "Epoch: 16/20.. Loss: 0.1530.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2906.0000\n",
      "Epoch: 16/20.. Loss: 0.1640.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2908.0000\n",
      "Epoch: 16/20.. Loss: 0.1264.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2910.0000\n",
      "Epoch: 16/20.. Loss: 0.1600.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2912.0000\n",
      "Epoch: 16/20.. Loss: 0.1592.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2914.0000\n",
      "Epoch: 16/20.. Loss: 0.1316.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2916.0000\n",
      "Epoch: 16/20.. Loss: 0.1485.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2918.0000\n",
      "Epoch: 16/20.. Loss: 0.1500.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2920.0000\n",
      "Epoch: 16/20.. Loss: 0.1603.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2922.0000\n",
      "Epoch: 16/20.. Loss: 0.1350.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2924.0000\n",
      "Epoch: 16/20.. Loss: 0.1330.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2926.0000\n",
      "Epoch: 16/20.. Loss: 0.1685.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2928.0000\n",
      "Epoch: 16/20.. Loss: 0.1524.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2930.0000\n",
      "Epoch: 16/20.. Loss: 0.1541.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2932.0000\n",
      "Epoch: 16/20.. Loss: 0.1393.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2934.0000\n",
      "Epoch: 16/20.. Loss: 0.1335.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2936.0000\n",
      "Epoch: 16/20.. Loss: 0.1622.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 2938.0000\n",
      "Epoch: 16/20.. Loss: 0.1398.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2940.0000\n",
      "Epoch: 16/20.. Loss: 0.1478.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2942.0000\n",
      "Epoch: 16/20.. Loss: 0.1304.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2944.0000\n",
      "Epoch: 16/20.. Loss: 0.1571.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2946.0000\n",
      "Epoch: 16/20.. Loss: 0.1338.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2948.0000\n",
      "Epoch: 16/20.. Loss: 0.1620.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2950.0000\n",
      "Epoch: 16/20.. Loss: 0.1787.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2952.0000\n",
      "Epoch: 16/20.. Loss: 0.1396.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2954.0000\n",
      "Epoch: 16/20.. Loss: 0.1632.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2956.0000\n",
      "Epoch: 16/20.. Loss: 0.1055.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 2958.0000\n",
      "Epoch: 16/20.. Loss: 0.1579.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2960.0000\n",
      "Epoch: 16/20.. Loss: 0.1468.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2962.0000\n",
      "Epoch: 16/20.. Loss: 0.1447.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2964.0000\n",
      "Epoch: 16/20.. Loss: 0.1564.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2966.0000\n",
      "Epoch: 16/20.. Loss: 0.1360.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2968.0000\n",
      "Epoch: 16/20.. Loss: 0.1270.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2970.0000\n",
      "Epoch: 16/20.. Loss: 0.1028.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2972.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20.. Loss: 0.1333.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2974.0000\n",
      "Epoch: 16/20.. Loss: 0.1606.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2976.0000\n",
      "Epoch: 16/20.. Loss: 0.1458.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2978.0000\n",
      "Epoch: 16/20.. Loss: 0.1233.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2980.0000\n",
      "Epoch: 16/20.. Loss: 0.1777.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2982.0000\n",
      "Epoch: 16/20.. Loss: 0.1225.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2984.0000\n",
      "Epoch: 16/20.. Loss: 0.1592.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2986.0000\n",
      "Epoch: 16/20.. Loss: 0.1137.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 2988.0000\n",
      "Epoch: 16/20.. Loss: 0.1326.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 2990.0000\n",
      "Epoch: 16/20.. Loss: 0.1376.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 2992.0000\n",
      "Epoch: 16/20.. Loss: 0.1183.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 2994.0000\n",
      "Epoch: 16/20.. Loss: 0.1547.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 2996.0000\n",
      "Epoch: 16/20.. Loss: 0.1330.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 2998.0000\n",
      "Epoch: 16/20.. Loss: 0.1352.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3000.0000\n",
      "Epoch: 16/20.. Loss: 0.1671.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3002.0000\n",
      "Epoch: 16/20.. Loss: 0.1495.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3004.0000\n",
      "Epoch: 16/20.. Loss: 0.1540.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3006.0000\n",
      "Epoch: 16/20.. Loss: 0.1429.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3008.0000\n",
      "Epoch: 16/20.. Loss: 0.1352.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3010.0000\n",
      "Epoch: 16/20.. Loss: 0.1126.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3012.0000\n",
      "Epoch: 16/20.. Loss: 0.1329.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3014.0000\n",
      "Epoch: 16/20.. Loss: 0.1510.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3016.0000\n",
      "Epoch: 16/20.. Loss: 0.1316.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3018.0000\n",
      "Epoch: 16/20.. Loss: 0.1800.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3020.0000\n",
      "Epoch: 16/20.. Loss: 0.1394.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3022.0000\n",
      "Epoch: 16/20.. Loss: 0.1491.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3024.0000\n",
      "Epoch: 16/20.. Loss: 0.1335.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3026.0000\n",
      "Epoch: 16/20.. Loss: 0.1111.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3028.0000\n",
      "Epoch: 16/20.. Loss: 0.1114.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3030.0000\n",
      "Epoch: 16/20.. Loss: 0.1599.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3032.0000\n",
      "Epoch: 16/20.. Loss: 0.1336.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3034.0000\n",
      "Epoch: 16/20.. Loss: 0.1356.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3036.0000\n",
      "Epoch: 16/20.. Loss: 0.1278.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3038.0000\n",
      "Epoch: 16/20.. Loss: 0.1309.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3040.0000\n",
      "Epoch: 17/20.. Loss: 0.1485.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3042.0000\n",
      "Epoch: 17/20.. Loss: 0.1157.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3044.0000\n",
      "Epoch: 17/20.. Loss: 0.1496.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3046.0000\n",
      "Epoch: 17/20.. Loss: 0.1504.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3048.0000\n",
      "Epoch: 17/20.. Loss: 0.1340.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3050.0000\n",
      "Epoch: 17/20.. Loss: 0.1504.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3052.0000\n",
      "Epoch: 17/20.. Loss: 0.1363.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3054.0000\n",
      "Epoch: 17/20.. Loss: 0.1238.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3056.0000\n",
      "Epoch: 17/20.. Loss: 0.1385.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3058.0000\n",
      "Epoch: 17/20.. Loss: 0.1126.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3060.0000\n",
      "Epoch: 17/20.. Loss: 0.1500.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3062.0000\n",
      "Epoch: 17/20.. Loss: 0.1437.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3064.0000\n",
      "Epoch: 17/20.. Loss: 0.1557.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3066.0000\n",
      "Epoch: 17/20.. Loss: 0.1478.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3068.0000\n",
      "Epoch: 17/20.. Loss: 0.1422.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3070.0000\n",
      "Epoch: 17/20.. Loss: 0.1314.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3072.0000\n",
      "Epoch: 17/20.. Loss: 0.1306.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3074.0000\n",
      "Epoch: 17/20.. Loss: 0.1247.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3076.0000\n",
      "Epoch: 17/20.. Loss: 0.1408.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3078.0000\n",
      "Epoch: 17/20.. Loss: 0.1294.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3080.0000\n",
      "Epoch: 17/20.. Loss: 0.1186.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3082.0000\n",
      "Epoch: 17/20.. Loss: 0.1156.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3084.0000\n",
      "Epoch: 17/20.. Loss: 0.1605.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3086.0000\n",
      "Epoch: 17/20.. Loss: 0.1485.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3088.0000\n",
      "Epoch: 17/20.. Loss: 0.1509.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3090.0000\n",
      "Epoch: 17/20.. Loss: 0.1155.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3092.0000\n",
      "Epoch: 17/20.. Loss: 0.1457.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3094.0000\n",
      "Epoch: 17/20.. Loss: 0.1588.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3096.0000\n",
      "Epoch: 17/20.. Loss: 0.1443.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3098.0000\n",
      "Epoch: 17/20.. Loss: 0.1417.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3100.0000\n",
      "Epoch: 17/20.. Loss: 0.1352.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3102.0000\n",
      "Epoch: 17/20.. Loss: 0.1327.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3104.0000\n",
      "Epoch: 17/20.. Loss: 0.1419.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3106.0000\n",
      "Epoch: 17/20.. Loss: 0.1496.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3108.0000\n",
      "Epoch: 17/20.. Loss: 0.1179.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3110.0000\n",
      "Epoch: 17/20.. Loss: 0.1164.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3112.0000\n",
      "Epoch: 17/20.. Loss: 0.0985.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3114.0000\n",
      "Epoch: 17/20.. Loss: 0.1407.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3116.0000\n",
      "Epoch: 17/20.. Loss: 0.1462.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3118.0000\n",
      "Epoch: 17/20.. Loss: 0.1253.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3120.0000\n",
      "Epoch: 17/20.. Loss: 0.1530.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3122.0000\n",
      "Epoch: 17/20.. Loss: 0.1433.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3124.0000\n",
      "Epoch: 17/20.. Loss: 0.1421.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3126.0000\n",
      "Epoch: 17/20.. Loss: 0.1446.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3128.0000\n",
      "Epoch: 17/20.. Loss: 0.1403.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3130.0000\n",
      "Epoch: 17/20.. Loss: 0.1470.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3132.0000\n",
      "Epoch: 17/20.. Loss: 0.1162.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3134.0000\n",
      "Epoch: 17/20.. Loss: 0.1558.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3136.0000\n",
      "Epoch: 17/20.. Loss: 0.1306.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3138.0000\n",
      "Epoch: 17/20.. Loss: 0.1170.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3140.0000\n",
      "Epoch: 17/20.. Loss: 0.1297.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3142.0000\n",
      "Epoch: 17/20.. Loss: 0.1577.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 3144.0000\n",
      "Epoch: 17/20.. Loss: 0.1271.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3146.0000\n",
      "Epoch: 17/20.. Loss: 0.1260.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3148.0000\n",
      "Epoch: 17/20.. Loss: 0.1367.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3150.0000\n",
      "Epoch: 17/20.. Loss: 0.1342.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3152.0000\n",
      "Epoch: 17/20.. Loss: 0.1539.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3154.0000\n",
      "Epoch: 17/20.. Loss: 0.1283.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3156.0000\n",
      "Epoch: 17/20.. Loss: 0.1512.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3158.0000\n",
      "Epoch: 17/20.. Loss: 0.1331.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3160.0000\n",
      "Epoch: 17/20.. Loss: 0.1728.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3162.0000\n",
      "Epoch: 17/20.. Loss: 0.1315.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3164.0000\n",
      "Epoch: 17/20.. Loss: 0.1423.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3166.0000\n",
      "Epoch: 17/20.. Loss: 0.1387.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3168.0000\n",
      "Epoch: 17/20.. Loss: 0.1281.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3170.0000\n",
      "Epoch: 17/20.. Loss: 0.1368.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3172.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20.. Loss: 0.1270.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3174.0000\n",
      "Epoch: 17/20.. Loss: 0.1657.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3176.0000\n",
      "Epoch: 17/20.. Loss: 0.1290.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3178.0000\n",
      "Epoch: 17/20.. Loss: 0.1600.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3180.0000\n",
      "Epoch: 17/20.. Loss: 0.1171.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3182.0000\n",
      "Epoch: 17/20.. Loss: 0.1320.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3184.0000\n",
      "Epoch: 17/20.. Loss: 0.1391.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3186.0000\n",
      "Epoch: 17/20.. Loss: 0.1302.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3188.0000\n",
      "Epoch: 17/20.. Loss: 0.1080.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3190.0000\n",
      "Epoch: 17/20.. Loss: 0.1247.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3192.0000\n",
      "Epoch: 17/20.. Loss: 0.1412.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3194.0000\n",
      "Epoch: 17/20.. Loss: 0.1332.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3196.0000\n",
      "Epoch: 17/20.. Loss: 0.1134.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3198.0000\n",
      "Epoch: 17/20.. Loss: 0.1463.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 3200.0000\n",
      "Epoch: 17/20.. Loss: 0.1229.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3202.0000\n",
      "Epoch: 17/20.. Loss: 0.1654.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 3204.0000\n",
      "Epoch: 17/20.. Loss: 0.1400.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3206.0000\n",
      "Epoch: 17/20.. Loss: 0.1164.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3208.0000\n",
      "Epoch: 17/20.. Loss: 0.1725.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3210.0000\n",
      "Epoch: 17/20.. Loss: 0.1005.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3212.0000\n",
      "Epoch: 17/20.. Loss: 0.1400.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3214.0000\n",
      "Epoch: 17/20.. Loss: 0.1584.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3216.0000\n",
      "Epoch: 17/20.. Loss: 0.1212.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3218.0000\n",
      "Epoch: 17/20.. Loss: 0.1237.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3220.0000\n",
      "Epoch: 17/20.. Loss: 0.1102.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3222.0000\n",
      "Epoch: 17/20.. Loss: 0.1250.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3224.0000\n",
      "Epoch: 17/20.. Loss: 0.1292.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3226.0000\n",
      "Epoch: 17/20.. Loss: 0.1306.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3228.0000\n",
      "Epoch: 17/20.. Loss: 0.1481.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3230.0000\n",
      "Epoch: 18/20.. Loss: 0.1751.. Test accuracy: 0.2801.. 0.0015 s/batch  steps 3232.0000\n",
      "Epoch: 18/20.. Loss: 0.1616.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3234.0000\n",
      "Epoch: 18/20.. Loss: 0.1416.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3236.0000\n",
      "Epoch: 18/20.. Loss: 0.1202.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3238.0000\n",
      "Epoch: 18/20.. Loss: 0.1251.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3240.0000\n",
      "Epoch: 18/20.. Loss: 0.1391.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3242.0000\n",
      "Epoch: 18/20.. Loss: 0.1603.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3244.0000\n",
      "Epoch: 18/20.. Loss: 0.1356.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3246.0000\n",
      "Epoch: 18/20.. Loss: 0.1469.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3248.0000\n",
      "Epoch: 18/20.. Loss: 0.1254.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3250.0000\n",
      "Epoch: 18/20.. Loss: 0.1366.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3252.0000\n",
      "Epoch: 18/20.. Loss: 0.0980.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3254.0000\n",
      "Epoch: 18/20.. Loss: 0.1232.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3256.0000\n",
      "Epoch: 18/20.. Loss: 0.1448.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3258.0000\n",
      "Epoch: 18/20.. Loss: 0.1202.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 3260.0000\n",
      "Epoch: 18/20.. Loss: 0.1505.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3262.0000\n",
      "Epoch: 18/20.. Loss: 0.1361.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3264.0000\n",
      "Epoch: 18/20.. Loss: 0.1426.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3266.0000\n",
      "Epoch: 18/20.. Loss: 0.1303.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3268.0000\n",
      "Epoch: 18/20.. Loss: 0.1289.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3270.0000\n",
      "Epoch: 18/20.. Loss: 0.1392.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 3272.0000\n",
      "Epoch: 18/20.. Loss: 0.1182.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3274.0000\n",
      "Epoch: 18/20.. Loss: 0.1399.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3276.0000\n",
      "Epoch: 18/20.. Loss: 0.1291.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3278.0000\n",
      "Epoch: 18/20.. Loss: 0.1485.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3280.0000\n",
      "Epoch: 18/20.. Loss: 0.1660.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3282.0000\n",
      "Epoch: 18/20.. Loss: 0.1160.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3284.0000\n",
      "Epoch: 18/20.. Loss: 0.1392.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3286.0000\n",
      "Epoch: 18/20.. Loss: 0.1473.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3288.0000\n",
      "Epoch: 18/20.. Loss: 0.1405.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3290.0000\n",
      "Epoch: 18/20.. Loss: 0.1190.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3292.0000\n",
      "Epoch: 18/20.. Loss: 0.1130.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3294.0000\n",
      "Epoch: 18/20.. Loss: 0.1640.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3296.0000\n",
      "Epoch: 18/20.. Loss: 0.1310.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3298.0000\n",
      "Epoch: 18/20.. Loss: 0.1441.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3300.0000\n",
      "Epoch: 18/20.. Loss: 0.1107.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3302.0000\n",
      "Epoch: 18/20.. Loss: 0.1529.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3304.0000\n",
      "Epoch: 18/20.. Loss: 0.1454.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3306.0000\n",
      "Epoch: 18/20.. Loss: 0.1487.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 3308.0000\n",
      "Epoch: 18/20.. Loss: 0.1150.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3310.0000\n",
      "Epoch: 18/20.. Loss: 0.1040.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3312.0000\n",
      "Epoch: 18/20.. Loss: 0.1074.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3314.0000\n",
      "Epoch: 18/20.. Loss: 0.1150.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3316.0000\n",
      "Epoch: 18/20.. Loss: 0.1245.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3318.0000\n",
      "Epoch: 18/20.. Loss: 0.1256.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3320.0000\n",
      "Epoch: 18/20.. Loss: 0.1187.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3322.0000\n",
      "Epoch: 18/20.. Loss: 0.1074.. Test accuracy: 0.2800.. 0.0017 s/batch  steps 3324.0000\n",
      "Epoch: 18/20.. Loss: 0.1278.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3326.0000\n",
      "Epoch: 18/20.. Loss: 0.1454.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3328.0000\n",
      "Epoch: 18/20.. Loss: 0.1127.. Test accuracy: 0.2801.. 0.0020 s/batch  steps 3330.0000\n",
      "Epoch: 18/20.. Loss: 0.1336.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3332.0000\n",
      "Epoch: 18/20.. Loss: 0.1408.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3334.0000\n",
      "Epoch: 18/20.. Loss: 0.1027.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3336.0000\n",
      "Epoch: 18/20.. Loss: 0.1278.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3338.0000\n",
      "Epoch: 18/20.. Loss: 0.1312.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3340.0000\n",
      "Epoch: 18/20.. Loss: 0.1017.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3342.0000\n",
      "Epoch: 18/20.. Loss: 0.1115.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3344.0000\n",
      "Epoch: 18/20.. Loss: 0.1274.. Test accuracy: 0.2801.. 0.0016 s/batch  steps 3346.0000\n",
      "Epoch: 18/20.. Loss: 0.1442.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3348.0000\n",
      "Epoch: 18/20.. Loss: 0.1500.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3350.0000\n",
      "Epoch: 18/20.. Loss: 0.1362.. Test accuracy: 0.2800.. 0.0027 s/batch  steps 3352.0000\n",
      "Epoch: 18/20.. Loss: 0.1389.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3354.0000\n",
      "Epoch: 18/20.. Loss: 0.1414.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3356.0000\n",
      "Epoch: 18/20.. Loss: 0.1416.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3358.0000\n",
      "Epoch: 18/20.. Loss: 0.1338.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3360.0000\n",
      "Epoch: 18/20.. Loss: 0.1342.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3362.0000\n",
      "Epoch: 18/20.. Loss: 0.1465.. Test accuracy: 0.2801.. 0.0033 s/batch  steps 3364.0000\n",
      "Epoch: 18/20.. Loss: 0.1104.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3366.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20.. Loss: 0.1362.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3368.0000\n",
      "Epoch: 18/20.. Loss: 0.1436.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3370.0000\n",
      "Epoch: 18/20.. Loss: 0.1197.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3372.0000\n",
      "Epoch: 18/20.. Loss: 0.1144.. Test accuracy: 0.2801.. 0.0019 s/batch  steps 3374.0000\n",
      "Epoch: 18/20.. Loss: 0.1102.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3376.0000\n",
      "Epoch: 18/20.. Loss: 0.1302.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3378.0000\n",
      "Epoch: 18/20.. Loss: 0.1242.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3380.0000\n",
      "Epoch: 18/20.. Loss: 0.1303.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3382.0000\n",
      "Epoch: 18/20.. Loss: 0.1296.. Test accuracy: 0.2800.. 0.0006 s/batch  steps 3384.0000\n",
      "Epoch: 18/20.. Loss: 0.1566.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3386.0000\n",
      "Epoch: 18/20.. Loss: 0.1144.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3388.0000\n",
      "Epoch: 18/20.. Loss: 0.1226.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3390.0000\n",
      "Epoch: 18/20.. Loss: 0.1151.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3392.0000\n",
      "Epoch: 18/20.. Loss: 0.1405.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3394.0000\n",
      "Epoch: 18/20.. Loss: 0.1210.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3396.0000\n",
      "Epoch: 18/20.. Loss: 0.1288.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 3398.0000\n",
      "Epoch: 18/20.. Loss: 0.1454.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3400.0000\n",
      "Epoch: 18/20.. Loss: 0.1346.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3402.0000\n",
      "Epoch: 18/20.. Loss: 0.1551.. Test accuracy: 0.2801.. 0.0006 s/batch  steps 3404.0000\n",
      "Epoch: 18/20.. Loss: 0.1215.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3406.0000\n",
      "Epoch: 18/20.. Loss: 0.1109.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3408.0000\n",
      "Epoch: 18/20.. Loss: 0.1161.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3410.0000\n",
      "Epoch: 18/20.. Loss: 0.1433.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3412.0000\n",
      "Epoch: 18/20.. Loss: 0.1332.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3414.0000\n",
      "Epoch: 18/20.. Loss: 0.1462.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3416.0000\n",
      "Epoch: 18/20.. Loss: 0.1327.. Test accuracy: 0.2801.. 0.0014 s/batch  steps 3418.0000\n",
      "Epoch: 18/20.. Loss: 0.1561.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3420.0000\n",
      "Epoch: 19/20.. Loss: 0.1145.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3422.0000\n",
      "Epoch: 19/20.. Loss: 0.1107.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3424.0000\n",
      "Epoch: 19/20.. Loss: 0.1156.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3426.0000\n",
      "Epoch: 19/20.. Loss: 0.1284.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3428.0000\n",
      "Epoch: 19/20.. Loss: 0.1380.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3430.0000\n",
      "Epoch: 19/20.. Loss: 0.1366.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3432.0000\n",
      "Epoch: 19/20.. Loss: 0.1061.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3434.0000\n",
      "Epoch: 19/20.. Loss: 0.1070.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3436.0000\n",
      "Epoch: 19/20.. Loss: 0.1052.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3438.0000\n",
      "Epoch: 19/20.. Loss: 0.1035.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3440.0000\n",
      "Epoch: 19/20.. Loss: 0.1396.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3442.0000\n",
      "Epoch: 19/20.. Loss: 0.1343.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3444.0000\n",
      "Epoch: 19/20.. Loss: 0.1259.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3446.0000\n",
      "Epoch: 19/20.. Loss: 0.1276.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3448.0000\n",
      "Epoch: 19/20.. Loss: 0.1574.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3450.0000\n",
      "Epoch: 19/20.. Loss: 0.1121.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3452.0000\n",
      "Epoch: 19/20.. Loss: 0.1347.. Test accuracy: 0.2801.. 0.0013 s/batch  steps 3454.0000\n",
      "Epoch: 19/20.. Loss: 0.1419.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3456.0000\n",
      "Epoch: 19/20.. Loss: 0.1069.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3458.0000\n",
      "Epoch: 19/20.. Loss: 0.1116.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3460.0000\n",
      "Epoch: 19/20.. Loss: 0.1246.. Test accuracy: 0.2800.. 0.0015 s/batch  steps 3462.0000\n",
      "Epoch: 19/20.. Loss: 0.1524.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3464.0000\n",
      "Epoch: 19/20.. Loss: 0.1502.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3466.0000\n",
      "Epoch: 19/20.. Loss: 0.1325.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3468.0000\n",
      "Epoch: 19/20.. Loss: 0.1192.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3470.0000\n",
      "Epoch: 19/20.. Loss: 0.1351.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3472.0000\n",
      "Epoch: 19/20.. Loss: 0.1310.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3474.0000\n",
      "Epoch: 19/20.. Loss: 0.1176.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3476.0000\n",
      "Epoch: 19/20.. Loss: 0.1151.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3478.0000\n",
      "Epoch: 19/20.. Loss: 0.1301.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3480.0000\n",
      "Epoch: 19/20.. Loss: 0.1204.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3482.0000\n",
      "Epoch: 19/20.. Loss: 0.1033.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3484.0000\n",
      "Epoch: 19/20.. Loss: 0.1070.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3486.0000\n",
      "Epoch: 19/20.. Loss: 0.1439.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3488.0000\n",
      "Epoch: 19/20.. Loss: 0.0979.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3490.0000\n",
      "Epoch: 19/20.. Loss: 0.1074.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3492.0000\n",
      "Epoch: 19/20.. Loss: 0.1392.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3494.0000\n",
      "Epoch: 19/20.. Loss: 0.1598.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3496.0000\n",
      "Epoch: 19/20.. Loss: 0.1278.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3498.0000\n",
      "Epoch: 19/20.. Loss: 0.1432.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3500.0000\n",
      "Epoch: 19/20.. Loss: 0.1268.. Test accuracy: 0.2801.. 0.0012 s/batch  steps 3502.0000\n",
      "Epoch: 19/20.. Loss: 0.0969.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3504.0000\n",
      "Epoch: 19/20.. Loss: 0.1273.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3506.0000\n",
      "Epoch: 19/20.. Loss: 0.1219.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3508.0000\n",
      "Epoch: 19/20.. Loss: 0.1161.. Test accuracy: 0.2801.. 0.0010 s/batch  steps 3510.0000\n",
      "Epoch: 19/20.. Loss: 0.1182.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3512.0000\n",
      "Epoch: 19/20.. Loss: 0.1323.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3514.0000\n",
      "Epoch: 19/20.. Loss: 0.1244.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3516.0000\n",
      "Epoch: 19/20.. Loss: 0.1275.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3518.0000\n",
      "Epoch: 19/20.. Loss: 0.1291.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3520.0000\n",
      "Epoch: 19/20.. Loss: 0.1026.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3522.0000\n",
      "Epoch: 19/20.. Loss: 0.1294.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3524.0000\n",
      "Epoch: 19/20.. Loss: 0.1261.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3526.0000\n",
      "Epoch: 19/20.. Loss: 0.1156.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3528.0000\n",
      "Epoch: 19/20.. Loss: 0.1364.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3530.0000\n",
      "Epoch: 19/20.. Loss: 0.1369.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3532.0000\n",
      "Epoch: 19/20.. Loss: 0.1263.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3534.0000\n",
      "Epoch: 19/20.. Loss: 0.1109.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3536.0000\n",
      "Epoch: 19/20.. Loss: 0.1208.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3538.0000\n",
      "Epoch: 19/20.. Loss: 0.1245.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3540.0000\n",
      "Epoch: 19/20.. Loss: 0.1376.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3542.0000\n",
      "Epoch: 19/20.. Loss: 0.1620.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3544.0000\n",
      "Epoch: 19/20.. Loss: 0.1439.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3546.0000\n",
      "Epoch: 19/20.. Loss: 0.1169.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3548.0000\n",
      "Epoch: 19/20.. Loss: 0.1412.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3550.0000\n",
      "Epoch: 19/20.. Loss: 0.1485.. Test accuracy: 0.2801.. 0.0008 s/batch  steps 3552.0000\n",
      "Epoch: 19/20.. Loss: 0.1471.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3554.0000\n",
      "Epoch: 19/20.. Loss: 0.1238.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3556.0000\n",
      "Epoch: 19/20.. Loss: 0.1212.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3558.0000\n",
      "Epoch: 19/20.. Loss: 0.1217.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3560.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20.. Loss: 0.1641.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3562.0000\n",
      "Epoch: 19/20.. Loss: 0.1409.. Test accuracy: 0.2801.. 0.0007 s/batch  steps 3564.0000\n",
      "Epoch: 19/20.. Loss: 0.1412.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3566.0000\n",
      "Epoch: 19/20.. Loss: 0.1421.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3568.0000\n",
      "Epoch: 19/20.. Loss: 0.1382.. Test accuracy: 0.2801.. 0.0009 s/batch  steps 3570.0000\n",
      "Epoch: 19/20.. Loss: 0.1325.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3572.0000\n",
      "Epoch: 19/20.. Loss: 0.1297.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3574.0000\n",
      "Epoch: 19/20.. Loss: 0.1194.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3576.0000\n",
      "Epoch: 19/20.. Loss: 0.1285.. Test accuracy: 0.2801.. 0.0017 s/batch  steps 3578.0000\n",
      "Epoch: 19/20.. Loss: 0.0894.. Test accuracy: 0.2800.. 0.0017 s/batch  steps 3580.0000\n",
      "Epoch: 19/20.. Loss: 0.1362.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3582.0000\n",
      "Epoch: 19/20.. Loss: 0.1212.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3584.0000\n",
      "Epoch: 19/20.. Loss: 0.1397.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3586.0000\n",
      "Epoch: 19/20.. Loss: 0.1143.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3588.0000\n",
      "Epoch: 19/20.. Loss: 0.1277.. Test accuracy: 0.2800.. 0.0017 s/batch  steps 3590.0000\n",
      "Epoch: 19/20.. Loss: 0.1341.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3592.0000\n",
      "Epoch: 19/20.. Loss: 0.1381.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3594.0000\n",
      "Epoch: 19/20.. Loss: 0.1239.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3596.0000\n",
      "Epoch: 19/20.. Loss: 0.1413.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3598.0000\n",
      "Epoch: 19/20.. Loss: 0.1558.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3600.0000\n",
      "Epoch: 19/20.. Loss: 0.1114.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3602.0000\n",
      "Epoch: 19/20.. Loss: 0.1065.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3604.0000\n",
      "Epoch: 19/20.. Loss: 0.1176.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3606.0000\n",
      "Epoch: 19/20.. Loss: 0.1286.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3608.0000\n",
      "Epoch: 19/20.. Loss: 0.1253.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3610.0000\n",
      "Epoch: 20/20.. Loss: 0.1018.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3612.0000\n",
      "Epoch: 20/20.. Loss: 0.0981.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3614.0000\n",
      "Epoch: 20/20.. Loss: 0.0999.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3616.0000\n",
      "Epoch: 20/20.. Loss: 0.1211.. Test accuracy: 0.2800.. 0.0006 s/batch  steps 3618.0000\n",
      "Epoch: 20/20.. Loss: 0.1330.. Test accuracy: 0.2801.. 0.0011 s/batch  steps 3620.0000\n",
      "Epoch: 20/20.. Loss: 0.1238.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3622.0000\n",
      "Epoch: 20/20.. Loss: 0.1345.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3624.0000\n",
      "Epoch: 20/20.. Loss: 0.1056.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3626.0000\n",
      "Epoch: 20/20.. Loss: 0.1072.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3628.0000\n",
      "Epoch: 20/20.. Loss: 0.1302.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3630.0000\n",
      "Epoch: 20/20.. Loss: 0.1287.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3632.0000\n",
      "Epoch: 20/20.. Loss: 0.1448.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3634.0000\n",
      "Epoch: 20/20.. Loss: 0.1313.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3636.0000\n",
      "Epoch: 20/20.. Loss: 0.1212.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3638.0000\n",
      "Epoch: 20/20.. Loss: 0.1102.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3640.0000\n",
      "Epoch: 20/20.. Loss: 0.1199.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3642.0000\n",
      "Epoch: 20/20.. Loss: 0.1360.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3644.0000\n",
      "Epoch: 20/20.. Loss: 0.1332.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3646.0000\n",
      "Epoch: 20/20.. Loss: 0.1201.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3648.0000\n",
      "Epoch: 20/20.. Loss: 0.1222.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3650.0000\n",
      "Epoch: 20/20.. Loss: 0.1075.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3652.0000\n",
      "Epoch: 20/20.. Loss: 0.1309.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3654.0000\n",
      "Epoch: 20/20.. Loss: 0.1123.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3656.0000\n",
      "Epoch: 20/20.. Loss: 0.1349.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3658.0000\n",
      "Epoch: 20/20.. Loss: 0.1443.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3660.0000\n",
      "Epoch: 20/20.. Loss: 0.1360.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3662.0000\n",
      "Epoch: 20/20.. Loss: 0.1401.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3664.0000\n",
      "Epoch: 20/20.. Loss: 0.1186.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3666.0000\n",
      "Epoch: 20/20.. Loss: 0.1121.. Test accuracy: 0.2800.. 0.0006 s/batch  steps 3668.0000\n",
      "Epoch: 20/20.. Loss: 0.1382.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3670.0000\n",
      "Epoch: 20/20.. Loss: 0.1141.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3672.0000\n",
      "Epoch: 20/20.. Loss: 0.1534.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3674.0000\n",
      "Epoch: 20/20.. Loss: 0.1175.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3676.0000\n",
      "Epoch: 20/20.. Loss: 0.1466.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3678.0000\n",
      "Epoch: 20/20.. Loss: 0.1087.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3680.0000\n",
      "Epoch: 20/20.. Loss: 0.1185.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3682.0000\n",
      "Epoch: 20/20.. Loss: 0.1116.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3684.0000\n",
      "Epoch: 20/20.. Loss: 0.1377.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3686.0000\n",
      "Epoch: 20/20.. Loss: 0.1179.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3688.0000\n",
      "Epoch: 20/20.. Loss: 0.1292.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3690.0000\n",
      "Epoch: 20/20.. Loss: 0.1187.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3692.0000\n",
      "Epoch: 20/20.. Loss: 0.1113.. Test accuracy: 0.2800.. 0.0014 s/batch  steps 3694.0000\n",
      "Epoch: 20/20.. Loss: 0.1061.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3696.0000\n",
      "Epoch: 20/20.. Loss: 0.1386.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3698.0000\n",
      "Epoch: 20/20.. Loss: 0.1370.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3700.0000\n",
      "Epoch: 20/20.. Loss: 0.1331.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3702.0000\n",
      "Epoch: 20/20.. Loss: 0.1511.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3704.0000\n",
      "Epoch: 20/20.. Loss: 0.1205.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3706.0000\n",
      "Epoch: 20/20.. Loss: 0.1285.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3708.0000\n",
      "Epoch: 20/20.. Loss: 0.1168.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3710.0000\n",
      "Epoch: 20/20.. Loss: 0.1250.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3712.0000\n",
      "Epoch: 20/20.. Loss: 0.1357.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3714.0000\n",
      "Epoch: 20/20.. Loss: 0.1020.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3716.0000\n",
      "Epoch: 20/20.. Loss: 0.1332.. Test accuracy: 0.2800.. 0.0016 s/batch  steps 3718.0000\n",
      "Epoch: 20/20.. Loss: 0.1414.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3720.0000\n",
      "Epoch: 20/20.. Loss: 0.1431.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3722.0000\n",
      "Epoch: 20/20.. Loss: 0.1325.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3724.0000\n",
      "Epoch: 20/20.. Loss: 0.0883.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3726.0000\n",
      "Epoch: 20/20.. Loss: 0.1169.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3728.0000\n",
      "Epoch: 20/20.. Loss: 0.1315.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3730.0000\n",
      "Epoch: 20/20.. Loss: 0.1282.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3732.0000\n",
      "Epoch: 20/20.. Loss: 0.1061.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3734.0000\n",
      "Epoch: 20/20.. Loss: 0.1339.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3736.0000\n",
      "Epoch: 20/20.. Loss: 0.1465.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3738.0000\n",
      "Epoch: 20/20.. Loss: 0.0963.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3740.0000\n",
      "Epoch: 20/20.. Loss: 0.1140.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3742.0000\n",
      "Epoch: 20/20.. Loss: 0.1391.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3744.0000\n",
      "Epoch: 20/20.. Loss: 0.1135.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3746.0000\n",
      "Epoch: 20/20.. Loss: 0.1336.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3748.0000\n",
      "Epoch: 20/20.. Loss: 0.1013.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3750.0000\n",
      "Epoch: 20/20.. Loss: 0.1557.. Test accuracy: 0.2800.. 0.0012 s/batch  steps 3752.0000\n",
      "Epoch: 20/20.. Loss: 0.1262.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3754.0000\n",
      "Epoch: 20/20.. Loss: 0.1285.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3756.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20.. Loss: 0.1243.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3758.0000\n",
      "Epoch: 20/20.. Loss: 0.1364.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3760.0000\n",
      "Epoch: 20/20.. Loss: 0.1369.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3762.0000\n",
      "Epoch: 20/20.. Loss: 0.1013.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3764.0000\n",
      "Epoch: 20/20.. Loss: 0.1463.. Test accuracy: 0.2800.. 0.0009 s/batch  steps 3766.0000\n",
      "Epoch: 20/20.. Loss: 0.1518.. Test accuracy: 0.2800.. 0.0013 s/batch  steps 3768.0000\n",
      "Epoch: 20/20.. Loss: 0.1504.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3770.0000\n",
      "Epoch: 20/20.. Loss: 0.1005.. Test accuracy: 0.2800.. 0.0007 s/batch  steps 3772.0000\n",
      "Epoch: 20/20.. Loss: 0.1120.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3774.0000\n",
      "Epoch: 20/20.. Loss: 0.1443.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3776.0000\n",
      "Epoch: 20/20.. Loss: 0.1102.. Test accuracy: 0.2800.. 0.0011 s/batch  steps 3778.0000\n",
      "Epoch: 20/20.. Loss: 0.1240.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3780.0000\n",
      "Epoch: 20/20.. Loss: 0.1457.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3782.0000\n",
      "Epoch: 20/20.. Loss: 0.1532.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3784.0000\n",
      "Epoch: 20/20.. Loss: 0.0913.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3786.0000\n",
      "Epoch: 20/20.. Loss: 0.1303.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3788.0000\n",
      "Epoch: 20/20.. Loss: 0.1102.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3790.0000\n",
      "Epoch: 20/20.. Loss: 0.1330.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3792.0000\n",
      "Epoch: 20/20.. Loss: 0.1109.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3794.0000\n",
      "Epoch: 20/20.. Loss: 0.1094.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3796.0000\n",
      "Epoch: 20/20.. Loss: 0.1194.. Test accuracy: 0.2800.. 0.0008 s/batch  steps 3798.0000\n",
      "Epoch: 20/20.. Loss: 0.1368.. Test accuracy: 0.2800.. 0.0010 s/batch  steps 3800.0000\n"
     ]
    }
   ],
   "source": [
    "net = ConvNetcreate()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.00001, weight_decay=1e-4)\n",
    "epochs = 20\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 2\n",
    "#vec_acc_ = np.zeros(epochs*50)\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Do not forget to transform the inputs and outputs into Variable        #\n",
    "        # which pytorch uses.                                                          #\n",
    "        ################################################################################\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        output = net.forward(inputs)\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        grad = loss.backward()\n",
    "        optimizer.step()\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            sum_accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                inputs = Variable(images)\n",
    "                targets = Variable(labels)\n",
    "                predicted = net.predict(inputs)\n",
    "                accuracy = criterion(predicted, targets)\n",
    "                accuracy = accuracy.data.numpy().tolist()[0]\n",
    "                #vec_acc_[steps-1] = accuracy/(ii+1)\n",
    "                sum_accuracy += accuracy\n",
    "                \n",
    "                #inputs = Variable(images, volatile=True)\n",
    "                #predicted = net.predict(inputs)\n",
    "                #equality = (labels == predicted.max(1)[1])\n",
    "                #accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "                \n",
    "                \n",
    "                #im = Variable(images)\n",
    "                #out = net.predict(im)\n",
    "                #_,prediction = torch.max(out, 1)\n",
    "                #pred_y = prediction.data.numpy().squeeze()\n",
    "                #target_y = labels.numpy()\n",
    "                #accuracy = np.mean(predicted == inputs)\n",
    "                #print(pred_y.shape,target_y.shape)\n",
    "                \n",
    "                \n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(loss.data[0]),\n",
    "                  \"Test accuracy: {:.4f}..\".format(sum_accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch \".format((stop - start)/print_every),\n",
    "                  \"steps {:.4f}\".format(steps)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()\n",
    "\n",
    "#plt.plot(range(epochs*25),vec_acc_)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
