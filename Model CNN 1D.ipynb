{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10b0a85d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from LSTM import *\n",
    "from LSTMbis import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import time\n",
    "\n",
    "import pdb\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data = {}\n",
    "a=0\n",
    "for j in range(1,4):\n",
    "    for i in os.listdir('./data_linear_augm/%s'%j):\n",
    "        if i.endswith('.txt'):\n",
    "            a = a+1\n",
    "            data['%s'%a] = pd.read_csv('data_linear_augm/{}/{}'.format(j,i), header = None, \n",
    "                                        names = ['frameNb','id', 'x','y','Vx','Vy'],\n",
    "                                           delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "inputs = np.zeros([len(data),20])\n",
    "gt = np.zeros([len(data),20])\n",
    "in_coord = np.zeros([len(data),20])\n",
    "gt_coord = np.zeros([len(data),22])\n",
    "\n",
    "for i in data:\n",
    "    inputs[a,:,:] = np.array(data['%s'%i].loc[0:9,['Vx','Vy']])\n",
    "    gt[a,:,:] = np.array(data['%s'%i].loc[10:19,['Vx','Vy']])\n",
    "    in_coord[a,:,:] = np.array(data['%s'%i].loc[0:9,['x','y']])\n",
    "    gt_coord[a,:,:] = np.array(data['%s'%i].loc[9:19,['x','y']])\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  torch.Size([125, 1, 18])\n",
      "Train labels shape:  torch.Size([125, 1, 18])\n",
      "Validation data shape:  torch.Size([20, 1, 18])\n",
      "Validation labels shape:  torch.Size([20, 1, 18])\n"
     ]
    }
   ],
   "source": [
    "vector = np.zeros((len(vector_speed),2*len(vector_speed[0])))\n",
    "x = np.zeros((len(vector_speed),18))\n",
    "y = np.zeros((len(vector_speed),18))\n",
    "x_train = np.zeros((len(vector_speed)-20,18))\n",
    "Y_train = np.zeros((len(vector_speed)-20,18))\n",
    "x_val = np.zeros((20,18))\n",
    "y_val = np.zeros((20,18))\n",
    "\n",
    "for i in range(len(vector_speed)):\n",
    "    vector[i][:] = np.reshape(vector_speed[i][:][:],2*19,'C')\n",
    "for i in range(len(vector)):\n",
    "    x[i][:] = vector[i][:18]\n",
    "    y[i][:] = vector[i][20:38]\n",
    "\n",
    "mask = list(range(len(vector)-20, len(vector)))\n",
    "x_val = x[mask]\n",
    "y_val = y[mask]\n",
    "mask = list(range(len(vector)-20))\n",
    "x_train = x[mask]\n",
    "y_train = y[mask]\n",
    "\n",
    "x_train,y_train = torch.from_numpy(x_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "x_val,y_val = torch.from_numpy(x_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.FloatTensor)\n",
    "\n",
    "x_train = x_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "y_train = y_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "x_val = x_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "y_val = y_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "traindataset = utils.TensorDataset(x_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(x_val, y_val)\n",
    "valloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=1, n_output=None):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Define 2 or more different layers of the neural network                      #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_input_channels,8,5,padding=2)\n",
    "        self.conv2 = nn.Conv1d(8,30,3,padding=1)\n",
    "        self.conv3 = nn.Conv1d(30,40,3,padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True)\n",
    "     \n",
    "        self.fc1 = nn.Linear(9*2 * 40, 500)\n",
    "        self.fc2 = nn.Linear(500, 200)\n",
    "        self.fc3 = nn.Linear(200, 18)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Set up the forward pass that the input data will go through.                 #\n",
    "        # A good activation function betweent the layers is a ReLu function.           #\n",
    "        #                                                                              #\n",
    "        # Note that the output of the last convolution layer should be flattened       #\n",
    "        # before being inputted to the fully connected layer. We can flatten           #\n",
    "        # Variable `x` with `x.view`.                                                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = x.view(-1, 9*2 * 40) # in order to reshape the tensor for as many columns we need\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/4romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20.. Loss: 0.6133.. Test accuracy: 0.0380.. 0.0547 s/batch  steps 1.0000\n",
      "Epoch: 1/20.. Loss: 0.2411.. Test accuracy: 0.0367.. 0.0100 s/batch  steps 2.0000\n",
      "Epoch: 1/20.. Loss: 0.8234.. Test accuracy: 0.0462.. 0.0102 s/batch  steps 3.0000\n",
      "Epoch: 1/20.. Loss: 0.8162.. Test accuracy: 0.0145.. 0.0101 s/batch  steps 4.0000\n",
      "Epoch: 1/20.. Loss: 0.4252.. Test accuracy: 0.0161.. 0.0079 s/batch  steps 5.0000\n",
      "Epoch: 1/20.. Loss: 1.0390.. Test accuracy: 0.0284.. 0.0109 s/batch  steps 6.0000\n",
      "Epoch: 1/20.. Loss: 0.5160.. Test accuracy: 0.0315.. 0.0108 s/batch  steps 7.0000\n",
      "Epoch: 1/20.. Loss: 0.5897.. Test accuracy: 0.0325.. 0.0112 s/batch  steps 8.0000\n",
      "Epoch: 1/20.. Loss: 0.9377.. Test accuracy: 0.0121.. 0.0103 s/batch  steps 9.0000\n",
      "Epoch: 1/20.. Loss: 0.5754.. Test accuracy: 0.0243.. 0.0089 s/batch  steps 10.0000\n",
      "Epoch: 1/20.. Loss: 0.1971.. Test accuracy: 0.0318.. 0.0096 s/batch  steps 11.0000\n",
      "Epoch: 1/20.. Loss: 0.2477.. Test accuracy: 0.0086.. 0.0102 s/batch  steps 12.0000\n",
      "Epoch: 1/20.. Loss: 0.6786.. Test accuracy: 0.0122.. 0.0097 s/batch  steps 13.0000\n",
      "Epoch: 1/20.. Loss: 0.7086.. Test accuracy: 0.0304.. 0.0098 s/batch  steps 14.0000\n",
      "Epoch: 1/20.. Loss: 0.2613.. Test accuracy: 0.0306.. 0.0096 s/batch  steps 15.0000\n",
      "Epoch: 1/20.. Loss: 0.0219.. Test accuracy: 0.0432.. 0.0097 s/batch  steps 16.0000\n",
      "Epoch: 1/20.. Loss: 0.2090.. Test accuracy: 0.0104.. 0.0111 s/batch  steps 17.0000\n",
      "Epoch: 1/20.. Loss: 0.5055.. Test accuracy: 0.0306.. 0.0094 s/batch  steps 18.0000\n",
      "Epoch: 1/20.. Loss: 0.7177.. Test accuracy: 0.0377.. 0.0094 s/batch  steps 19.0000\n",
      "Epoch: 1/20.. Loss: 0.1552.. Test accuracy: 0.0267.. 0.0097 s/batch  steps 20.0000\n",
      "Epoch: 1/20.. Loss: 0.2518.. Test accuracy: 0.0085.. 0.0085 s/batch  steps 21.0000\n",
      "Epoch: 1/20.. Loss: 0.0842.. Test accuracy: 0.0445.. 0.0105 s/batch  steps 22.0000\n",
      "Epoch: 1/20.. Loss: 0.2211.. Test accuracy: 0.0075.. 0.0086 s/batch  steps 23.0000\n",
      "Epoch: 1/20.. Loss: 0.5579.. Test accuracy: 0.0184.. 0.0085 s/batch  steps 24.0000\n",
      "Epoch: 1/20.. Loss: 0.2904.. Test accuracy: 0.0208.. 0.0087 s/batch  steps 25.0000\n",
      "Epoch: 2/20.. Loss: 0.0989.. Test accuracy: 0.0216.. 0.0098 s/batch  steps 26.0000\n",
      "Epoch: 2/20.. Loss: 0.4155.. Test accuracy: 0.0002.. 0.0113 s/batch  steps 27.0000\n",
      "Epoch: 2/20.. Loss: 0.3710.. Test accuracy: 0.0190.. 0.0104 s/batch  steps 28.0000\n",
      "Epoch: 2/20.. Loss: 0.2415.. Test accuracy: 0.0122.. 0.0102 s/batch  steps 29.0000\n",
      "Epoch: 2/20.. Loss: 0.1061.. Test accuracy: 0.0282.. 0.0109 s/batch  steps 30.0000\n",
      "Epoch: 2/20.. Loss: 0.0996.. Test accuracy: 0.0190.. 0.0104 s/batch  steps 31.0000\n",
      "Epoch: 2/20.. Loss: 0.1755.. Test accuracy: 0.0198.. 0.0133 s/batch  steps 32.0000\n",
      "Epoch: 2/20.. Loss: 0.2169.. Test accuracy: 0.0239.. 0.0116 s/batch  steps 33.0000\n",
      "Epoch: 2/20.. Loss: 0.2904.. Test accuracy: 0.0282.. 0.0111 s/batch  steps 34.0000\n",
      "Epoch: 2/20.. Loss: 0.1112.. Test accuracy: 0.0105.. 0.0114 s/batch  steps 35.0000\n",
      "Epoch: 2/20.. Loss: 0.0542.. Test accuracy: 0.0341.. 0.0130 s/batch  steps 36.0000\n",
      "Epoch: 2/20.. Loss: 0.2740.. Test accuracy: 0.0211.. 0.0103 s/batch  steps 37.0000\n",
      "Epoch: 2/20.. Loss: 0.1252.. Test accuracy: 0.0239.. 0.0105 s/batch  steps 38.0000\n",
      "Epoch: 2/20.. Loss: 0.0867.. Test accuracy: 0.0072.. 0.0110 s/batch  steps 39.0000\n",
      "Epoch: 2/20.. Loss: 0.2630.. Test accuracy: 0.0203.. 0.0116 s/batch  steps 40.0000\n",
      "Epoch: 2/20.. Loss: 0.2761.. Test accuracy: 0.0281.. 0.0128 s/batch  steps 41.0000\n",
      "Epoch: 2/20.. Loss: 0.1897.. Test accuracy: 0.0193.. 0.0115 s/batch  steps 42.0000\n",
      "Epoch: 2/20.. Loss: 0.0678.. Test accuracy: 0.0153.. 0.0114 s/batch  steps 43.0000\n",
      "Epoch: 2/20.. Loss: 0.0551.. Test accuracy: 0.0278.. 0.0108 s/batch  steps 44.0000\n",
      "Epoch: 2/20.. Loss: 0.1058.. Test accuracy: 0.0177.. 0.0126 s/batch  steps 45.0000\n",
      "Epoch: 2/20.. Loss: 0.0791.. Test accuracy: 0.0151.. 0.0107 s/batch  steps 46.0000\n",
      "Epoch: 2/20.. Loss: 0.1648.. Test accuracy: 0.0140.. 0.0112 s/batch  steps 47.0000\n",
      "Epoch: 2/20.. Loss: 0.1049.. Test accuracy: 0.0147.. 0.0121 s/batch  steps 48.0000\n",
      "Epoch: 2/20.. Loss: 0.1850.. Test accuracy: 0.0206.. 0.0113 s/batch  steps 49.0000\n",
      "Epoch: 2/20.. Loss: 0.0494.. Test accuracy: 0.0298.. 0.0112 s/batch  steps 50.0000\n",
      "Epoch: 3/20.. Loss: 0.0397.. Test accuracy: 0.0105.. 0.0101 s/batch  steps 51.0000\n",
      "Epoch: 3/20.. Loss: 0.0512.. Test accuracy: 0.0313.. 0.0094 s/batch  steps 52.0000\n",
      "Epoch: 3/20.. Loss: 0.1421.. Test accuracy: 0.0168.. 0.0090 s/batch  steps 53.0000\n",
      "Epoch: 3/20.. Loss: 0.1703.. Test accuracy: 0.0143.. 0.0091 s/batch  steps 54.0000\n",
      "Epoch: 3/20.. Loss: 0.0438.. Test accuracy: 0.0296.. 0.0159 s/batch  steps 55.0000\n",
      "Epoch: 3/20.. Loss: 0.0629.. Test accuracy: 0.0133.. 0.0119 s/batch  steps 56.0000\n",
      "Epoch: 3/20.. Loss: 0.0566.. Test accuracy: 0.0466.. 0.0124 s/batch  steps 57.0000\n",
      "Epoch: 3/20.. Loss: 0.1074.. Test accuracy: 0.0243.. 0.0108 s/batch  steps 58.0000\n",
      "Epoch: 3/20.. Loss: 0.0621.. Test accuracy: 0.0215.. 0.0104 s/batch  steps 59.0000\n",
      "Epoch: 3/20.. Loss: 0.0866.. Test accuracy: 0.0142.. 0.0125 s/batch  steps 60.0000\n",
      "Epoch: 3/20.. Loss: 0.2096.. Test accuracy: 0.0128.. 0.0139 s/batch  steps 61.0000\n",
      "Epoch: 3/20.. Loss: 0.0259.. Test accuracy: 0.0335.. 0.0133 s/batch  steps 62.0000\n",
      "Epoch: 3/20.. Loss: 0.1182.. Test accuracy: 0.0263.. 0.0103 s/batch  steps 63.0000\n",
      "Epoch: 3/20.. Loss: 0.0451.. Test accuracy: 0.0100.. 0.0101 s/batch  steps 64.0000\n",
      "Epoch: 3/20.. Loss: 0.0464.. Test accuracy: 0.0202.. 0.0103 s/batch  steps 65.0000\n",
      "Epoch: 3/20.. Loss: 0.1366.. Test accuracy: 0.0315.. 0.0157 s/batch  steps 66.0000\n",
      "Epoch: 3/20.. Loss: 0.0215.. Test accuracy: 0.0261.. 0.0097 s/batch  steps 67.0000\n",
      "Epoch: 3/20.. Loss: 0.0241.. Test accuracy: 0.0225.. 0.0131 s/batch  steps 68.0000\n",
      "Epoch: 3/20.. Loss: 0.1499.. Test accuracy: 0.0200.. 0.0116 s/batch  steps 69.0000\n",
      "Epoch: 3/20.. Loss: 0.1037.. Test accuracy: 0.0246.. 0.0100 s/batch  steps 70.0000\n",
      "Epoch: 3/20.. Loss: 0.0626.. Test accuracy: 0.0134.. 0.0107 s/batch  steps 71.0000\n",
      "Epoch: 3/20.. Loss: 0.0286.. Test accuracy: 0.0095.. 0.0103 s/batch  steps 72.0000\n",
      "Epoch: 3/20.. Loss: 0.1656.. Test accuracy: 0.0330.. 0.0094 s/batch  steps 73.0000\n",
      "Epoch: 3/20.. Loss: 0.1465.. Test accuracy: 0.0274.. 0.0116 s/batch  steps 74.0000\n",
      "Epoch: 3/20.. Loss: 0.1679.. Test accuracy: 0.0209.. 0.0086 s/batch  steps 75.0000\n",
      "Epoch: 4/20.. Loss: 0.1134.. Test accuracy: 0.0191.. 0.0098 s/batch  steps 76.0000\n",
      "Epoch: 4/20.. Loss: 0.0521.. Test accuracy: 0.0326.. 0.0096 s/batch  steps 77.0000\n",
      "Epoch: 4/20.. Loss: 0.0734.. Test accuracy: 0.0187.. 0.0106 s/batch  steps 78.0000\n",
      "Epoch: 4/20.. Loss: 0.0483.. Test accuracy: 0.0415.. 0.0094 s/batch  steps 79.0000\n",
      "Epoch: 4/20.. Loss: 0.0112.. Test accuracy: 0.0187.. 0.0171 s/batch  steps 80.0000\n",
      "Epoch: 4/20.. Loss: 0.0254.. Test accuracy: 0.0136.. 0.0156 s/batch  steps 81.0000\n",
      "Epoch: 4/20.. Loss: 0.0806.. Test accuracy: 0.0081.. 0.0134 s/batch  steps 82.0000\n",
      "Epoch: 4/20.. Loss: 0.1788.. Test accuracy: 0.0095.. 0.0110 s/batch  steps 83.0000\n",
      "Epoch: 4/20.. Loss: 0.0319.. Test accuracy: 0.0273.. 0.0114 s/batch  steps 84.0000\n",
      "Epoch: 4/20.. Loss: 0.0994.. Test accuracy: 0.0159.. 0.0097 s/batch  steps 85.0000\n",
      "Epoch: 4/20.. Loss: 0.2697.. Test accuracy: 0.0403.. 0.0085 s/batch  steps 86.0000\n",
      "Epoch: 4/20.. Loss: 0.0403.. Test accuracy: 0.0201.. 0.0107 s/batch  steps 87.0000\n",
      "Epoch: 4/20.. Loss: 0.1147.. Test accuracy: 0.0218.. 0.0108 s/batch  steps 88.0000\n",
      "Epoch: 4/20.. Loss: 0.0822.. Test accuracy: 0.0244.. 0.0102 s/batch  steps 89.0000\n",
      "Epoch: 4/20.. Loss: 0.1272.. Test accuracy: 0.0280.. 0.0099 s/batch  steps 90.0000\n",
      "Epoch: 4/20.. Loss: 0.0424.. Test accuracy: 0.0197.. 0.0091 s/batch  steps 91.0000\n",
      "Epoch: 4/20.. Loss: 0.0725.. Test accuracy: 0.0289.. 0.0107 s/batch  steps 92.0000\n",
      "Epoch: 4/20.. Loss: 0.0512.. Test accuracy: 0.0259.. 0.0111 s/batch  steps 93.0000\n",
      "Epoch: 4/20.. Loss: 0.0481.. Test accuracy: 0.0186.. 0.0108 s/batch  steps 94.0000\n",
      "Epoch: 4/20.. Loss: 0.0370.. Test accuracy: 0.0126.. 0.0118 s/batch  steps 95.0000\n",
      "Epoch: 4/20.. Loss: 0.0435.. Test accuracy: 0.0243.. 0.0125 s/batch  steps 96.0000\n",
      "Epoch: 4/20.. Loss: 0.0545.. Test accuracy: 0.0178.. 0.0118 s/batch  steps 97.0000\n",
      "Epoch: 4/20.. Loss: 0.1012.. Test accuracy: 0.0261.. 0.0096 s/batch  steps 98.0000\n",
      "Epoch: 4/20.. Loss: 0.0592.. Test accuracy: 0.0190.. 0.0103 s/batch  steps 99.0000\n",
      "Epoch: 4/20.. Loss: 0.0417.. Test accuracy: 0.0258.. 0.0101 s/batch  steps 100.0000\n",
      "Epoch: 5/20.. Loss: 0.0867.. Test accuracy: 0.0247.. 0.0094 s/batch  steps 101.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20.. Loss: 0.1278.. Test accuracy: 0.0373.. 0.0096 s/batch  steps 102.0000\n",
      "Epoch: 5/20.. Loss: 0.0480.. Test accuracy: 0.0127.. 0.0100 s/batch  steps 103.0000\n",
      "Epoch: 5/20.. Loss: 0.0184.. Test accuracy: 0.0157.. 0.0081 s/batch  steps 104.0000\n",
      "Epoch: 5/20.. Loss: 0.0498.. Test accuracy: 0.0170.. 0.0102 s/batch  steps 105.0000\n",
      "Epoch: 5/20.. Loss: 0.0471.. Test accuracy: 0.0177.. 0.0096 s/batch  steps 106.0000\n",
      "Epoch: 5/20.. Loss: 0.0351.. Test accuracy: 0.0180.. 0.0088 s/batch  steps 107.0000\n",
      "Epoch: 5/20.. Loss: 0.0243.. Test accuracy: 0.0329.. 0.0111 s/batch  steps 108.0000\n",
      "Epoch: 5/20.. Loss: 0.0178.. Test accuracy: 0.0128.. 0.0099 s/batch  steps 109.0000\n",
      "Epoch: 5/20.. Loss: 0.0253.. Test accuracy: 0.0096.. 0.0088 s/batch  steps 110.0000\n",
      "Epoch: 5/20.. Loss: 0.0407.. Test accuracy: 0.0339.. 0.0084 s/batch  steps 111.0000\n",
      "Epoch: 5/20.. Loss: 0.0621.. Test accuracy: 0.0137.. 0.0096 s/batch  steps 112.0000\n",
      "Epoch: 5/20.. Loss: 0.0463.. Test accuracy: 0.0075.. 0.0100 s/batch  steps 113.0000\n",
      "Epoch: 5/20.. Loss: 0.0361.. Test accuracy: 0.0260.. 0.0102 s/batch  steps 114.0000\n",
      "Epoch: 5/20.. Loss: 0.0218.. Test accuracy: 0.0251.. 0.0096 s/batch  steps 115.0000\n",
      "Epoch: 5/20.. Loss: 0.1015.. Test accuracy: 0.0217.. 0.0104 s/batch  steps 116.0000\n",
      "Epoch: 5/20.. Loss: 0.0868.. Test accuracy: 0.0270.. 0.0102 s/batch  steps 117.0000\n",
      "Epoch: 5/20.. Loss: 0.1058.. Test accuracy: 0.0002.. 0.0097 s/batch  steps 118.0000\n",
      "Epoch: 5/20.. Loss: 0.1156.. Test accuracy: 0.0122.. 0.0102 s/batch  steps 119.0000\n",
      "Epoch: 5/20.. Loss: 0.0788.. Test accuracy: 0.0158.. 0.0103 s/batch  steps 120.0000\n",
      "Epoch: 5/20.. Loss: 0.0713.. Test accuracy: 0.0124.. 0.0121 s/batch  steps 121.0000\n",
      "Epoch: 5/20.. Loss: 0.0184.. Test accuracy: 0.0096.. 0.0110 s/batch  steps 122.0000\n",
      "Epoch: 5/20.. Loss: 0.0522.. Test accuracy: 0.0263.. 0.0148 s/batch  steps 123.0000\n",
      "Epoch: 5/20.. Loss: 0.1741.. Test accuracy: 0.0165.. 0.0098 s/batch  steps 124.0000\n",
      "Epoch: 5/20.. Loss: 0.0746.. Test accuracy: 0.0004.. 0.0102 s/batch  steps 125.0000\n",
      "Epoch: 6/20.. Loss: 0.1707.. Test accuracy: 0.0367.. 0.0099 s/batch  steps 126.0000\n",
      "Epoch: 6/20.. Loss: 0.0546.. Test accuracy: 0.0241.. 0.0099 s/batch  steps 127.0000\n",
      "Epoch: 6/20.. Loss: 0.0269.. Test accuracy: 0.0225.. 0.0101 s/batch  steps 128.0000\n",
      "Epoch: 6/20.. Loss: 0.0965.. Test accuracy: 0.0224.. 0.0099 s/batch  steps 129.0000\n",
      "Epoch: 6/20.. Loss: 0.2004.. Test accuracy: 0.0100.. 0.0104 s/batch  steps 130.0000\n",
      "Epoch: 6/20.. Loss: 0.0804.. Test accuracy: 0.0401.. 0.0099 s/batch  steps 131.0000\n",
      "Epoch: 6/20.. Loss: 0.0343.. Test accuracy: 0.0242.. 0.0134 s/batch  steps 132.0000\n",
      "Epoch: 6/20.. Loss: 0.0208.. Test accuracy: 0.0054.. 0.0138 s/batch  steps 133.0000\n",
      "Epoch: 6/20.. Loss: 0.0792.. Test accuracy: 0.0160.. 0.0108 s/batch  steps 134.0000\n",
      "Epoch: 6/20.. Loss: 0.0200.. Test accuracy: 0.0255.. 0.0094 s/batch  steps 135.0000\n",
      "Epoch: 6/20.. Loss: 0.1269.. Test accuracy: 0.0114.. 0.0102 s/batch  steps 136.0000\n",
      "Epoch: 6/20.. Loss: 0.0539.. Test accuracy: 0.0200.. 0.0110 s/batch  steps 137.0000\n",
      "Epoch: 6/20.. Loss: 0.0298.. Test accuracy: 0.0090.. 0.0114 s/batch  steps 138.0000\n",
      "Epoch: 6/20.. Loss: 0.0390.. Test accuracy: 0.0223.. 0.0106 s/batch  steps 139.0000\n",
      "Epoch: 6/20.. Loss: 0.0158.. Test accuracy: 0.0160.. 0.0131 s/batch  steps 140.0000\n",
      "Epoch: 6/20.. Loss: 0.0794.. Test accuracy: 0.0200.. 0.0144 s/batch  steps 141.0000\n",
      "Epoch: 6/20.. Loss: 0.0396.. Test accuracy: 0.0306.. 0.0096 s/batch  steps 142.0000\n",
      "Epoch: 6/20.. Loss: 0.0919.. Test accuracy: 0.0095.. 0.0092 s/batch  steps 143.0000\n",
      "Epoch: 6/20.. Loss: 0.0691.. Test accuracy: 0.0226.. 0.0096 s/batch  steps 144.0000\n",
      "Epoch: 6/20.. Loss: 0.0271.. Test accuracy: 0.0272.. 0.0110 s/batch  steps 145.0000\n",
      "Epoch: 6/20.. Loss: 0.1045.. Test accuracy: 0.0265.. 0.0097 s/batch  steps 146.0000\n",
      "Epoch: 6/20.. Loss: 0.1160.. Test accuracy: 0.0153.. 0.0093 s/batch  steps 147.0000\n",
      "Epoch: 6/20.. Loss: 0.0495.. Test accuracy: 0.0235.. 0.0100 s/batch  steps 148.0000\n",
      "Epoch: 6/20.. Loss: 0.0688.. Test accuracy: 0.0218.. 0.0095 s/batch  steps 149.0000\n",
      "Epoch: 6/20.. Loss: 0.0244.. Test accuracy: 0.0305.. 0.0099 s/batch  steps 150.0000\n",
      "Epoch: 7/20.. Loss: 0.1189.. Test accuracy: 0.0208.. 0.0111 s/batch  steps 151.0000\n",
      "Epoch: 7/20.. Loss: 0.0435.. Test accuracy: 0.0352.. 0.0096 s/batch  steps 152.0000\n",
      "Epoch: 7/20.. Loss: 0.1518.. Test accuracy: 0.0283.. 0.0102 s/batch  steps 153.0000\n",
      "Epoch: 7/20.. Loss: 0.0822.. Test accuracy: 0.0458.. 0.0101 s/batch  steps 154.0000\n",
      "Epoch: 7/20.. Loss: 0.0414.. Test accuracy: 0.0113.. 0.0105 s/batch  steps 155.0000\n",
      "Epoch: 7/20.. Loss: 0.0501.. Test accuracy: 0.0084.. 0.0098 s/batch  steps 156.0000\n",
      "Epoch: 7/20.. Loss: 0.0579.. Test accuracy: 0.0106.. 0.0098 s/batch  steps 157.0000\n",
      "Epoch: 7/20.. Loss: 0.1123.. Test accuracy: 0.0002.. 0.0099 s/batch  steps 158.0000\n",
      "Epoch: 7/20.. Loss: 0.0463.. Test accuracy: 0.0089.. 0.0111 s/batch  steps 159.0000\n",
      "Epoch: 7/20.. Loss: 0.0279.. Test accuracy: 0.0115.. 0.0104 s/batch  steps 160.0000\n",
      "Epoch: 7/20.. Loss: 0.0536.. Test accuracy: 0.0231.. 0.0107 s/batch  steps 161.0000\n",
      "Epoch: 7/20.. Loss: 0.0351.. Test accuracy: 0.0196.. 0.0104 s/batch  steps 162.0000\n",
      "Epoch: 7/20.. Loss: 0.0173.. Test accuracy: 0.0391.. 0.0115 s/batch  steps 163.0000\n",
      "Epoch: 7/20.. Loss: 0.0430.. Test accuracy: 0.0036.. 0.0110 s/batch  steps 164.0000\n",
      "Epoch: 7/20.. Loss: 0.0140.. Test accuracy: 0.0104.. 0.0098 s/batch  steps 165.0000\n",
      "Epoch: 7/20.. Loss: 0.0408.. Test accuracy: 0.0223.. 0.0094 s/batch  steps 166.0000\n",
      "Epoch: 7/20.. Loss: 0.1743.. Test accuracy: 0.0171.. 0.0093 s/batch  steps 167.0000\n",
      "Epoch: 7/20.. Loss: 0.0852.. Test accuracy: 0.0267.. 0.0089 s/batch  steps 168.0000\n",
      "Epoch: 7/20.. Loss: 0.0624.. Test accuracy: 0.0099.. 0.0094 s/batch  steps 169.0000\n",
      "Epoch: 7/20.. Loss: 0.0336.. Test accuracy: 0.0254.. 0.0091 s/batch  steps 170.0000\n",
      "Epoch: 7/20.. Loss: 0.0463.. Test accuracy: 0.0053.. 0.0109 s/batch  steps 171.0000\n",
      "Epoch: 7/20.. Loss: 0.0686.. Test accuracy: 0.0120.. 0.0092 s/batch  steps 172.0000\n",
      "Epoch: 7/20.. Loss: 0.0261.. Test accuracy: 0.0380.. 0.0098 s/batch  steps 173.0000\n",
      "Epoch: 7/20.. Loss: 0.0799.. Test accuracy: 0.0106.. 0.0111 s/batch  steps 174.0000\n",
      "Epoch: 7/20.. Loss: 0.0951.. Test accuracy: 0.0146.. 0.0095 s/batch  steps 175.0000\n",
      "Epoch: 8/20.. Loss: 0.0493.. Test accuracy: 0.0247.. 0.0108 s/batch  steps 176.0000\n",
      "Epoch: 8/20.. Loss: 0.0435.. Test accuracy: 0.0365.. 0.0097 s/batch  steps 177.0000\n",
      "Epoch: 8/20.. Loss: 0.0255.. Test accuracy: 0.0054.. 0.0085 s/batch  steps 178.0000\n",
      "Epoch: 8/20.. Loss: 0.0589.. Test accuracy: 0.0340.. 0.0088 s/batch  steps 179.0000\n",
      "Epoch: 8/20.. Loss: 0.0467.. Test accuracy: 0.0307.. 0.0081 s/batch  steps 180.0000\n",
      "Epoch: 8/20.. Loss: 0.0533.. Test accuracy: 0.0129.. 0.0098 s/batch  steps 181.0000\n",
      "Epoch: 8/20.. Loss: 0.0285.. Test accuracy: 0.0341.. 0.0099 s/batch  steps 182.0000\n",
      "Epoch: 8/20.. Loss: 0.0974.. Test accuracy: 0.0234.. 0.0102 s/batch  steps 183.0000\n",
      "Epoch: 8/20.. Loss: 0.0447.. Test accuracy: 0.0192.. 0.0090 s/batch  steps 184.0000\n",
      "Epoch: 8/20.. Loss: 0.1241.. Test accuracy: 0.0142.. 0.0095 s/batch  steps 185.0000\n",
      "Epoch: 8/20.. Loss: 0.0401.. Test accuracy: 0.0317.. 0.0102 s/batch  steps 186.0000\n",
      "Epoch: 8/20.. Loss: 0.0494.. Test accuracy: 0.0171.. 0.0138 s/batch  steps 187.0000\n",
      "Epoch: 8/20.. Loss: 0.2132.. Test accuracy: 0.0219.. 0.0114 s/batch  steps 188.0000\n",
      "Epoch: 8/20.. Loss: 0.0744.. Test accuracy: 0.0298.. 0.0107 s/batch  steps 189.0000\n",
      "Epoch: 8/20.. Loss: 0.0294.. Test accuracy: 0.0218.. 0.0119 s/batch  steps 190.0000\n",
      "Epoch: 8/20.. Loss: 0.0160.. Test accuracy: 0.0269.. 0.0113 s/batch  steps 191.0000\n",
      "Epoch: 8/20.. Loss: 0.0593.. Test accuracy: 0.0097.. 0.0118 s/batch  steps 192.0000\n",
      "Epoch: 8/20.. Loss: 0.0581.. Test accuracy: 0.0108.. 0.0106 s/batch  steps 193.0000\n",
      "Epoch: 8/20.. Loss: 0.0329.. Test accuracy: 0.0192.. 0.0135 s/batch  steps 194.0000\n",
      "Epoch: 8/20.. Loss: 0.0181.. Test accuracy: 0.0230.. 0.0102 s/batch  steps 195.0000\n",
      "Epoch: 8/20.. Loss: 0.0333.. Test accuracy: 0.0127.. 0.0116 s/batch  steps 196.0000\n",
      "Epoch: 8/20.. Loss: 0.0676.. Test accuracy: 0.0093.. 0.0116 s/batch  steps 197.0000\n",
      "Epoch: 8/20.. Loss: 0.0537.. Test accuracy: 0.0138.. 0.0117 s/batch  steps 198.0000\n",
      "Epoch: 8/20.. Loss: 0.0403.. Test accuracy: 0.0151.. 0.0139 s/batch  steps 199.0000\n",
      "Epoch: 8/20.. Loss: 0.1565.. Test accuracy: 0.0218.. 0.0115 s/batch  steps 200.0000\n",
      "Epoch: 9/20.. Loss: 0.0381.. Test accuracy: 0.0218.. 0.0125 s/batch  steps 201.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20.. Loss: 0.0292.. Test accuracy: 0.0218.. 0.0117 s/batch  steps 202.0000\n",
      "Epoch: 9/20.. Loss: 0.0465.. Test accuracy: 0.0099.. 0.0109 s/batch  steps 203.0000\n",
      "Epoch: 9/20.. Loss: 0.0434.. Test accuracy: 0.0263.. 0.0151 s/batch  steps 204.0000\n",
      "Epoch: 9/20.. Loss: 0.0127.. Test accuracy: 0.0138.. 0.0094 s/batch  steps 205.0000\n",
      "Epoch: 9/20.. Loss: 0.0507.. Test accuracy: 0.0220.. 0.0100 s/batch  steps 206.0000\n",
      "Epoch: 9/20.. Loss: 0.0962.. Test accuracy: 0.0310.. 0.0102 s/batch  steps 207.0000\n",
      "Epoch: 9/20.. Loss: 0.0250.. Test accuracy: 0.0130.. 0.0130 s/batch  steps 208.0000\n",
      "Epoch: 9/20.. Loss: 0.1770.. Test accuracy: 0.0168.. 0.0122 s/batch  steps 209.0000\n",
      "Epoch: 9/20.. Loss: 0.0204.. Test accuracy: 0.0330.. 0.0141 s/batch  steps 210.0000\n",
      "Epoch: 9/20.. Loss: 0.0412.. Test accuracy: 0.0201.. 0.0111 s/batch  steps 211.0000\n",
      "Epoch: 9/20.. Loss: 0.0462.. Test accuracy: 0.0208.. 0.0122 s/batch  steps 212.0000\n",
      "Epoch: 9/20.. Loss: 0.0927.. Test accuracy: 0.0311.. 0.0129 s/batch  steps 213.0000\n",
      "Epoch: 9/20.. Loss: 0.0713.. Test accuracy: 0.0045.. 0.0130 s/batch  steps 214.0000\n",
      "Epoch: 9/20.. Loss: 0.0229.. Test accuracy: 0.0053.. 0.0097 s/batch  steps 215.0000\n",
      "Epoch: 9/20.. Loss: 0.0389.. Test accuracy: 0.0166.. 0.0096 s/batch  steps 216.0000\n",
      "Epoch: 9/20.. Loss: 0.0311.. Test accuracy: 0.0129.. 0.0100 s/batch  steps 217.0000\n",
      "Epoch: 9/20.. Loss: 0.0137.. Test accuracy: 0.0291.. 0.0099 s/batch  steps 218.0000\n",
      "Epoch: 9/20.. Loss: 0.0368.. Test accuracy: 0.0174.. 0.0088 s/batch  steps 219.0000\n",
      "Epoch: 9/20.. Loss: 0.1083.. Test accuracy: 0.0223.. 0.0100 s/batch  steps 220.0000\n",
      "Epoch: 9/20.. Loss: 0.0367.. Test accuracy: 0.0265.. 0.0094 s/batch  steps 221.0000\n",
      "Epoch: 9/20.. Loss: 0.0287.. Test accuracy: 0.0268.. 0.0101 s/batch  steps 222.0000\n",
      "Epoch: 9/20.. Loss: 0.0402.. Test accuracy: 0.0168.. 0.0089 s/batch  steps 223.0000\n",
      "Epoch: 9/20.. Loss: 0.0254.. Test accuracy: 0.0279.. 0.0107 s/batch  steps 224.0000\n",
      "Epoch: 9/20.. Loss: 0.0453.. Test accuracy: 0.0268.. 0.0096 s/batch  steps 225.0000\n",
      "Epoch: 10/20.. Loss: 0.0277.. Test accuracy: 0.0212.. 0.0089 s/batch  steps 226.0000\n",
      "Epoch: 10/20.. Loss: 0.0232.. Test accuracy: 0.0231.. 0.0100 s/batch  steps 227.0000\n",
      "Epoch: 10/20.. Loss: 0.0096.. Test accuracy: 0.0207.. 0.0098 s/batch  steps 228.0000\n",
      "Epoch: 10/20.. Loss: 0.0380.. Test accuracy: 0.0052.. 0.0095 s/batch  steps 229.0000\n",
      "Epoch: 10/20.. Loss: 0.1620.. Test accuracy: 0.0149.. 0.0101 s/batch  steps 230.0000\n",
      "Epoch: 10/20.. Loss: 0.0610.. Test accuracy: 0.0084.. 0.0101 s/batch  steps 231.0000\n",
      "Epoch: 10/20.. Loss: 0.0360.. Test accuracy: 0.0054.. 0.0083 s/batch  steps 232.0000\n",
      "Epoch: 10/20.. Loss: 0.0149.. Test accuracy: 0.0037.. 0.0101 s/batch  steps 233.0000\n",
      "Epoch: 10/20.. Loss: 0.0459.. Test accuracy: 0.0226.. 0.0111 s/batch  steps 234.0000\n",
      "Epoch: 10/20.. Loss: 0.0175.. Test accuracy: 0.0168.. 0.0147 s/batch  steps 235.0000\n",
      "Epoch: 10/20.. Loss: 0.0146.. Test accuracy: 0.0167.. 0.0204 s/batch  steps 236.0000\n",
      "Epoch: 10/20.. Loss: 0.0231.. Test accuracy: 0.0144.. 0.0092 s/batch  steps 237.0000\n",
      "Epoch: 10/20.. Loss: 0.0151.. Test accuracy: 0.0182.. 0.0093 s/batch  steps 238.0000\n",
      "Epoch: 10/20.. Loss: 0.0989.. Test accuracy: 0.0390.. 0.0092 s/batch  steps 239.0000\n",
      "Epoch: 10/20.. Loss: 0.0189.. Test accuracy: 0.0300.. 0.0096 s/batch  steps 240.0000\n",
      "Epoch: 10/20.. Loss: 0.0621.. Test accuracy: 0.0150.. 0.0092 s/batch  steps 241.0000\n",
      "Epoch: 10/20.. Loss: 0.0362.. Test accuracy: 0.0103.. 0.0098 s/batch  steps 242.0000\n",
      "Epoch: 10/20.. Loss: 0.0701.. Test accuracy: 0.0265.. 0.0109 s/batch  steps 243.0000\n",
      "Epoch: 10/20.. Loss: 0.1114.. Test accuracy: 0.0280.. 0.0100 s/batch  steps 244.0000\n",
      "Epoch: 10/20.. Loss: 0.0580.. Test accuracy: 0.0176.. 0.0099 s/batch  steps 245.0000\n",
      "Epoch: 10/20.. Loss: 0.0189.. Test accuracy: 0.0178.. 0.0120 s/batch  steps 246.0000\n",
      "Epoch: 10/20.. Loss: 0.0141.. Test accuracy: 0.0384.. 0.0169 s/batch  steps 247.0000\n",
      "Epoch: 10/20.. Loss: 0.0916.. Test accuracy: 0.0316.. 0.0109 s/batch  steps 248.0000\n",
      "Epoch: 10/20.. Loss: 0.0478.. Test accuracy: 0.0277.. 0.0097 s/batch  steps 249.0000\n",
      "Epoch: 10/20.. Loss: 0.0233.. Test accuracy: 0.0322.. 0.0096 s/batch  steps 250.0000\n",
      "Epoch: 11/20.. Loss: 0.0025.. Test accuracy: 0.0255.. 0.0100 s/batch  steps 251.0000\n",
      "Epoch: 11/20.. Loss: 0.0879.. Test accuracy: 0.0393.. 0.0092 s/batch  steps 252.0000\n",
      "Epoch: 11/20.. Loss: 0.0437.. Test accuracy: 0.0454.. 0.0104 s/batch  steps 253.0000\n",
      "Epoch: 11/20.. Loss: 0.0684.. Test accuracy: 0.0324.. 0.0105 s/batch  steps 254.0000\n",
      "Epoch: 11/20.. Loss: 0.0186.. Test accuracy: 0.0278.. 0.0094 s/batch  steps 255.0000\n",
      "Epoch: 11/20.. Loss: 0.0121.. Test accuracy: 0.0243.. 0.0104 s/batch  steps 256.0000\n",
      "Epoch: 11/20.. Loss: 0.0199.. Test accuracy: 0.0244.. 0.0105 s/batch  steps 257.0000\n",
      "Epoch: 11/20.. Loss: 0.0220.. Test accuracy: 0.0346.. 0.0108 s/batch  steps 258.0000\n",
      "Epoch: 11/20.. Loss: 0.0439.. Test accuracy: 0.0133.. 0.0104 s/batch  steps 259.0000\n",
      "Epoch: 11/20.. Loss: 0.0377.. Test accuracy: 0.0300.. 0.0089 s/batch  steps 260.0000\n",
      "Epoch: 11/20.. Loss: 0.0337.. Test accuracy: 0.0239.. 0.0100 s/batch  steps 261.0000\n",
      "Epoch: 11/20.. Loss: 0.0451.. Test accuracy: 0.0184.. 0.0144 s/batch  steps 262.0000\n",
      "Epoch: 11/20.. Loss: 0.0369.. Test accuracy: 0.0224.. 0.0147 s/batch  steps 263.0000\n",
      "Epoch: 11/20.. Loss: 0.0270.. Test accuracy: 0.0301.. 0.0170 s/batch  steps 264.0000\n",
      "Epoch: 11/20.. Loss: 0.0195.. Test accuracy: 0.0223.. 0.0127 s/batch  steps 265.0000\n",
      "Epoch: 11/20.. Loss: 0.0295.. Test accuracy: 0.0024.. 0.0135 s/batch  steps 266.0000\n",
      "Epoch: 11/20.. Loss: 0.0317.. Test accuracy: 0.0253.. 0.0134 s/batch  steps 267.0000\n",
      "Epoch: 11/20.. Loss: 0.0266.. Test accuracy: 0.0201.. 0.0112 s/batch  steps 268.0000\n",
      "Epoch: 11/20.. Loss: 0.0392.. Test accuracy: 0.0265.. 0.0103 s/batch  steps 269.0000\n",
      "Epoch: 11/20.. Loss: 0.0239.. Test accuracy: 0.0300.. 0.0085 s/batch  steps 270.0000\n",
      "Epoch: 11/20.. Loss: 0.0930.. Test accuracy: 0.0071.. 0.0104 s/batch  steps 271.0000\n",
      "Epoch: 11/20.. Loss: 0.0353.. Test accuracy: 0.0177.. 0.0094 s/batch  steps 272.0000\n",
      "Epoch: 11/20.. Loss: 0.1455.. Test accuracy: 0.0303.. 0.0096 s/batch  steps 273.0000\n",
      "Epoch: 11/20.. Loss: 0.1316.. Test accuracy: 0.0309.. 0.0085 s/batch  steps 274.0000\n",
      "Epoch: 11/20.. Loss: 0.0064.. Test accuracy: 0.0263.. 0.0109 s/batch  steps 275.0000\n",
      "Epoch: 12/20.. Loss: 0.1652.. Test accuracy: 0.0250.. 0.0124 s/batch  steps 276.0000\n",
      "Epoch: 12/20.. Loss: 0.0891.. Test accuracy: 0.0377.. 0.0159 s/batch  steps 277.0000\n",
      "Epoch: 12/20.. Loss: 0.0493.. Test accuracy: 0.0124.. 0.0131 s/batch  steps 278.0000\n",
      "Epoch: 12/20.. Loss: 0.0468.. Test accuracy: 0.0158.. 0.0111 s/batch  steps 279.0000\n",
      "Epoch: 12/20.. Loss: 0.0443.. Test accuracy: 0.0188.. 0.0095 s/batch  steps 280.0000\n",
      "Epoch: 12/20.. Loss: 0.0763.. Test accuracy: 0.0192.. 0.0099 s/batch  steps 281.0000\n",
      "Epoch: 12/20.. Loss: 0.0087.. Test accuracy: 0.0168.. 0.0169 s/batch  steps 282.0000\n",
      "Epoch: 12/20.. Loss: 0.0480.. Test accuracy: 0.0162.. 0.0168 s/batch  steps 283.0000\n",
      "Epoch: 12/20.. Loss: 0.0556.. Test accuracy: 0.0346.. 0.0142 s/batch  steps 284.0000\n",
      "Epoch: 12/20.. Loss: 0.0199.. Test accuracy: 0.0368.. 0.0127 s/batch  steps 285.0000\n",
      "Epoch: 12/20.. Loss: 0.0210.. Test accuracy: 0.0317.. 0.0124 s/batch  steps 286.0000\n",
      "Epoch: 12/20.. Loss: 0.0462.. Test accuracy: 0.0235.. 0.0114 s/batch  steps 287.0000\n",
      "Epoch: 12/20.. Loss: 0.0339.. Test accuracy: 0.0240.. 0.0124 s/batch  steps 288.0000\n",
      "Epoch: 12/20.. Loss: 0.0163.. Test accuracy: 0.0281.. 0.0107 s/batch  steps 289.0000\n",
      "Epoch: 12/20.. Loss: 0.0126.. Test accuracy: 0.0335.. 0.0118 s/batch  steps 290.0000\n",
      "Epoch: 12/20.. Loss: 0.0368.. Test accuracy: 0.0109.. 0.0118 s/batch  steps 291.0000\n",
      "Epoch: 12/20.. Loss: 0.0315.. Test accuracy: 0.0247.. 0.0128 s/batch  steps 292.0000\n",
      "Epoch: 12/20.. Loss: 0.0344.. Test accuracy: 0.0106.. 0.0118 s/batch  steps 293.0000\n",
      "Epoch: 12/20.. Loss: 0.0213.. Test accuracy: 0.0339.. 0.0129 s/batch  steps 294.0000\n",
      "Epoch: 12/20.. Loss: 0.0209.. Test accuracy: 0.0079.. 0.0128 s/batch  steps 295.0000\n",
      "Epoch: 12/20.. Loss: 0.0288.. Test accuracy: 0.0018.. 0.0132 s/batch  steps 296.0000\n",
      "Epoch: 12/20.. Loss: 0.1006.. Test accuracy: 0.0081.. 0.0129 s/batch  steps 297.0000\n",
      "Epoch: 12/20.. Loss: 0.0556.. Test accuracy: 0.0086.. 0.0108 s/batch  steps 298.0000\n",
      "Epoch: 12/20.. Loss: 0.0356.. Test accuracy: 0.0209.. 0.0107 s/batch  steps 299.0000\n",
      "Epoch: 12/20.. Loss: 0.0141.. Test accuracy: 0.0201.. 0.0112 s/batch  steps 300.0000\n",
      "Epoch: 13/20.. Loss: 0.0435.. Test accuracy: 0.0390.. 0.0121 s/batch  steps 301.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20.. Loss: 0.0573.. Test accuracy: 0.0367.. 0.0125 s/batch  steps 302.0000\n",
      "Epoch: 13/20.. Loss: 0.0370.. Test accuracy: 0.0324.. 0.0109 s/batch  steps 303.0000\n",
      "Epoch: 13/20.. Loss: 0.0140.. Test accuracy: 0.0153.. 0.0095 s/batch  steps 304.0000\n",
      "Epoch: 13/20.. Loss: 0.0427.. Test accuracy: 0.0271.. 0.0095 s/batch  steps 305.0000\n",
      "Epoch: 13/20.. Loss: 0.0359.. Test accuracy: 0.0296.. 0.0095 s/batch  steps 306.0000\n",
      "Epoch: 13/20.. Loss: 0.0302.. Test accuracy: 0.0149.. 0.0107 s/batch  steps 307.0000\n",
      "Epoch: 13/20.. Loss: 0.0142.. Test accuracy: 0.0305.. 0.0104 s/batch  steps 308.0000\n",
      "Epoch: 13/20.. Loss: 0.0786.. Test accuracy: 0.0064.. 0.0100 s/batch  steps 309.0000\n",
      "Epoch: 13/20.. Loss: 0.0441.. Test accuracy: 0.0228.. 0.0102 s/batch  steps 310.0000\n",
      "Epoch: 13/20.. Loss: 0.0328.. Test accuracy: 0.0092.. 0.0099 s/batch  steps 311.0000\n",
      "Epoch: 13/20.. Loss: 0.0247.. Test accuracy: 0.0128.. 0.0102 s/batch  steps 312.0000\n",
      "Epoch: 13/20.. Loss: 0.0206.. Test accuracy: 0.0161.. 0.0102 s/batch  steps 313.0000\n",
      "Epoch: 13/20.. Loss: 0.0218.. Test accuracy: 0.0255.. 0.0115 s/batch  steps 314.0000\n",
      "Epoch: 13/20.. Loss: 0.0149.. Test accuracy: 0.0045.. 0.0102 s/batch  steps 315.0000\n",
      "Epoch: 13/20.. Loss: 0.0289.. Test accuracy: 0.0122.. 0.0132 s/batch  steps 316.0000\n",
      "Epoch: 13/20.. Loss: 0.0444.. Test accuracy: 0.0303.. 0.0121 s/batch  steps 317.0000\n",
      "Epoch: 13/20.. Loss: 0.0243.. Test accuracy: 0.0106.. 0.0119 s/batch  steps 318.0000\n",
      "Epoch: 13/20.. Loss: 0.0184.. Test accuracy: 0.0308.. 0.0105 s/batch  steps 319.0000\n",
      "Epoch: 13/20.. Loss: 0.0836.. Test accuracy: 0.0151.. 0.0113 s/batch  steps 320.0000\n",
      "Epoch: 13/20.. Loss: 0.1542.. Test accuracy: 0.0207.. 0.0124 s/batch  steps 321.0000\n",
      "Epoch: 13/20.. Loss: 0.0485.. Test accuracy: 0.0075.. 0.0096 s/batch  steps 322.0000\n",
      "Epoch: 13/20.. Loss: 0.0144.. Test accuracy: 0.0195.. 0.0096 s/batch  steps 323.0000\n",
      "Epoch: 13/20.. Loss: 0.0816.. Test accuracy: 0.0235.. 0.0103 s/batch  steps 324.0000\n",
      "Epoch: 13/20.. Loss: 0.0475.. Test accuracy: 0.0165.. 0.0112 s/batch  steps 325.0000\n",
      "Epoch: 14/20.. Loss: 0.0256.. Test accuracy: 0.0195.. 0.0111 s/batch  steps 326.0000\n",
      "Epoch: 14/20.. Loss: 0.0509.. Test accuracy: 0.0029.. 0.0112 s/batch  steps 327.0000\n",
      "Epoch: 14/20.. Loss: 0.0507.. Test accuracy: 0.0165.. 0.0110 s/batch  steps 328.0000\n",
      "Epoch: 14/20.. Loss: 0.0711.. Test accuracy: 0.0076.. 0.0102 s/batch  steps 329.0000\n",
      "Epoch: 14/20.. Loss: 0.0597.. Test accuracy: 0.0274.. 0.0087 s/batch  steps 330.0000\n",
      "Epoch: 14/20.. Loss: 0.0237.. Test accuracy: 0.0274.. 0.0107 s/batch  steps 331.0000\n",
      "Epoch: 14/20.. Loss: 0.0286.. Test accuracy: 0.0221.. 0.0100 s/batch  steps 332.0000\n",
      "Epoch: 14/20.. Loss: 0.0419.. Test accuracy: 0.0317.. 0.0103 s/batch  steps 333.0000\n",
      "Epoch: 14/20.. Loss: 0.0790.. Test accuracy: 0.0106.. 0.0102 s/batch  steps 334.0000\n",
      "Epoch: 14/20.. Loss: 0.0904.. Test accuracy: 0.0357.. 0.0098 s/batch  steps 335.0000\n",
      "Epoch: 14/20.. Loss: 0.0802.. Test accuracy: 0.0305.. 0.0102 s/batch  steps 336.0000\n",
      "Epoch: 14/20.. Loss: 0.0272.. Test accuracy: 0.0245.. 0.0097 s/batch  steps 337.0000\n",
      "Epoch: 14/20.. Loss: 0.0268.. Test accuracy: 0.0270.. 0.0096 s/batch  steps 338.0000\n",
      "Epoch: 14/20.. Loss: 0.0347.. Test accuracy: 0.0353.. 0.0102 s/batch  steps 339.0000\n",
      "Epoch: 14/20.. Loss: 0.0251.. Test accuracy: 0.0083.. 0.0110 s/batch  steps 340.0000\n",
      "Epoch: 14/20.. Loss: 0.0479.. Test accuracy: 0.0187.. 0.0092 s/batch  steps 341.0000\n",
      "Epoch: 14/20.. Loss: 0.1950.. Test accuracy: 0.0106.. 0.0083 s/batch  steps 342.0000\n",
      "Epoch: 14/20.. Loss: 0.0419.. Test accuracy: 0.0353.. 0.0086 s/batch  steps 343.0000\n",
      "Epoch: 14/20.. Loss: 0.0301.. Test accuracy: 0.0178.. 0.0086 s/batch  steps 344.0000\n",
      "Epoch: 14/20.. Loss: 0.0296.. Test accuracy: 0.0135.. 0.0110 s/batch  steps 345.0000\n",
      "Epoch: 14/20.. Loss: 0.0122.. Test accuracy: 0.0340.. 0.0112 s/batch  steps 346.0000\n",
      "Epoch: 14/20.. Loss: 0.0124.. Test accuracy: 0.0175.. 0.0132 s/batch  steps 347.0000\n",
      "Epoch: 14/20.. Loss: 0.0244.. Test accuracy: 0.0272.. 0.0128 s/batch  steps 348.0000\n",
      "Epoch: 14/20.. Loss: 0.0067.. Test accuracy: 0.0261.. 0.0131 s/batch  steps 349.0000\n",
      "Epoch: 14/20.. Loss: 0.0192.. Test accuracy: 0.0209.. 0.0126 s/batch  steps 350.0000\n",
      "Epoch: 15/20.. Loss: 0.0911.. Test accuracy: 0.0240.. 0.0118 s/batch  steps 351.0000\n",
      "Epoch: 15/20.. Loss: 0.0169.. Test accuracy: 0.0252.. 0.0124 s/batch  steps 352.0000\n",
      "Epoch: 15/20.. Loss: 0.0643.. Test accuracy: 0.0235.. 0.0104 s/batch  steps 353.0000\n",
      "Epoch: 15/20.. Loss: 0.1383.. Test accuracy: 0.0225.. 0.0083 s/batch  steps 354.0000\n",
      "Epoch: 15/20.. Loss: 0.0454.. Test accuracy: 0.0104.. 0.0103 s/batch  steps 355.0000\n",
      "Epoch: 15/20.. Loss: 0.0224.. Test accuracy: 0.0183.. 0.0098 s/batch  steps 356.0000\n",
      "Epoch: 15/20.. Loss: 0.0514.. Test accuracy: 0.0293.. 0.0098 s/batch  steps 357.0000\n",
      "Epoch: 15/20.. Loss: 0.0161.. Test accuracy: 0.0107.. 0.0102 s/batch  steps 358.0000\n",
      "Epoch: 15/20.. Loss: 0.0401.. Test accuracy: 0.0138.. 0.0102 s/batch  steps 359.0000\n",
      "Epoch: 15/20.. Loss: 0.0476.. Test accuracy: 0.0169.. 0.0143 s/batch  steps 360.0000\n",
      "Epoch: 15/20.. Loss: 0.0203.. Test accuracy: 0.0198.. 0.0120 s/batch  steps 361.0000\n",
      "Epoch: 15/20.. Loss: 0.0179.. Test accuracy: 0.0259.. 0.0114 s/batch  steps 362.0000\n",
      "Epoch: 15/20.. Loss: 0.0439.. Test accuracy: 0.0165.. 0.0118 s/batch  steps 363.0000\n",
      "Epoch: 15/20.. Loss: 0.0117.. Test accuracy: 0.0180.. 0.0139 s/batch  steps 364.0000\n",
      "Epoch: 15/20.. Loss: 0.0231.. Test accuracy: 0.0088.. 0.0101 s/batch  steps 365.0000\n",
      "Epoch: 15/20.. Loss: 0.0132.. Test accuracy: 0.0307.. 0.0110 s/batch  steps 366.0000\n",
      "Epoch: 15/20.. Loss: 0.0311.. Test accuracy: 0.0219.. 0.0105 s/batch  steps 367.0000\n",
      "Epoch: 15/20.. Loss: 0.0525.. Test accuracy: 0.0195.. 0.0107 s/batch  steps 368.0000\n",
      "Epoch: 15/20.. Loss: 0.0128.. Test accuracy: 0.0189.. 0.0107 s/batch  steps 369.0000\n",
      "Epoch: 15/20.. Loss: 0.1012.. Test accuracy: 0.0189.. 0.0104 s/batch  steps 370.0000\n",
      "Epoch: 15/20.. Loss: 0.0278.. Test accuracy: 0.0077.. 0.0126 s/batch  steps 371.0000\n",
      "Epoch: 15/20.. Loss: 0.0175.. Test accuracy: 0.0274.. 0.0106 s/batch  steps 372.0000\n",
      "Epoch: 15/20.. Loss: 0.0249.. Test accuracy: 0.0309.. 0.0126 s/batch  steps 373.0000\n",
      "Epoch: 15/20.. Loss: 0.0145.. Test accuracy: 0.0248.. 0.0138 s/batch  steps 374.0000\n",
      "Epoch: 15/20.. Loss: 0.0777.. Test accuracy: 0.0310.. 0.0140 s/batch  steps 375.0000\n",
      "Epoch: 16/20.. Loss: 0.0423.. Test accuracy: 0.0194.. 0.0149 s/batch  steps 376.0000\n",
      "Epoch: 16/20.. Loss: 0.0439.. Test accuracy: 0.0156.. 0.0139 s/batch  steps 377.0000\n",
      "Epoch: 16/20.. Loss: 0.0250.. Test accuracy: 0.0252.. 0.0118 s/batch  steps 378.0000\n",
      "Epoch: 16/20.. Loss: 0.0300.. Test accuracy: 0.0189.. 0.0113 s/batch  steps 379.0000\n",
      "Epoch: 16/20.. Loss: 0.0151.. Test accuracy: 0.0190.. 0.0103 s/batch  steps 380.0000\n",
      "Epoch: 16/20.. Loss: 0.0904.. Test accuracy: 0.0267.. 0.0093 s/batch  steps 381.0000\n",
      "Epoch: 16/20.. Loss: 0.0477.. Test accuracy: 0.0304.. 0.0096 s/batch  steps 382.0000\n",
      "Epoch: 16/20.. Loss: 0.0267.. Test accuracy: 0.0141.. 0.0101 s/batch  steps 383.0000\n",
      "Epoch: 16/20.. Loss: 0.0162.. Test accuracy: 0.0328.. 0.0098 s/batch  steps 384.0000\n",
      "Epoch: 16/20.. Loss: 0.1405.. Test accuracy: 0.0210.. 0.0084 s/batch  steps 385.0000\n",
      "Epoch: 16/20.. Loss: 0.0233.. Test accuracy: 0.0196.. 0.0102 s/batch  steps 386.0000\n",
      "Epoch: 16/20.. Loss: 0.2119.. Test accuracy: 0.0094.. 0.0086 s/batch  steps 387.0000\n",
      "Epoch: 16/20.. Loss: 0.0239.. Test accuracy: 0.0234.. 0.0100 s/batch  steps 388.0000\n",
      "Epoch: 16/20.. Loss: 0.0205.. Test accuracy: 0.0037.. 0.0164 s/batch  steps 389.0000\n",
      "Epoch: 16/20.. Loss: 0.0254.. Test accuracy: 0.0292.. 0.0178 s/batch  steps 390.0000\n",
      "Epoch: 16/20.. Loss: 0.0382.. Test accuracy: 0.0214.. 0.0125 s/batch  steps 391.0000\n",
      "Epoch: 16/20.. Loss: 0.0562.. Test accuracy: 0.0145.. 0.0107 s/batch  steps 392.0000\n",
      "Epoch: 16/20.. Loss: 0.0025.. Test accuracy: 0.0264.. 0.0095 s/batch  steps 393.0000\n",
      "Epoch: 16/20.. Loss: 0.0128.. Test accuracy: 0.0095.. 0.0103 s/batch  steps 394.0000\n",
      "Epoch: 16/20.. Loss: 0.0140.. Test accuracy: 0.0234.. 0.0115 s/batch  steps 395.0000\n",
      "Epoch: 16/20.. Loss: 0.0205.. Test accuracy: 0.0202.. 0.0116 s/batch  steps 396.0000\n",
      "Epoch: 16/20.. Loss: 0.0229.. Test accuracy: 0.0149.. 0.0108 s/batch  steps 397.0000\n",
      "Epoch: 16/20.. Loss: 0.0491.. Test accuracy: 0.0242.. 0.0098 s/batch  steps 398.0000\n",
      "Epoch: 16/20.. Loss: 0.0326.. Test accuracy: 0.0255.. 0.0104 s/batch  steps 399.0000\n",
      "Epoch: 16/20.. Loss: 0.0301.. Test accuracy: 0.0159.. 0.0101 s/batch  steps 400.0000\n",
      "Epoch: 17/20.. Loss: 0.0144.. Test accuracy: 0.0235.. 0.0097 s/batch  steps 401.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20.. Loss: 0.0350.. Test accuracy: 0.0254.. 0.0109 s/batch  steps 402.0000\n",
      "Epoch: 17/20.. Loss: 0.0102.. Test accuracy: 0.0226.. 0.0104 s/batch  steps 403.0000\n",
      "Epoch: 17/20.. Loss: 0.0805.. Test accuracy: 0.0231.. 0.0105 s/batch  steps 404.0000\n",
      "Epoch: 17/20.. Loss: 0.0228.. Test accuracy: 0.0214.. 0.0102 s/batch  steps 405.0000\n",
      "Epoch: 17/20.. Loss: 0.0353.. Test accuracy: 0.0381.. 0.0099 s/batch  steps 406.0000\n",
      "Epoch: 17/20.. Loss: 0.0829.. Test accuracy: 0.0131.. 0.0101 s/batch  steps 407.0000\n",
      "Epoch: 17/20.. Loss: 0.0193.. Test accuracy: 0.0138.. 0.0095 s/batch  steps 408.0000\n",
      "Epoch: 17/20.. Loss: 0.0215.. Test accuracy: 0.0219.. 0.0112 s/batch  steps 409.0000\n",
      "Epoch: 17/20.. Loss: 0.0233.. Test accuracy: 0.0122.. 0.0094 s/batch  steps 410.0000\n",
      "Epoch: 17/20.. Loss: 0.0066.. Test accuracy: 0.0223.. 0.0096 s/batch  steps 411.0000\n",
      "Epoch: 17/20.. Loss: 0.0760.. Test accuracy: 0.0193.. 0.0109 s/batch  steps 412.0000\n",
      "Epoch: 17/20.. Loss: 0.0345.. Test accuracy: 0.0055.. 0.0101 s/batch  steps 413.0000\n",
      "Epoch: 17/20.. Loss: 0.0523.. Test accuracy: 0.0241.. 0.0101 s/batch  steps 414.0000\n",
      "Epoch: 17/20.. Loss: 0.0445.. Test accuracy: 0.0107.. 0.0088 s/batch  steps 415.0000\n",
      "Epoch: 17/20.. Loss: 0.0300.. Test accuracy: 0.0079.. 0.0111 s/batch  steps 416.0000\n",
      "Epoch: 17/20.. Loss: 0.0381.. Test accuracy: 0.0388.. 0.0168 s/batch  steps 417.0000\n",
      "Epoch: 17/20.. Loss: 0.0277.. Test accuracy: 0.0189.. 0.0109 s/batch  steps 418.0000\n",
      "Epoch: 17/20.. Loss: 0.0475.. Test accuracy: 0.0095.. 0.0111 s/batch  steps 419.0000\n",
      "Epoch: 17/20.. Loss: 0.0256.. Test accuracy: 0.0287.. 0.0110 s/batch  steps 420.0000\n",
      "Epoch: 17/20.. Loss: 0.1438.. Test accuracy: 0.0242.. 0.0110 s/batch  steps 421.0000\n",
      "Epoch: 17/20.. Loss: 0.0263.. Test accuracy: 0.0117.. 0.0111 s/batch  steps 422.0000\n",
      "Epoch: 17/20.. Loss: 0.0436.. Test accuracy: 0.0243.. 0.0112 s/batch  steps 423.0000\n",
      "Epoch: 17/20.. Loss: 0.0279.. Test accuracy: 0.0199.. 0.0096 s/batch  steps 424.0000\n",
      "Epoch: 17/20.. Loss: 0.0293.. Test accuracy: 0.0096.. 0.0091 s/batch  steps 425.0000\n",
      "Epoch: 18/20.. Loss: 0.0279.. Test accuracy: 0.0227.. 0.0108 s/batch  steps 426.0000\n",
      "Epoch: 18/20.. Loss: 0.1005.. Test accuracy: 0.0088.. 0.0107 s/batch  steps 427.0000\n",
      "Epoch: 18/20.. Loss: 0.0224.. Test accuracy: 0.0147.. 0.0112 s/batch  steps 428.0000\n",
      "Epoch: 18/20.. Loss: 0.0134.. Test accuracy: 0.0142.. 0.0119 s/batch  steps 429.0000\n",
      "Epoch: 18/20.. Loss: 0.0342.. Test accuracy: 0.0291.. 0.0109 s/batch  steps 430.0000\n",
      "Epoch: 18/20.. Loss: 0.0068.. Test accuracy: 0.0091.. 0.0110 s/batch  steps 431.0000\n",
      "Epoch: 18/20.. Loss: 0.0217.. Test accuracy: 0.0105.. 0.0110 s/batch  steps 432.0000\n",
      "Epoch: 18/20.. Loss: 0.0295.. Test accuracy: 0.0103.. 0.0094 s/batch  steps 433.0000\n",
      "Epoch: 18/20.. Loss: 0.0111.. Test accuracy: 0.0208.. 0.0105 s/batch  steps 434.0000\n",
      "Epoch: 18/20.. Loss: 0.0956.. Test accuracy: 0.0331.. 0.0096 s/batch  steps 435.0000\n",
      "Epoch: 18/20.. Loss: 0.0191.. Test accuracy: 0.0154.. 0.0106 s/batch  steps 436.0000\n",
      "Epoch: 18/20.. Loss: 0.0694.. Test accuracy: 0.0226.. 0.0102 s/batch  steps 437.0000\n",
      "Epoch: 18/20.. Loss: 0.0337.. Test accuracy: 0.0230.. 0.0126 s/batch  steps 438.0000\n",
      "Epoch: 18/20.. Loss: 0.0332.. Test accuracy: 0.0177.. 0.0107 s/batch  steps 439.0000\n",
      "Epoch: 18/20.. Loss: 0.0184.. Test accuracy: 0.0136.. 0.0088 s/batch  steps 440.0000\n",
      "Epoch: 18/20.. Loss: 0.0235.. Test accuracy: 0.0053.. 0.0095 s/batch  steps 441.0000\n",
      "Epoch: 18/20.. Loss: 0.1025.. Test accuracy: 0.0062.. 0.0097 s/batch  steps 442.0000\n",
      "Epoch: 18/20.. Loss: 0.0410.. Test accuracy: 0.0114.. 0.0099 s/batch  steps 443.0000\n",
      "Epoch: 18/20.. Loss: 0.0260.. Test accuracy: 0.0067.. 0.0089 s/batch  steps 444.0000\n",
      "Epoch: 18/20.. Loss: 0.0191.. Test accuracy: 0.0284.. 0.0105 s/batch  steps 445.0000\n",
      "Epoch: 18/20.. Loss: 0.0253.. Test accuracy: 0.0318.. 0.0103 s/batch  steps 446.0000\n",
      "Epoch: 18/20.. Loss: 0.1326.. Test accuracy: 0.0015.. 0.0121 s/batch  steps 447.0000\n",
      "Epoch: 18/20.. Loss: 0.0214.. Test accuracy: 0.0157.. 0.0110 s/batch  steps 448.0000\n",
      "Epoch: 18/20.. Loss: 0.0464.. Test accuracy: 0.0208.. 0.0094 s/batch  steps 449.0000\n",
      "Epoch: 18/20.. Loss: 0.0136.. Test accuracy: 0.0073.. 0.0111 s/batch  steps 450.0000\n",
      "Epoch: 19/20.. Loss: 0.1756.. Test accuracy: 0.0307.. 0.0109 s/batch  steps 451.0000\n",
      "Epoch: 19/20.. Loss: 0.0323.. Test accuracy: 0.0212.. 0.0093 s/batch  steps 452.0000\n",
      "Epoch: 19/20.. Loss: 0.0571.. Test accuracy: 0.0126.. 0.0089 s/batch  steps 453.0000\n",
      "Epoch: 19/20.. Loss: 0.0894.. Test accuracy: 0.0128.. 0.0098 s/batch  steps 454.0000\n",
      "Epoch: 19/20.. Loss: 0.0207.. Test accuracy: 0.0159.. 0.0109 s/batch  steps 455.0000\n",
      "Epoch: 19/20.. Loss: 0.0298.. Test accuracy: 0.0365.. 0.0096 s/batch  steps 456.0000\n",
      "Epoch: 19/20.. Loss: 0.0263.. Test accuracy: 0.0189.. 0.0115 s/batch  steps 457.0000\n",
      "Epoch: 19/20.. Loss: 0.0346.. Test accuracy: 0.0265.. 0.0117 s/batch  steps 458.0000\n",
      "Epoch: 19/20.. Loss: 0.0383.. Test accuracy: 0.0246.. 0.0101 s/batch  steps 459.0000\n",
      "Epoch: 19/20.. Loss: 0.0483.. Test accuracy: 0.0361.. 0.0098 s/batch  steps 460.0000\n",
      "Epoch: 19/20.. Loss: 0.0948.. Test accuracy: 0.0286.. 0.0102 s/batch  steps 461.0000\n",
      "Epoch: 19/20.. Loss: 0.0442.. Test accuracy: 0.0094.. 0.0101 s/batch  steps 462.0000\n",
      "Epoch: 19/20.. Loss: 0.0301.. Test accuracy: 0.0117.. 0.0117 s/batch  steps 463.0000\n",
      "Epoch: 19/20.. Loss: 0.0273.. Test accuracy: 0.0248.. 0.0116 s/batch  steps 464.0000\n",
      "Epoch: 19/20.. Loss: 0.0206.. Test accuracy: 0.0335.. 0.0110 s/batch  steps 465.0000\n",
      "Epoch: 19/20.. Loss: 0.0133.. Test accuracy: 0.0202.. 0.0101 s/batch  steps 466.0000\n",
      "Epoch: 19/20.. Loss: 0.0173.. Test accuracy: 0.0201.. 0.0131 s/batch  steps 467.0000\n",
      "Epoch: 19/20.. Loss: 0.0386.. Test accuracy: 0.0262.. 0.0113 s/batch  steps 468.0000\n",
      "Epoch: 19/20.. Loss: 0.0383.. Test accuracy: 0.0055.. 0.0103 s/batch  steps 469.0000\n",
      "Epoch: 19/20.. Loss: 0.0228.. Test accuracy: 0.0156.. 0.0103 s/batch  steps 470.0000\n",
      "Epoch: 19/20.. Loss: 0.0229.. Test accuracy: 0.0210.. 0.0091 s/batch  steps 471.0000\n",
      "Epoch: 19/20.. Loss: 0.0195.. Test accuracy: 0.0243.. 0.0115 s/batch  steps 472.0000\n",
      "Epoch: 19/20.. Loss: 0.0354.. Test accuracy: 0.0105.. 0.0113 s/batch  steps 473.0000\n",
      "Epoch: 19/20.. Loss: 0.0304.. Test accuracy: 0.0324.. 0.0107 s/batch  steps 474.0000\n",
      "Epoch: 19/20.. Loss: 0.0231.. Test accuracy: 0.0110.. 0.0107 s/batch  steps 475.0000\n",
      "Epoch: 20/20.. Loss: 0.0255.. Test accuracy: 0.0152.. 0.0107 s/batch  steps 476.0000\n",
      "Epoch: 20/20.. Loss: 0.0215.. Test accuracy: 0.0210.. 0.0136 s/batch  steps 477.0000\n",
      "Epoch: 20/20.. Loss: 0.0159.. Test accuracy: 0.0315.. 0.0134 s/batch  steps 478.0000\n",
      "Epoch: 20/20.. Loss: 0.0858.. Test accuracy: 0.0110.. 0.0145 s/batch  steps 479.0000\n",
      "Epoch: 20/20.. Loss: 0.0416.. Test accuracy: 0.0314.. 0.0104 s/batch  steps 480.0000\n",
      "Epoch: 20/20.. Loss: 0.0177.. Test accuracy: 0.0188.. 0.0126 s/batch  steps 481.0000\n",
      "Epoch: 20/20.. Loss: 0.0264.. Test accuracy: 0.0408.. 0.0116 s/batch  steps 482.0000\n",
      "Epoch: 20/20.. Loss: 0.0382.. Test accuracy: 0.0216.. 0.0103 s/batch  steps 483.0000\n",
      "Epoch: 20/20.. Loss: 0.0558.. Test accuracy: 0.0170.. 0.0102 s/batch  steps 484.0000\n",
      "Epoch: 20/20.. Loss: 0.1219.. Test accuracy: 0.0150.. 0.0109 s/batch  steps 485.0000\n",
      "Epoch: 20/20.. Loss: 0.1085.. Test accuracy: 0.0157.. 0.0111 s/batch  steps 486.0000\n",
      "Epoch: 20/20.. Loss: 0.0299.. Test accuracy: 0.0276.. 0.0139 s/batch  steps 487.0000\n",
      "Epoch: 20/20.. Loss: 0.0297.. Test accuracy: 0.0273.. 0.0142 s/batch  steps 488.0000\n",
      "Epoch: 20/20.. Loss: 0.0139.. Test accuracy: 0.0231.. 0.0117 s/batch  steps 489.0000\n",
      "Epoch: 20/20.. Loss: 0.0387.. Test accuracy: 0.0197.. 0.0132 s/batch  steps 490.0000\n",
      "Epoch: 20/20.. Loss: 0.0357.. Test accuracy: 0.0165.. 0.0143 s/batch  steps 491.0000\n",
      "Epoch: 20/20.. Loss: 0.0411.. Test accuracy: 0.0312.. 0.0126 s/batch  steps 492.0000\n",
      "Epoch: 20/20.. Loss: 0.0355.. Test accuracy: 0.0139.. 0.0107 s/batch  steps 493.0000\n",
      "Epoch: 20/20.. Loss: 0.0891.. Test accuracy: 0.0129.. 0.0106 s/batch  steps 494.0000\n",
      "Epoch: 20/20.. Loss: 0.0400.. Test accuracy: 0.0104.. 0.0099 s/batch  steps 495.0000\n",
      "Epoch: 20/20.. Loss: 0.0248.. Test accuracy: 0.0108.. 0.0106 s/batch  steps 496.0000\n",
      "Epoch: 20/20.. Loss: 0.0219.. Test accuracy: 0.0214.. 0.0107 s/batch  steps 497.0000\n",
      "Epoch: 20/20.. Loss: 0.0301.. Test accuracy: 0.0176.. 0.0094 s/batch  steps 498.0000\n",
      "Epoch: 20/20.. Loss: 0.0029.. Test accuracy: 0.0330.. 0.0100 s/batch  steps 499.0000\n",
      "Epoch: 20/20.. Loss: 0.0155.. Test accuracy: 0.0212.. 0.0098 s/batch  steps 500.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAHyCAYAAABbIyCJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAwBEE7wAAAIAjCN4BAAAAR/w/5zi4EbGWV9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c5256a0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 375
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "epochs = 20\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 1\n",
    "vec_acc_ = np.zeros(epochs*25)\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Do not forget to transform the inputs and outputs into Variable        #\n",
    "        # which pytorch uses.                                                          #\n",
    "        ################################################################################\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        output = net.forward(inputs)\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        grad = loss.backward()\n",
    "        optimizer.step()\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            sum_accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                inputs = Variable(images)\n",
    "                targets = Variable(labels)\n",
    "                predicted = net.predict(inputs)\n",
    "                accuracy = criterion(predicted, targets)\n",
    "                accuracy = accuracy.data.numpy().tolist()[0]\n",
    "                #vec_acc_[steps-1] = accuracy/(ii+1)\n",
    "                sum_accuracy += accuracy\n",
    "                \n",
    "                #inputs = Variable(images, volatile=True)\n",
    "                #predicted = net.predict(inputs)\n",
    "                #equality = (labels == predicted.max(1)[1])\n",
    "                #accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "                \n",
    "                \n",
    "                #im = Variable(images)\n",
    "                #out = net.predict(im)\n",
    "                #_,prediction = torch.max(out, 1)\n",
    "                #pred_y = prediction.data.numpy().squeeze()\n",
    "                #target_y = labels.numpy()\n",
    "                #accuracy = np.mean(predicted == inputs)\n",
    "                #print(pred_y.shape,target_y.shape)\n",
    "                \n",
    "                \n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(loss.data[0]),\n",
    "                  \"Test accuracy: {:.4f}..\".format(sum_accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch \".format((stop - start)/print_every),\n",
    "                  \"steps {:.4f}\".format(steps)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()\n",
    "\n",
    "#plt.plot(range(epochs*25),vec_acc_)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vector_create = np.random.rand(1000,38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  torch.Size([950, 1, 18])\n",
      "Train labels shape:  torch.Size([950, 1, 18])\n",
      "Validation data shape:  torch.Size([50, 1, 18])\n",
      "Validation labels shape:  torch.Size([50, 1, 18])\n"
     ]
    }
   ],
   "source": [
    "vector = np.zeros((len(Vector_create),len(Vector_create[0])))\n",
    "x = np.zeros((len(Vector_create),18))\n",
    "y = np.zeros((len(Vector_create),18))\n",
    "x_train = np.zeros((len(Vector_create)-20,18))\n",
    "Y_train = np.zeros((len(Vector_create)-20,18))\n",
    "x_val = np.zeros((20,18))\n",
    "y_val = np.zeros((20,18))\n",
    "\n",
    "for i in range(len(Vector_create)):\n",
    "    vector[i][:] = np.reshape(Vector_create[i][:][:],2*19,'C')\n",
    "for i in range(len(vector)):\n",
    "    x[i][:] = vector[i][:18]\n",
    "    y[i][:] = vector[i][20:38]\n",
    "\n",
    "mask = list(range(len(vector)-50, len(vector)))\n",
    "x_val = x[mask]\n",
    "y_val = y[mask]\n",
    "mask = list(range(len(vector)-50))\n",
    "x_train = x[mask]\n",
    "y_train = y[mask]\n",
    "\n",
    "x_train,y_train = torch.from_numpy(x_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "x_val,y_val = torch.from_numpy(x_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.FloatTensor)\n",
    "\n",
    "x_train = x_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "y_train = y_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "x_val = x_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "y_val = y_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "traindataset = utils.TensorDataset(x_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(x_val, y_val)\n",
    "valloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=1, n_output=None):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Define 2 or more different layers of the neural network                      #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_input_channels,8,5,padding=2)\n",
    "        self.conv2 = nn.Conv1d(8,30,3,padding=1)\n",
    "        self.conv3 = nn.Conv1d(30,40,3,padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True)\n",
    "     \n",
    "        self.fc1 = nn.Linear(9*2 * 40, 500)\n",
    "        self.fc2 = nn.Linear(500, 200)\n",
    "        self.fc3 = nn.Linear(200, 18)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Set up the forward pass that the input data will go through.                 #\n",
    "        # A good activation function betweent the layers is a ReLu function.           #\n",
    "        #                                                                              #\n",
    "        # Note that the output of the last convolution layer should be flattened       #\n",
    "        # before being inputted to the fully connected layer. We can flatten           #\n",
    "        # Variable `x` with `x.view`.                                                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = x.view(-1, 9*2 * 40) # in order to reshape the tensor for as many columns we need\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/4romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100.. Loss: 0.3494.. Test accuracy: 0.2789.. 0.0134 s/batch  steps 1.0000\n",
      "Epoch: 1/100.. Loss: 0.3129.. Test accuracy: 0.2789.. 0.0111 s/batch  steps 2.0000\n",
      "Epoch: 1/100.. Loss: 0.2940.. Test accuracy: 0.2789.. 0.0111 s/batch  steps 3.0000\n",
      "Epoch: 1/100.. Loss: 0.3234.. Test accuracy: 0.2789.. 0.0095 s/batch  steps 4.0000\n",
      "Epoch: 1/100.. Loss: 0.3431.. Test accuracy: 0.2789.. 0.0116 s/batch  steps 5.0000\n",
      "Epoch: 1/100.. Loss: 0.2822.. Test accuracy: 0.2789.. 0.0092 s/batch  steps 6.0000\n",
      "Epoch: 1/100.. Loss: 0.2989.. Test accuracy: 0.2789.. 0.0151 s/batch  steps 7.0000\n",
      "Epoch: 1/100.. Loss: 0.2930.. Test accuracy: 0.2789.. 0.0119 s/batch  steps 8.0000\n",
      "Epoch: 1/100.. Loss: 0.2666.. Test accuracy: 0.2789.. 0.0093 s/batch  steps 9.0000\n",
      "Epoch: 1/100.. Loss: 0.2837.. Test accuracy: 0.2789.. 0.0095 s/batch  steps 10.0000\n",
      "Epoch: 1/100.. Loss: 0.3118.. Test accuracy: 0.2789.. 0.0105 s/batch  steps 11.0000\n",
      "Epoch: 1/100.. Loss: 0.2884.. Test accuracy: 0.2789.. 0.0098 s/batch  steps 12.0000\n",
      "Epoch: 1/100.. Loss: 0.2127.. Test accuracy: 0.2789.. 0.0103 s/batch  steps 13.0000\n",
      "Epoch: 1/100.. Loss: 0.2298.. Test accuracy: 0.2789.. 0.0113 s/batch  steps 14.0000\n",
      "Epoch: 1/100.. Loss: 0.2695.. Test accuracy: 0.2789.. 0.0091 s/batch  steps 15.0000\n",
      "Epoch: 1/100.. Loss: 0.1753.. Test accuracy: 0.2789.. 0.0103 s/batch  steps 16.0000\n",
      "Epoch: 1/100.. Loss: 0.1691.. Test accuracy: 0.2789.. 0.0085 s/batch  steps 17.0000\n",
      "Epoch: 1/100.. Loss: 0.1660.. Test accuracy: 0.2789.. 0.0199 s/batch  steps 18.0000\n",
      "Epoch: 1/100.. Loss: 0.1688.. Test accuracy: 0.2789.. 0.0094 s/batch  steps 19.0000\n",
      "Epoch: 1/100.. Loss: 0.2007.. Test accuracy: 0.2789.. 0.0091 s/batch  steps 20.0000\n",
      "Epoch: 1/100.. Loss: 0.1725.. Test accuracy: 0.2789.. 0.0081 s/batch  steps 21.0000\n",
      "Epoch: 1/100.. Loss: 0.1608.. Test accuracy: 0.2789.. 0.0094 s/batch  steps 22.0000\n",
      "Epoch: 1/100.. Loss: 0.1599.. Test accuracy: 0.2789.. 0.0110 s/batch  steps 23.0000\n",
      "Epoch: 1/100.. Loss: 0.1705.. Test accuracy: 0.2789.. 0.0096 s/batch  steps 24.0000\n",
      "Epoch: 1/100.. Loss: 0.1701.. Test accuracy: 0.2789.. 0.0101 s/batch  steps 25.0000\n",
      "Epoch: 1/100.. Loss: 0.1508.. Test accuracy: 0.2789.. 0.0091 s/batch  steps 26.0000\n",
      "Epoch: 1/100.. Loss: 0.1574.. Test accuracy: 0.2789.. 0.0091 s/batch  steps 27.0000\n",
      "Epoch: 1/100.. Loss: 0.1381.. Test accuracy: 0.2789.. 0.0097 s/batch  steps 28.0000\n",
      "Epoch: 1/100.. Loss: 0.1455.. Test accuracy: 0.2789.. 0.0099 s/batch  steps 29.0000\n",
      "Epoch: 1/100.. Loss: 0.1360.. Test accuracy: 0.2789.. 0.0088 s/batch  steps 30.0000\n",
      "Epoch: 1/100.. Loss: 0.1332.. Test accuracy: 0.2789.. 0.0079 s/batch  steps 31.0000\n",
      "Epoch: 1/100.. Loss: 0.1253.. Test accuracy: 0.2789.. 0.0104 s/batch  steps 32.0000\n",
      "Epoch: 1/100.. Loss: 0.1286.. Test accuracy: 0.2789.. 0.0110 s/batch  steps 33.0000\n",
      "Epoch: 1/100.. Loss: 0.1040.. Test accuracy: 0.2789.. 0.0116 s/batch  steps 34.0000\n",
      "Epoch: 1/100.. Loss: 0.1052.. Test accuracy: 0.2789.. 0.0124 s/batch  steps 35.0000\n",
      "Epoch: 1/100.. Loss: 0.1167.. Test accuracy: 0.2789.. 0.0099 s/batch  steps 36.0000\n",
      "Epoch: 1/100.. Loss: 0.0683.. Test accuracy: 0.2789.. 0.0103 s/batch  steps 37.0000\n",
      "Epoch: 1/100.. Loss: 0.1140.. Test accuracy: 0.2789.. 0.0102 s/batch  steps 38.0000\n",
      "Epoch: 1/100.. Loss: 0.0926.. Test accuracy: 0.2789.. 0.0097 s/batch  steps 39.0000\n",
      "Epoch: 1/100.. Loss: 0.1038.. Test accuracy: 0.2789.. 0.0093 s/batch  steps 40.0000\n",
      "Epoch: 1/100.. Loss: 0.0891.. Test accuracy: 0.2789.. 0.0087 s/batch  steps 41.0000\n",
      "Epoch: 1/100.. Loss: 0.1096.. Test accuracy: 0.2789.. 0.0135 s/batch  steps 42.0000\n",
      "Epoch: 1/100.. Loss: 0.1005.. Test accuracy: 0.2789.. 0.0095 s/batch  steps 43.0000\n",
      "Epoch: 1/100.. Loss: 0.0985.. Test accuracy: 0.2789.. 0.0112 s/batch  steps 44.0000\n",
      "Epoch: 1/100.. Loss: 0.0929.. Test accuracy: 0.2789.. 0.0099 s/batch  steps 45.0000\n",
      "Epoch: 1/100.. Loss: 0.0868.. Test accuracy: 0.2789.. 0.0100 s/batch  steps 46.0000\n",
      "Epoch: 1/100.. Loss: 0.0942.. Test accuracy: 0.2789.. 0.0108 s/batch  steps 47.0000\n",
      "Epoch: 1/100.. Loss: 0.0987.. Test accuracy: 0.2789.. 0.0110 s/batch  steps 48.0000\n",
      "Epoch: 1/100.. Loss: 0.0865.. Test accuracy: 0.2789.. 0.0107 s/batch  steps 49.0000\n",
      "Epoch: 1/100.. Loss: 0.0897.. Test accuracy: 0.2789.. 0.0094 s/batch  steps 50.0000\n",
      "Epoch: 1/100.. Loss: 0.0915.. Test accuracy: 0.2789.. 0.0095 s/batch  steps 51.0000\n",
      "Epoch: 1/100.. Loss: 0.0951.. Test accuracy: 0.2789.. 0.0083 s/batch  steps 52.0000\n",
      "Epoch: 1/100.. Loss: 0.0789.. Test accuracy: 0.2789.. 0.0100 s/batch  steps 53.0000\n",
      "Epoch: 1/100.. Loss: 0.0924.. Test accuracy: 0.2789.. 0.0082 s/batch  steps 54.0000\n",
      "Epoch: 1/100.. Loss: 0.1026.. Test accuracy: 0.2789.. 0.0093 s/batch  steps 55.0000\n",
      "Epoch: 1/100.. Loss: 0.0962.. Test accuracy: 0.2789.. 0.0101 s/batch  steps 56.0000\n",
      "Epoch: 1/100.. Loss: 0.0766.. Test accuracy: 0.2789.. 0.0098 s/batch  steps 57.0000\n",
      "Epoch: 1/100.. Loss: 0.0746.. Test accuracy: 0.2789.. 0.0087 s/batch  steps 58.0000\n",
      "Epoch: 1/100.. Loss: 0.0938.. Test accuracy: 0.2789.. 0.0089 s/batch  steps 59.0000\n",
      "Epoch: 1/100.. Loss: 0.0970.. Test accuracy: 0.2789.. 0.0107 s/batch  steps 60.0000\n",
      "Epoch: 1/100.. Loss: 0.0936.. Test accuracy: 0.2789.. 0.0134 s/batch  steps 61.0000\n",
      "Epoch: 1/100.. Loss: 0.0842.. Test accuracy: 0.2789.. 0.0097 s/batch  steps 62.0000\n",
      "Epoch: 1/100.. Loss: 0.0845.. Test accuracy: 0.2789.. 0.0095 s/batch  steps 63.0000\n",
      "Epoch: 1/100.. Loss: 0.1021.. Test accuracy: 0.2789.. 0.0103 s/batch  steps 64.0000\n",
      "Epoch: 1/100.. Loss: 0.0680.. Test accuracy: 0.2789.. 0.0096 s/batch  steps 65.0000\n",
      "Epoch: 1/100.. Loss: 0.0861.. Test accuracy: 0.2789.. 0.0098 s/batch  steps 66.0000\n",
      "Epoch: 1/100.. Loss: 0.1109.. Test accuracy: 0.2789.. 0.0105 s/batch  steps 67.0000\n",
      "Epoch: 1/100.. Loss: 0.0985.. Test accuracy: 0.2789.. 0.0109 s/batch  steps 68.0000\n",
      "Epoch: 1/100.. Loss: 0.0910.. Test accuracy: 0.2789.. 0.0100 s/batch  steps 69.0000\n",
      "Epoch: 1/100.. Loss: 0.0863.. Test accuracy: 0.2789.. 0.0104 s/batch  steps 70.0000\n",
      "Epoch: 1/100.. Loss: 0.0763.. Test accuracy: 0.2789.. 0.0145 s/batch  steps 71.0000\n",
      "Epoch: 1/100.. Loss: 0.0758.. Test accuracy: 0.2789.. 0.0094 s/batch  steps 72.0000\n",
      "Epoch: 1/100.. Loss: 0.0762.. Test accuracy: 0.2789.. 0.0117 s/batch  steps 73.0000\n",
      "Epoch: 1/100.. Loss: 0.0932.. Test accuracy: 0.2789.. 0.0107 s/batch  steps 74.0000\n",
      "Epoch: 1/100.. Loss: 0.1061.. Test accuracy: 0.2789.. 0.0097 s/batch  steps 75.0000\n",
      "Epoch: 1/100.. Loss: 0.0994.. Test accuracy: 0.2789.. 0.0088 s/batch  steps 76.0000\n",
      "Epoch: 1/100.. Loss: 0.0861.. Test accuracy: 0.2788.. 0.0109 s/batch  steps 77.0000\n",
      "Epoch: 1/100.. Loss: 0.0928.. Test accuracy: 0.2788.. 0.0144 s/batch  steps 78.0000\n",
      "Epoch: 1/100.. Loss: 0.0894.. Test accuracy: 0.2788.. 0.0163 s/batch  steps 79.0000\n",
      "Epoch: 1/100.. Loss: 0.0964.. Test accuracy: 0.2788.. 0.0085 s/batch  steps 80.0000\n",
      "Epoch: 1/100.. Loss: 0.0792.. Test accuracy: 0.2788.. 0.0107 s/batch  steps 81.0000\n",
      "Epoch: 1/100.. Loss: 0.0895.. Test accuracy: 0.2788.. 0.0101 s/batch  steps 82.0000\n",
      "Epoch: 1/100.. Loss: 0.0849.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 83.0000\n",
      "Epoch: 1/100.. Loss: 0.0889.. Test accuracy: 0.2788.. 0.0130 s/batch  steps 84.0000\n",
      "Epoch: 1/100.. Loss: 0.0918.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 85.0000\n",
      "Epoch: 1/100.. Loss: 0.0817.. Test accuracy: 0.2788.. 0.0125 s/batch  steps 86.0000\n",
      "Epoch: 1/100.. Loss: 0.0795.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 87.0000\n",
      "Epoch: 1/100.. Loss: 0.0863.. Test accuracy: 0.2789.. 0.0129 s/batch  steps 88.0000\n",
      "Epoch: 1/100.. Loss: 0.0910.. Test accuracy: 0.2789.. 0.0112 s/batch  steps 89.0000\n",
      "Epoch: 1/100.. Loss: 0.0823.. Test accuracy: 0.2789.. 0.0105 s/batch  steps 90.0000\n",
      "Epoch: 1/100.. Loss: 0.0813.. Test accuracy: 0.2789.. 0.0151 s/batch  steps 91.0000\n",
      "Epoch: 1/100.. Loss: 0.0864.. Test accuracy: 0.2789.. 0.0107 s/batch  steps 92.0000\n",
      "Epoch: 1/100.. Loss: 0.1014.. Test accuracy: 0.2789.. 0.0096 s/batch  steps 93.0000\n",
      "Epoch: 1/100.. Loss: 0.0933.. Test accuracy: 0.2789.. 0.0105 s/batch  steps 94.0000\n",
      "Epoch: 1/100.. Loss: 0.0873.. Test accuracy: 0.2789.. 0.0109 s/batch  steps 95.0000\n",
      "Epoch: 1/100.. Loss: 0.0962.. Test accuracy: 0.2789.. 0.0105 s/batch  steps 96.0000\n",
      "Epoch: 1/100.. Loss: 0.0783.. Test accuracy: 0.2789.. 0.0093 s/batch  steps 97.0000\n",
      "Epoch: 1/100.. Loss: 0.1063.. Test accuracy: 0.2789.. 0.0099 s/batch  steps 98.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100.. Loss: 0.0876.. Test accuracy: 0.2789.. 0.0097 s/batch  steps 99.0000\n",
      "Epoch: 1/100.. Loss: 0.0728.. Test accuracy: 0.2789.. 0.0109 s/batch  steps 100.0000\n",
      "Epoch: 1/100.. Loss: 0.0858.. Test accuracy: 0.2788.. 0.0112 s/batch  steps 101.0000\n",
      "Epoch: 1/100.. Loss: 0.0746.. Test accuracy: 0.2788.. 0.0153 s/batch  steps 102.0000\n",
      "Epoch: 1/100.. Loss: 0.0785.. Test accuracy: 0.2788.. 0.0124 s/batch  steps 103.0000\n",
      "Epoch: 1/100.. Loss: 0.0879.. Test accuracy: 0.2788.. 0.0090 s/batch  steps 104.0000\n",
      "Epoch: 1/100.. Loss: 0.0794.. Test accuracy: 0.2788.. 0.0084 s/batch  steps 105.0000\n",
      "Epoch: 1/100.. Loss: 0.0865.. Test accuracy: 0.2788.. 0.0110 s/batch  steps 106.0000\n",
      "Epoch: 1/100.. Loss: 0.0834.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 107.0000\n",
      "Epoch: 1/100.. Loss: 0.0836.. Test accuracy: 0.2788.. 0.0107 s/batch  steps 108.0000\n",
      "Epoch: 1/100.. Loss: 0.0973.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 109.0000\n",
      "Epoch: 1/100.. Loss: 0.0990.. Test accuracy: 0.2788.. 0.0125 s/batch  steps 110.0000\n",
      "Epoch: 1/100.. Loss: 0.0703.. Test accuracy: 0.2788.. 0.0103 s/batch  steps 111.0000\n",
      "Epoch: 1/100.. Loss: 0.1007.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 112.0000\n",
      "Epoch: 1/100.. Loss: 0.0958.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 113.0000\n",
      "Epoch: 1/100.. Loss: 0.0902.. Test accuracy: 0.2788.. 0.0077 s/batch  steps 114.0000\n",
      "Epoch: 1/100.. Loss: 0.0815.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 115.0000\n",
      "Epoch: 1/100.. Loss: 0.1010.. Test accuracy: 0.2788.. 0.0086 s/batch  steps 116.0000\n",
      "Epoch: 1/100.. Loss: 0.0902.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 117.0000\n",
      "Epoch: 1/100.. Loss: 0.0828.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 118.0000\n",
      "Epoch: 1/100.. Loss: 0.0875.. Test accuracy: 0.2788.. 0.0085 s/batch  steps 119.0000\n",
      "Epoch: 1/100.. Loss: 0.0742.. Test accuracy: 0.2788.. 0.0090 s/batch  steps 120.0000\n",
      "Epoch: 1/100.. Loss: 0.0786.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 121.0000\n",
      "Epoch: 1/100.. Loss: 0.0837.. Test accuracy: 0.2788.. 0.0087 s/batch  steps 122.0000\n",
      "Epoch: 1/100.. Loss: 0.0791.. Test accuracy: 0.2788.. 0.0091 s/batch  steps 123.0000\n",
      "Epoch: 1/100.. Loss: 0.0815.. Test accuracy: 0.2788.. 0.0109 s/batch  steps 124.0000\n",
      "Epoch: 1/100.. Loss: 0.0797.. Test accuracy: 0.2788.. 0.0097 s/batch  steps 125.0000\n",
      "Epoch: 1/100.. Loss: 0.0703.. Test accuracy: 0.2788.. 0.0103 s/batch  steps 126.0000\n",
      "Epoch: 1/100.. Loss: 0.0861.. Test accuracy: 0.2788.. 0.0135 s/batch  steps 127.0000\n",
      "Epoch: 1/100.. Loss: 0.0736.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 128.0000\n",
      "Epoch: 1/100.. Loss: 0.0984.. Test accuracy: 0.2788.. 0.0085 s/batch  steps 129.0000\n",
      "Epoch: 1/100.. Loss: 0.0917.. Test accuracy: 0.2788.. 0.0111 s/batch  steps 130.0000\n",
      "Epoch: 1/100.. Loss: 0.0891.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 131.0000\n",
      "Epoch: 1/100.. Loss: 0.0867.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 132.0000\n",
      "Epoch: 1/100.. Loss: 0.0841.. Test accuracy: 0.2788.. 0.0088 s/batch  steps 133.0000\n",
      "Epoch: 1/100.. Loss: 0.0797.. Test accuracy: 0.2788.. 0.0102 s/batch  steps 134.0000\n",
      "Epoch: 1/100.. Loss: 0.1046.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 135.0000\n",
      "Epoch: 1/100.. Loss: 0.0923.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 136.0000\n",
      "Epoch: 1/100.. Loss: 0.0824.. Test accuracy: 0.2788.. 0.0087 s/batch  steps 137.0000\n",
      "Epoch: 1/100.. Loss: 0.0827.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 138.0000\n",
      "Epoch: 1/100.. Loss: 0.0980.. Test accuracy: 0.2788.. 0.0086 s/batch  steps 139.0000\n",
      "Epoch: 1/100.. Loss: 0.0963.. Test accuracy: 0.2788.. 0.0114 s/batch  steps 140.0000\n",
      "Epoch: 1/100.. Loss: 0.0947.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 141.0000\n",
      "Epoch: 1/100.. Loss: 0.0741.. Test accuracy: 0.2788.. 0.0080 s/batch  steps 142.0000\n",
      "Epoch: 1/100.. Loss: 0.0719.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 143.0000\n",
      "Epoch: 1/100.. Loss: 0.0737.. Test accuracy: 0.2788.. 0.0101 s/batch  steps 144.0000\n",
      "Epoch: 1/100.. Loss: 0.0882.. Test accuracy: 0.2788.. 0.0091 s/batch  steps 145.0000\n",
      "Epoch: 1/100.. Loss: 0.0772.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 146.0000\n",
      "Epoch: 1/100.. Loss: 0.0872.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 147.0000\n",
      "Epoch: 1/100.. Loss: 0.0971.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 148.0000\n",
      "Epoch: 1/100.. Loss: 0.0856.. Test accuracy: 0.2788.. 0.0114 s/batch  steps 149.0000\n",
      "Epoch: 1/100.. Loss: 0.0837.. Test accuracy: 0.2788.. 0.0126 s/batch  steps 150.0000\n",
      "Epoch: 1/100.. Loss: 0.0904.. Test accuracy: 0.2788.. 0.0102 s/batch  steps 151.0000\n",
      "Epoch: 1/100.. Loss: 0.0929.. Test accuracy: 0.2788.. 0.0091 s/batch  steps 152.0000\n",
      "Epoch: 1/100.. Loss: 0.0975.. Test accuracy: 0.2788.. 0.0119 s/batch  steps 153.0000\n",
      "Epoch: 1/100.. Loss: 0.0827.. Test accuracy: 0.2788.. 0.0102 s/batch  steps 154.0000\n",
      "Epoch: 1/100.. Loss: 0.0755.. Test accuracy: 0.2788.. 0.0130 s/batch  steps 155.0000\n",
      "Epoch: 1/100.. Loss: 0.0959.. Test accuracy: 0.2788.. 0.0103 s/batch  steps 156.0000\n",
      "Epoch: 1/100.. Loss: 0.0877.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 157.0000\n",
      "Epoch: 1/100.. Loss: 0.0872.. Test accuracy: 0.2788.. 0.0088 s/batch  steps 158.0000\n",
      "Epoch: 1/100.. Loss: 0.0828.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 159.0000\n",
      "Epoch: 1/100.. Loss: 0.0813.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 160.0000\n",
      "Epoch: 1/100.. Loss: 0.0929.. Test accuracy: 0.2788.. 0.0113 s/batch  steps 161.0000\n",
      "Epoch: 1/100.. Loss: 0.0878.. Test accuracy: 0.2788.. 0.0090 s/batch  steps 162.0000\n",
      "Epoch: 1/100.. Loss: 0.0824.. Test accuracy: 0.2788.. 0.0102 s/batch  steps 163.0000\n",
      "Epoch: 1/100.. Loss: 0.0660.. Test accuracy: 0.2788.. 0.0117 s/batch  steps 164.0000\n",
      "Epoch: 1/100.. Loss: 0.0929.. Test accuracy: 0.2788.. 0.0127 s/batch  steps 165.0000\n",
      "Epoch: 1/100.. Loss: 0.0826.. Test accuracy: 0.2788.. 0.0120 s/batch  steps 166.0000\n",
      "Epoch: 1/100.. Loss: 0.0964.. Test accuracy: 0.2788.. 0.0117 s/batch  steps 167.0000\n",
      "Epoch: 1/100.. Loss: 0.0872.. Test accuracy: 0.2788.. 0.0112 s/batch  steps 168.0000\n",
      "Epoch: 1/100.. Loss: 0.0925.. Test accuracy: 0.2788.. 0.0115 s/batch  steps 169.0000\n",
      "Epoch: 1/100.. Loss: 0.1059.. Test accuracy: 0.2788.. 0.0224 s/batch  steps 170.0000\n",
      "Epoch: 1/100.. Loss: 0.0907.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 171.0000\n",
      "Epoch: 1/100.. Loss: 0.0762.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 172.0000\n",
      "Epoch: 1/100.. Loss: 0.0757.. Test accuracy: 0.2788.. 0.0129 s/batch  steps 173.0000\n",
      "Epoch: 1/100.. Loss: 0.0885.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 174.0000\n",
      "Epoch: 1/100.. Loss: 0.0768.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 175.0000\n",
      "Epoch: 1/100.. Loss: 0.0875.. Test accuracy: 0.2788.. 0.0106 s/batch  steps 176.0000\n",
      "Epoch: 1/100.. Loss: 0.0825.. Test accuracy: 0.2788.. 0.0113 s/batch  steps 177.0000\n",
      "Epoch: 1/100.. Loss: 0.0845.. Test accuracy: 0.2788.. 0.0112 s/batch  steps 178.0000\n",
      "Epoch: 1/100.. Loss: 0.0903.. Test accuracy: 0.2788.. 0.0114 s/batch  steps 179.0000\n",
      "Epoch: 1/100.. Loss: 0.0980.. Test accuracy: 0.2788.. 0.0112 s/batch  steps 180.0000\n",
      "Epoch: 1/100.. Loss: 0.0828.. Test accuracy: 0.2788.. 0.0148 s/batch  steps 181.0000\n",
      "Epoch: 1/100.. Loss: 0.0823.. Test accuracy: 0.2788.. 0.0105 s/batch  steps 182.0000\n",
      "Epoch: 1/100.. Loss: 0.0807.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 183.0000\n",
      "Epoch: 1/100.. Loss: 0.0965.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 184.0000\n",
      "Epoch: 1/100.. Loss: 0.0788.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 185.0000\n",
      "Epoch: 1/100.. Loss: 0.0839.. Test accuracy: 0.2788.. 0.0101 s/batch  steps 186.0000\n",
      "Epoch: 1/100.. Loss: 0.0780.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 187.0000\n",
      "Epoch: 1/100.. Loss: 0.0922.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 188.0000\n",
      "Epoch: 1/100.. Loss: 0.0905.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 189.0000\n",
      "Epoch: 1/100.. Loss: 0.0905.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 190.0000\n",
      "Epoch: 2/100.. Loss: 0.0854.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 191.0000\n",
      "Epoch: 2/100.. Loss: 0.0803.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 192.0000\n",
      "Epoch: 2/100.. Loss: 0.0843.. Test accuracy: 0.2788.. 0.0105 s/batch  steps 193.0000\n",
      "Epoch: 2/100.. Loss: 0.0802.. Test accuracy: 0.2788.. 0.0088 s/batch  steps 194.0000\n",
      "Epoch: 2/100.. Loss: 0.0890.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 195.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100.. Loss: 0.0873.. Test accuracy: 0.2788.. 0.0097 s/batch  steps 196.0000\n",
      "Epoch: 2/100.. Loss: 0.0884.. Test accuracy: 0.2788.. 0.0083 s/batch  steps 197.0000\n",
      "Epoch: 2/100.. Loss: 0.0828.. Test accuracy: 0.2788.. 0.0080 s/batch  steps 198.0000\n",
      "Epoch: 2/100.. Loss: 0.0880.. Test accuracy: 0.2788.. 0.0103 s/batch  steps 199.0000\n",
      "Epoch: 2/100.. Loss: 0.0829.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 200.0000\n",
      "Epoch: 2/100.. Loss: 0.0745.. Test accuracy: 0.2788.. 0.0123 s/batch  steps 201.0000\n",
      "Epoch: 2/100.. Loss: 0.0796.. Test accuracy: 0.2788.. 0.0118 s/batch  steps 202.0000\n",
      "Epoch: 2/100.. Loss: 0.0934.. Test accuracy: 0.2788.. 0.0109 s/batch  steps 203.0000\n",
      "Epoch: 2/100.. Loss: 0.0885.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 204.0000\n",
      "Epoch: 2/100.. Loss: 0.0722.. Test accuracy: 0.2788.. 0.0101 s/batch  steps 205.0000\n",
      "Epoch: 2/100.. Loss: 0.0799.. Test accuracy: 0.2788.. 0.0123 s/batch  steps 206.0000\n",
      "Epoch: 2/100.. Loss: 0.0740.. Test accuracy: 0.2788.. 0.0158 s/batch  steps 207.0000\n",
      "Epoch: 2/100.. Loss: 0.0879.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 208.0000\n",
      "Epoch: 2/100.. Loss: 0.0741.. Test accuracy: 0.2788.. 0.0112 s/batch  steps 209.0000\n",
      "Epoch: 2/100.. Loss: 0.0895.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 210.0000\n",
      "Epoch: 2/100.. Loss: 0.0904.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 211.0000\n",
      "Epoch: 2/100.. Loss: 0.0789.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 212.0000\n",
      "Epoch: 2/100.. Loss: 0.0754.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 213.0000\n",
      "Epoch: 2/100.. Loss: 0.0817.. Test accuracy: 0.2788.. 0.0103 s/batch  steps 214.0000\n",
      "Epoch: 2/100.. Loss: 0.0796.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 215.0000\n",
      "Epoch: 2/100.. Loss: 0.0912.. Test accuracy: 0.2788.. 0.0106 s/batch  steps 216.0000\n",
      "Epoch: 2/100.. Loss: 0.0865.. Test accuracy: 0.2788.. 0.0097 s/batch  steps 217.0000\n",
      "Epoch: 2/100.. Loss: 0.0809.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 218.0000\n",
      "Epoch: 2/100.. Loss: 0.0884.. Test accuracy: 0.2788.. 0.0110 s/batch  steps 219.0000\n",
      "Epoch: 2/100.. Loss: 0.0800.. Test accuracy: 0.2788.. 0.0323 s/batch  steps 220.0000\n",
      "Epoch: 2/100.. Loss: 0.0747.. Test accuracy: 0.2788.. 0.0127 s/batch  steps 221.0000\n",
      "Epoch: 2/100.. Loss: 0.0826.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 222.0000\n",
      "Epoch: 2/100.. Loss: 0.1014.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 223.0000\n",
      "Epoch: 2/100.. Loss: 0.0903.. Test accuracy: 0.2788.. 0.0130 s/batch  steps 224.0000\n",
      "Epoch: 2/100.. Loss: 0.0792.. Test accuracy: 0.2788.. 0.0084 s/batch  steps 225.0000\n",
      "Epoch: 2/100.. Loss: 0.0804.. Test accuracy: 0.2788.. 0.0106 s/batch  steps 226.0000\n",
      "Epoch: 2/100.. Loss: 0.1046.. Test accuracy: 0.2788.. 0.0138 s/batch  steps 227.0000\n",
      "Epoch: 2/100.. Loss: 0.0830.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 228.0000\n",
      "Epoch: 2/100.. Loss: 0.0724.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 229.0000\n",
      "Epoch: 2/100.. Loss: 0.0972.. Test accuracy: 0.2788.. 0.0106 s/batch  steps 230.0000\n",
      "Epoch: 2/100.. Loss: 0.0904.. Test accuracy: 0.2788.. 0.0110 s/batch  steps 231.0000\n",
      "Epoch: 2/100.. Loss: 0.0783.. Test accuracy: 0.2788.. 0.0101 s/batch  steps 232.0000\n",
      "Epoch: 2/100.. Loss: 0.0825.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 233.0000\n",
      "Epoch: 2/100.. Loss: 0.0863.. Test accuracy: 0.2788.. 0.0103 s/batch  steps 234.0000\n",
      "Epoch: 2/100.. Loss: 0.0779.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 235.0000\n",
      "Epoch: 2/100.. Loss: 0.0847.. Test accuracy: 0.2788.. 0.0100 s/batch  steps 236.0000\n",
      "Epoch: 2/100.. Loss: 0.0825.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 237.0000\n",
      "Epoch: 2/100.. Loss: 0.0863.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 238.0000\n",
      "Epoch: 2/100.. Loss: 0.0953.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 239.0000\n",
      "Epoch: 2/100.. Loss: 0.0800.. Test accuracy: 0.2788.. 0.0116 s/batch  steps 240.0000\n",
      "Epoch: 2/100.. Loss: 0.0956.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 241.0000\n",
      "Epoch: 2/100.. Loss: 0.0699.. Test accuracy: 0.2788.. 0.0105 s/batch  steps 242.0000\n",
      "Epoch: 2/100.. Loss: 0.1102.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 243.0000\n",
      "Epoch: 2/100.. Loss: 0.0945.. Test accuracy: 0.2788.. 0.0102 s/batch  steps 244.0000\n",
      "Epoch: 2/100.. Loss: 0.0787.. Test accuracy: 0.2788.. 0.0102 s/batch  steps 245.0000\n",
      "Epoch: 2/100.. Loss: 0.0866.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 246.0000\n",
      "Epoch: 2/100.. Loss: 0.0860.. Test accuracy: 0.2788.. 0.0091 s/batch  steps 247.0000\n",
      "Epoch: 2/100.. Loss: 0.0756.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 248.0000\n",
      "Epoch: 2/100.. Loss: 0.1030.. Test accuracy: 0.2788.. 0.0112 s/batch  steps 249.0000\n",
      "Epoch: 2/100.. Loss: 0.0856.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 250.0000\n",
      "Epoch: 2/100.. Loss: 0.0854.. Test accuracy: 0.2788.. 0.0117 s/batch  steps 251.0000\n",
      "Epoch: 2/100.. Loss: 0.0872.. Test accuracy: 0.2788.. 0.0085 s/batch  steps 252.0000\n",
      "Epoch: 2/100.. Loss: 0.0894.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 253.0000\n",
      "Epoch: 2/100.. Loss: 0.0806.. Test accuracy: 0.2788.. 0.0114 s/batch  steps 254.0000\n",
      "Epoch: 2/100.. Loss: 0.0822.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 255.0000\n",
      "Epoch: 2/100.. Loss: 0.1016.. Test accuracy: 0.2788.. 0.0107 s/batch  steps 256.0000\n",
      "Epoch: 2/100.. Loss: 0.0804.. Test accuracy: 0.2788.. 0.0097 s/batch  steps 257.0000\n",
      "Epoch: 2/100.. Loss: 0.0816.. Test accuracy: 0.2788.. 0.0092 s/batch  steps 258.0000\n",
      "Epoch: 2/100.. Loss: 0.0839.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 259.0000\n",
      "Epoch: 2/100.. Loss: 0.0741.. Test accuracy: 0.2788.. 0.0082 s/batch  steps 260.0000\n",
      "Epoch: 2/100.. Loss: 0.0839.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 261.0000\n",
      "Epoch: 2/100.. Loss: 0.1035.. Test accuracy: 0.2788.. 0.0083 s/batch  steps 262.0000\n",
      "Epoch: 2/100.. Loss: 0.0793.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 263.0000\n",
      "Epoch: 2/100.. Loss: 0.0838.. Test accuracy: 0.2788.. 0.0090 s/batch  steps 264.0000\n",
      "Epoch: 2/100.. Loss: 0.0828.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 265.0000\n",
      "Epoch: 2/100.. Loss: 0.0763.. Test accuracy: 0.2788.. 0.0101 s/batch  steps 266.0000\n",
      "Epoch: 2/100.. Loss: 0.0754.. Test accuracy: 0.2788.. 0.0089 s/batch  steps 267.0000\n",
      "Epoch: 2/100.. Loss: 0.1012.. Test accuracy: 0.2788.. 0.0097 s/batch  steps 268.0000\n",
      "Epoch: 2/100.. Loss: 0.0860.. Test accuracy: 0.2788.. 0.0111 s/batch  steps 269.0000\n",
      "Epoch: 2/100.. Loss: 0.0860.. Test accuracy: 0.2788.. 0.0091 s/batch  steps 270.0000\n",
      "Epoch: 2/100.. Loss: 0.0819.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 271.0000\n",
      "Epoch: 2/100.. Loss: 0.0800.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 272.0000\n",
      "Epoch: 2/100.. Loss: 0.0874.. Test accuracy: 0.2788.. 0.0088 s/batch  steps 273.0000\n",
      "Epoch: 2/100.. Loss: 0.0754.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 274.0000\n",
      "Epoch: 2/100.. Loss: 0.0797.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 275.0000\n",
      "Epoch: 2/100.. Loss: 0.0989.. Test accuracy: 0.2788.. 0.0084 s/batch  steps 276.0000\n",
      "Epoch: 2/100.. Loss: 0.1012.. Test accuracy: 0.2788.. 0.0100 s/batch  steps 277.0000\n",
      "Epoch: 2/100.. Loss: 0.0936.. Test accuracy: 0.2788.. 0.0107 s/batch  steps 278.0000\n",
      "Epoch: 2/100.. Loss: 0.0903.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 279.0000\n",
      "Epoch: 2/100.. Loss: 0.0799.. Test accuracy: 0.2788.. 0.0133 s/batch  steps 280.0000\n",
      "Epoch: 2/100.. Loss: 0.0835.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 281.0000\n",
      "Epoch: 2/100.. Loss: 0.0721.. Test accuracy: 0.2788.. 0.0105 s/batch  steps 282.0000\n",
      "Epoch: 2/100.. Loss: 0.0868.. Test accuracy: 0.2788.. 0.0131 s/batch  steps 283.0000\n",
      "Epoch: 2/100.. Loss: 0.0815.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 284.0000\n",
      "Epoch: 2/100.. Loss: 0.0987.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 285.0000\n",
      "Epoch: 2/100.. Loss: 0.0942.. Test accuracy: 0.2788.. 0.0122 s/batch  steps 286.0000\n",
      "Epoch: 2/100.. Loss: 0.0968.. Test accuracy: 0.2788.. 0.0088 s/batch  steps 287.0000\n",
      "Epoch: 2/100.. Loss: 0.0778.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 288.0000\n",
      "Epoch: 2/100.. Loss: 0.0902.. Test accuracy: 0.2788.. 0.0099 s/batch  steps 289.0000\n",
      "Epoch: 2/100.. Loss: 0.0832.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 290.0000\n",
      "Epoch: 2/100.. Loss: 0.0901.. Test accuracy: 0.2788.. 0.0109 s/batch  steps 291.0000\n",
      "Epoch: 2/100.. Loss: 0.1029.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 292.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100.. Loss: 0.0749.. Test accuracy: 0.2788.. 0.0098 s/batch  steps 293.0000\n",
      "Epoch: 2/100.. Loss: 0.0922.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 294.0000\n",
      "Epoch: 2/100.. Loss: 0.0889.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 295.0000\n",
      "Epoch: 2/100.. Loss: 0.0867.. Test accuracy: 0.2788.. 0.0100 s/batch  steps 296.0000\n",
      "Epoch: 2/100.. Loss: 0.0745.. Test accuracy: 0.2788.. 0.0094 s/batch  steps 297.0000\n",
      "Epoch: 2/100.. Loss: 0.0858.. Test accuracy: 0.2788.. 0.0095 s/batch  steps 298.0000\n",
      "Epoch: 2/100.. Loss: 0.0894.. Test accuracy: 0.2788.. 0.0105 s/batch  steps 299.0000\n",
      "Epoch: 2/100.. Loss: 0.0701.. Test accuracy: 0.2788.. 0.0116 s/batch  steps 300.0000\n",
      "Epoch: 2/100.. Loss: 0.0781.. Test accuracy: 0.2788.. 0.0093 s/batch  steps 301.0000\n",
      "Epoch: 2/100.. Loss: 0.0836.. Test accuracy: 0.2788.. 0.0096 s/batch  steps 302.0000\n",
      "Epoch: 2/100.. Loss: 0.0861.. Test accuracy: 0.2788.. 0.0107 s/batch  steps 303.0000\n",
      "Epoch: 2/100.. Loss: 0.0823.. Test accuracy: 0.2788.. 0.0101 s/batch  steps 304.0000\n",
      "Epoch: 2/100.. Loss: 0.0901.. Test accuracy: 0.2788.. 0.0091 s/batch  steps 305.0000\n",
      "Epoch: 2/100.. Loss: 0.0875.. Test accuracy: 0.2788.. 0.0109 s/batch  steps 306.0000\n",
      "Epoch: 2/100.. Loss: 0.0750.. Test accuracy: 0.2788.. 0.0085 s/batch  steps 307.0000\n",
      "Epoch: 2/100.. Loss: 0.0897.. Test accuracy: 0.2788.. 0.0104 s/batch  steps 308.0000\n",
      "Epoch: 2/100.. Loss: 0.0830.. Test accuracy: 0.2788.. 0.0097 s/batch  steps 309.0000\n",
      "Epoch: 2/100.. Loss: 0.0936.. Test accuracy: 0.2788.. 0.0108 s/batch  steps 310.0000\n",
      "Epoch: 2/100.. Loss: 0.0893.. Test accuracy: 0.2788.. 0.0105 s/batch  steps 311.0000\n",
      "Epoch: 2/100.. Loss: 0.0849.. Test accuracy: 0.2788.. 0.0103 s/batch  steps 312.0000\n",
      "Epoch: 2/100.. Loss: 0.0735.. Test accuracy: 0.2788.. 0.0102 s/batch  steps 313.0000\n",
      "Epoch: 2/100.. Loss: 0.0740.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 314.0000\n",
      "Epoch: 2/100.. Loss: 0.0810.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 315.0000\n",
      "Epoch: 2/100.. Loss: 0.0731.. Test accuracy: 0.2787.. 0.0113 s/batch  steps 316.0000\n",
      "Epoch: 2/100.. Loss: 0.0732.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 317.0000\n",
      "Epoch: 2/100.. Loss: 0.0936.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 318.0000\n",
      "Epoch: 2/100.. Loss: 0.0782.. Test accuracy: 0.2787.. 0.0129 s/batch  steps 319.0000\n",
      "Epoch: 2/100.. Loss: 0.0811.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 320.0000\n",
      "Epoch: 2/100.. Loss: 0.0726.. Test accuracy: 0.2787.. 0.0086 s/batch  steps 321.0000\n",
      "Epoch: 2/100.. Loss: 0.0872.. Test accuracy: 0.2787.. 0.0088 s/batch  steps 322.0000\n",
      "Epoch: 2/100.. Loss: 0.0943.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 323.0000\n",
      "Epoch: 2/100.. Loss: 0.0847.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 324.0000\n",
      "Epoch: 2/100.. Loss: 0.0837.. Test accuracy: 0.2787.. 0.0082 s/batch  steps 325.0000\n",
      "Epoch: 2/100.. Loss: 0.0933.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 326.0000\n",
      "Epoch: 2/100.. Loss: 0.0763.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 327.0000\n",
      "Epoch: 2/100.. Loss: 0.0939.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 328.0000\n",
      "Epoch: 2/100.. Loss: 0.0676.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 329.0000\n",
      "Epoch: 2/100.. Loss: 0.0856.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 330.0000\n",
      "Epoch: 2/100.. Loss: 0.0833.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 331.0000\n",
      "Epoch: 2/100.. Loss: 0.0880.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 332.0000\n",
      "Epoch: 2/100.. Loss: 0.0924.. Test accuracy: 0.2787.. 0.0091 s/batch  steps 333.0000\n",
      "Epoch: 2/100.. Loss: 0.0732.. Test accuracy: 0.2787.. 0.0127 s/batch  steps 334.0000\n",
      "Epoch: 2/100.. Loss: 0.0913.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 335.0000\n",
      "Epoch: 2/100.. Loss: 0.1092.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 336.0000\n",
      "Epoch: 2/100.. Loss: 0.0805.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 337.0000\n",
      "Epoch: 2/100.. Loss: 0.0790.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 338.0000\n",
      "Epoch: 2/100.. Loss: 0.0955.. Test accuracy: 0.2787.. 0.0109 s/batch  steps 339.0000\n",
      "Epoch: 2/100.. Loss: 0.0762.. Test accuracy: 0.2787.. 0.0118 s/batch  steps 340.0000\n",
      "Epoch: 2/100.. Loss: 0.0755.. Test accuracy: 0.2787.. 0.0093 s/batch  steps 341.0000\n",
      "Epoch: 2/100.. Loss: 0.0823.. Test accuracy: 0.2787.. 0.0131 s/batch  steps 342.0000\n",
      "Epoch: 2/100.. Loss: 0.0806.. Test accuracy: 0.2787.. 0.0105 s/batch  steps 343.0000\n",
      "Epoch: 2/100.. Loss: 0.0945.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 344.0000\n",
      "Epoch: 2/100.. Loss: 0.0840.. Test accuracy: 0.2787.. 0.0112 s/batch  steps 345.0000\n",
      "Epoch: 2/100.. Loss: 0.0797.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 346.0000\n",
      "Epoch: 2/100.. Loss: 0.0765.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 347.0000\n",
      "Epoch: 2/100.. Loss: 0.0764.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 348.0000\n",
      "Epoch: 2/100.. Loss: 0.0868.. Test accuracy: 0.2787.. 0.0135 s/batch  steps 349.0000\n",
      "Epoch: 2/100.. Loss: 0.0707.. Test accuracy: 0.2787.. 0.0124 s/batch  steps 350.0000\n",
      "Epoch: 2/100.. Loss: 0.0932.. Test accuracy: 0.2787.. 0.0101 s/batch  steps 351.0000\n",
      "Epoch: 2/100.. Loss: 0.0774.. Test accuracy: 0.2787.. 0.0113 s/batch  steps 352.0000\n",
      "Epoch: 2/100.. Loss: 0.0764.. Test accuracy: 0.2787.. 0.0129 s/batch  steps 353.0000\n",
      "Epoch: 2/100.. Loss: 0.0959.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 354.0000\n",
      "Epoch: 2/100.. Loss: 0.1050.. Test accuracy: 0.2787.. 0.0113 s/batch  steps 355.0000\n",
      "Epoch: 2/100.. Loss: 0.0852.. Test accuracy: 0.2787.. 0.0105 s/batch  steps 356.0000\n",
      "Epoch: 2/100.. Loss: 0.0847.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 357.0000\n",
      "Epoch: 2/100.. Loss: 0.0876.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 358.0000\n",
      "Epoch: 2/100.. Loss: 0.0738.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 359.0000\n",
      "Epoch: 2/100.. Loss: 0.0875.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 360.0000\n",
      "Epoch: 2/100.. Loss: 0.0914.. Test accuracy: 0.2787.. 0.0109 s/batch  steps 361.0000\n",
      "Epoch: 2/100.. Loss: 0.0816.. Test accuracy: 0.2787.. 0.0127 s/batch  steps 362.0000\n",
      "Epoch: 2/100.. Loss: 0.0963.. Test accuracy: 0.2787.. 0.0121 s/batch  steps 363.0000\n",
      "Epoch: 2/100.. Loss: 0.0919.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 364.0000\n",
      "Epoch: 2/100.. Loss: 0.0807.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 365.0000\n",
      "Epoch: 2/100.. Loss: 0.0847.. Test accuracy: 0.2787.. 0.0093 s/batch  steps 366.0000\n",
      "Epoch: 2/100.. Loss: 0.0841.. Test accuracy: 0.2787.. 0.0093 s/batch  steps 367.0000\n",
      "Epoch: 2/100.. Loss: 0.0734.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 368.0000\n",
      "Epoch: 2/100.. Loss: 0.1062.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 369.0000\n",
      "Epoch: 2/100.. Loss: 0.0795.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 370.0000\n",
      "Epoch: 2/100.. Loss: 0.0761.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 371.0000\n",
      "Epoch: 2/100.. Loss: 0.0772.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 372.0000\n",
      "Epoch: 2/100.. Loss: 0.0905.. Test accuracy: 0.2787.. 0.0088 s/batch  steps 373.0000\n",
      "Epoch: 2/100.. Loss: 0.0834.. Test accuracy: 0.2787.. 0.0088 s/batch  steps 374.0000\n",
      "Epoch: 2/100.. Loss: 0.0776.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 375.0000\n",
      "Epoch: 2/100.. Loss: 0.0892.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 376.0000\n",
      "Epoch: 2/100.. Loss: 0.0877.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 377.0000\n",
      "Epoch: 2/100.. Loss: 0.0788.. Test accuracy: 0.2787.. 0.0109 s/batch  steps 378.0000\n",
      "Epoch: 2/100.. Loss: 0.0901.. Test accuracy: 0.2787.. 0.0113 s/batch  steps 379.0000\n",
      "Epoch: 2/100.. Loss: 0.0899.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 380.0000\n",
      "Epoch: 3/100.. Loss: 0.0792.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 381.0000\n",
      "Epoch: 3/100.. Loss: 0.0871.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 382.0000\n",
      "Epoch: 3/100.. Loss: 0.0931.. Test accuracy: 0.2787.. 0.0090 s/batch  steps 383.0000\n",
      "Epoch: 3/100.. Loss: 0.0842.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 384.0000\n",
      "Epoch: 3/100.. Loss: 0.0735.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 385.0000\n",
      "Epoch: 3/100.. Loss: 0.0742.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 386.0000\n",
      "Epoch: 3/100.. Loss: 0.0750.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 387.0000\n",
      "Epoch: 3/100.. Loss: 0.0808.. Test accuracy: 0.2787.. 0.0093 s/batch  steps 388.0000\n",
      "Epoch: 3/100.. Loss: 0.0758.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 389.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100.. Loss: 0.0893.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 390.0000\n",
      "Epoch: 3/100.. Loss: 0.0649.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 391.0000\n",
      "Epoch: 3/100.. Loss: 0.0732.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 392.0000\n",
      "Epoch: 3/100.. Loss: 0.0783.. Test accuracy: 0.2787.. 0.0129 s/batch  steps 393.0000\n",
      "Epoch: 3/100.. Loss: 0.0822.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 394.0000\n",
      "Epoch: 3/100.. Loss: 0.0863.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 395.0000\n",
      "Epoch: 3/100.. Loss: 0.0802.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 396.0000\n",
      "Epoch: 3/100.. Loss: 0.0750.. Test accuracy: 0.2787.. 0.0109 s/batch  steps 397.0000\n",
      "Epoch: 3/100.. Loss: 0.0690.. Test accuracy: 0.2787.. 0.0086 s/batch  steps 398.0000\n",
      "Epoch: 3/100.. Loss: 0.0847.. Test accuracy: 0.2787.. 0.0148 s/batch  steps 399.0000\n",
      "Epoch: 3/100.. Loss: 0.0736.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 400.0000\n",
      "Epoch: 3/100.. Loss: 0.0926.. Test accuracy: 0.2787.. 0.0087 s/batch  steps 401.0000\n",
      "Epoch: 3/100.. Loss: 0.0894.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 402.0000\n",
      "Epoch: 3/100.. Loss: 0.0980.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 403.0000\n",
      "Epoch: 3/100.. Loss: 0.0885.. Test accuracy: 0.2787.. 0.0124 s/batch  steps 404.0000\n",
      "Epoch: 3/100.. Loss: 0.0751.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 405.0000\n",
      "Epoch: 3/100.. Loss: 0.0962.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 406.0000\n",
      "Epoch: 3/100.. Loss: 0.0861.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 407.0000\n",
      "Epoch: 3/100.. Loss: 0.0717.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 408.0000\n",
      "Epoch: 3/100.. Loss: 0.0830.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 409.0000\n",
      "Epoch: 3/100.. Loss: 0.0707.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 410.0000\n",
      "Epoch: 3/100.. Loss: 0.0742.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 411.0000\n",
      "Epoch: 3/100.. Loss: 0.0840.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 412.0000\n",
      "Epoch: 3/100.. Loss: 0.0827.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 413.0000\n",
      "Epoch: 3/100.. Loss: 0.1055.. Test accuracy: 0.2787.. 0.0140 s/batch  steps 414.0000\n",
      "Epoch: 3/100.. Loss: 0.0872.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 415.0000\n",
      "Epoch: 3/100.. Loss: 0.0810.. Test accuracy: 0.2787.. 0.0115 s/batch  steps 416.0000\n",
      "Epoch: 3/100.. Loss: 0.0894.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 417.0000\n",
      "Epoch: 3/100.. Loss: 0.0749.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 418.0000\n",
      "Epoch: 3/100.. Loss: 0.0811.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 419.0000\n",
      "Epoch: 3/100.. Loss: 0.0698.. Test accuracy: 0.2787.. 0.0088 s/batch  steps 420.0000\n",
      "Epoch: 3/100.. Loss: 0.0912.. Test accuracy: 0.2787.. 0.0119 s/batch  steps 421.0000\n",
      "Epoch: 3/100.. Loss: 0.0829.. Test accuracy: 0.2787.. 0.0149 s/batch  steps 422.0000\n",
      "Epoch: 3/100.. Loss: 0.0831.. Test accuracy: 0.2787.. 0.0193 s/batch  steps 423.0000\n",
      "Epoch: 3/100.. Loss: 0.0731.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 424.0000\n",
      "Epoch: 3/100.. Loss: 0.0782.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 425.0000\n",
      "Epoch: 3/100.. Loss: 0.0885.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 426.0000\n",
      "Epoch: 3/100.. Loss: 0.0753.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 427.0000\n",
      "Epoch: 3/100.. Loss: 0.0902.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 428.0000\n",
      "Epoch: 3/100.. Loss: 0.0688.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 429.0000\n",
      "Epoch: 3/100.. Loss: 0.0845.. Test accuracy: 0.2787.. 0.0105 s/batch  steps 430.0000\n",
      "Epoch: 3/100.. Loss: 0.0832.. Test accuracy: 0.2787.. 0.0087 s/batch  steps 431.0000\n",
      "Epoch: 3/100.. Loss: 0.0823.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 432.0000\n",
      "Epoch: 3/100.. Loss: 0.0777.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 433.0000\n",
      "Epoch: 3/100.. Loss: 0.0722.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 434.0000\n",
      "Epoch: 3/100.. Loss: 0.0882.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 435.0000\n",
      "Epoch: 3/100.. Loss: 0.0922.. Test accuracy: 0.2787.. 0.0159 s/batch  steps 436.0000\n",
      "Epoch: 3/100.. Loss: 0.0751.. Test accuracy: 0.2787.. 0.0116 s/batch  steps 437.0000\n",
      "Epoch: 3/100.. Loss: 0.0699.. Test accuracy: 0.2787.. 0.0115 s/batch  steps 438.0000\n",
      "Epoch: 3/100.. Loss: 0.0878.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 439.0000\n",
      "Epoch: 3/100.. Loss: 0.0915.. Test accuracy: 0.2787.. 0.0156 s/batch  steps 440.0000\n",
      "Epoch: 3/100.. Loss: 0.0768.. Test accuracy: 0.2787.. 0.0126 s/batch  steps 441.0000\n",
      "Epoch: 3/100.. Loss: 0.0787.. Test accuracy: 0.2787.. 0.0138 s/batch  steps 442.0000\n",
      "Epoch: 3/100.. Loss: 0.0859.. Test accuracy: 0.2787.. 0.0147 s/batch  steps 443.0000\n",
      "Epoch: 3/100.. Loss: 0.0811.. Test accuracy: 0.2787.. 0.0098 s/batch  steps 444.0000\n",
      "Epoch: 3/100.. Loss: 0.0870.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 445.0000\n",
      "Epoch: 3/100.. Loss: 0.0892.. Test accuracy: 0.2787.. 0.0109 s/batch  steps 446.0000\n",
      "Epoch: 3/100.. Loss: 0.0823.. Test accuracy: 0.2787.. 0.0131 s/batch  steps 447.0000\n",
      "Epoch: 3/100.. Loss: 0.0789.. Test accuracy: 0.2787.. 0.0116 s/batch  steps 448.0000\n",
      "Epoch: 3/100.. Loss: 0.0801.. Test accuracy: 0.2787.. 0.0090 s/batch  steps 449.0000\n",
      "Epoch: 3/100.. Loss: 0.0830.. Test accuracy: 0.2787.. 0.0080 s/batch  steps 450.0000\n",
      "Epoch: 3/100.. Loss: 0.0745.. Test accuracy: 0.2787.. 0.0116 s/batch  steps 451.0000\n",
      "Epoch: 3/100.. Loss: 0.0932.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 452.0000\n",
      "Epoch: 3/100.. Loss: 0.0914.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 453.0000\n",
      "Epoch: 3/100.. Loss: 0.0980.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 454.0000\n",
      "Epoch: 3/100.. Loss: 0.0980.. Test accuracy: 0.2787.. 0.0086 s/batch  steps 455.0000\n",
      "Epoch: 3/100.. Loss: 0.0725.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 456.0000\n",
      "Epoch: 3/100.. Loss: 0.0872.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 457.0000\n",
      "Epoch: 3/100.. Loss: 0.0893.. Test accuracy: 0.2787.. 0.0084 s/batch  steps 458.0000\n",
      "Epoch: 3/100.. Loss: 0.0889.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 459.0000\n",
      "Epoch: 3/100.. Loss: 0.0656.. Test accuracy: 0.2787.. 0.0083 s/batch  steps 460.0000\n",
      "Epoch: 3/100.. Loss: 0.0860.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 461.0000\n",
      "Epoch: 3/100.. Loss: 0.0850.. Test accuracy: 0.2787.. 0.0115 s/batch  steps 462.0000\n",
      "Epoch: 3/100.. Loss: 0.0629.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 463.0000\n",
      "Epoch: 3/100.. Loss: 0.0926.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 464.0000\n",
      "Epoch: 3/100.. Loss: 0.0813.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 465.0000\n",
      "Epoch: 3/100.. Loss: 0.0837.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 466.0000\n",
      "Epoch: 3/100.. Loss: 0.0852.. Test accuracy: 0.2787.. 0.0088 s/batch  steps 467.0000\n",
      "Epoch: 3/100.. Loss: 0.0818.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 468.0000\n",
      "Epoch: 3/100.. Loss: 0.0838.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 469.0000\n",
      "Epoch: 3/100.. Loss: 0.0978.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 470.0000\n",
      "Epoch: 3/100.. Loss: 0.0802.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 471.0000\n",
      "Epoch: 3/100.. Loss: 0.0888.. Test accuracy: 0.2787.. 0.0085 s/batch  steps 472.0000\n",
      "Epoch: 3/100.. Loss: 0.0961.. Test accuracy: 0.2787.. 0.0105 s/batch  steps 473.0000\n",
      "Epoch: 3/100.. Loss: 0.0876.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 474.0000\n",
      "Epoch: 3/100.. Loss: 0.0937.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 475.0000\n",
      "Epoch: 3/100.. Loss: 0.0700.. Test accuracy: 0.2787.. 0.0113 s/batch  steps 476.0000\n",
      "Epoch: 3/100.. Loss: 0.0747.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 477.0000\n",
      "Epoch: 3/100.. Loss: 0.0809.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 478.0000\n",
      "Epoch: 3/100.. Loss: 0.0820.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 479.0000\n",
      "Epoch: 3/100.. Loss: 0.0938.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 480.0000\n",
      "Epoch: 3/100.. Loss: 0.0784.. Test accuracy: 0.2787.. 0.0081 s/batch  steps 481.0000\n",
      "Epoch: 3/100.. Loss: 0.0744.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 482.0000\n",
      "Epoch: 3/100.. Loss: 0.0799.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 483.0000\n",
      "Epoch: 3/100.. Loss: 0.0729.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 484.0000\n",
      "Epoch: 3/100.. Loss: 0.0898.. Test accuracy: 0.2787.. 0.0109 s/batch  steps 485.0000\n",
      "Epoch: 3/100.. Loss: 0.0790.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 486.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100.. Loss: 0.0908.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 487.0000\n",
      "Epoch: 3/100.. Loss: 0.0947.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 488.0000\n",
      "Epoch: 3/100.. Loss: 0.0871.. Test accuracy: 0.2787.. 0.0128 s/batch  steps 489.0000\n",
      "Epoch: 3/100.. Loss: 0.0790.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 490.0000\n",
      "Epoch: 3/100.. Loss: 0.0747.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 491.0000\n",
      "Epoch: 3/100.. Loss: 0.0805.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 492.0000\n",
      "Epoch: 3/100.. Loss: 0.0807.. Test accuracy: 0.2787.. 0.0113 s/batch  steps 493.0000\n",
      "Epoch: 3/100.. Loss: 0.0896.. Test accuracy: 0.2787.. 0.0182 s/batch  steps 494.0000\n",
      "Epoch: 3/100.. Loss: 0.0762.. Test accuracy: 0.2787.. 0.0113 s/batch  steps 495.0000\n",
      "Epoch: 3/100.. Loss: 0.0971.. Test accuracy: 0.2787.. 0.0119 s/batch  steps 496.0000\n",
      "Epoch: 3/100.. Loss: 0.0692.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 497.0000\n",
      "Epoch: 3/100.. Loss: 0.0834.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 498.0000\n",
      "Epoch: 3/100.. Loss: 0.0846.. Test accuracy: 0.2787.. 0.0117 s/batch  steps 499.0000\n",
      "Epoch: 3/100.. Loss: 0.0786.. Test accuracy: 0.2787.. 0.0132 s/batch  steps 500.0000\n",
      "Epoch: 3/100.. Loss: 0.0890.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 501.0000\n",
      "Epoch: 3/100.. Loss: 0.0883.. Test accuracy: 0.2787.. 0.0135 s/batch  steps 502.0000\n",
      "Epoch: 3/100.. Loss: 0.0713.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 503.0000\n",
      "Epoch: 3/100.. Loss: 0.0815.. Test accuracy: 0.2787.. 0.0118 s/batch  steps 504.0000\n",
      "Epoch: 3/100.. Loss: 0.0804.. Test accuracy: 0.2787.. 0.0090 s/batch  steps 505.0000\n",
      "Epoch: 3/100.. Loss: 0.0746.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 506.0000\n",
      "Epoch: 3/100.. Loss: 0.0910.. Test accuracy: 0.2787.. 0.0121 s/batch  steps 507.0000\n",
      "Epoch: 3/100.. Loss: 0.0922.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 508.0000\n",
      "Epoch: 3/100.. Loss: 0.0843.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 509.0000\n",
      "Epoch: 3/100.. Loss: 0.0959.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 510.0000\n",
      "Epoch: 3/100.. Loss: 0.0708.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 511.0000\n",
      "Epoch: 3/100.. Loss: 0.0705.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 512.0000\n",
      "Epoch: 3/100.. Loss: 0.0803.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 513.0000\n",
      "Epoch: 3/100.. Loss: 0.0805.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 514.0000\n",
      "Epoch: 3/100.. Loss: 0.0803.. Test accuracy: 0.2787.. 0.0115 s/batch  steps 515.0000\n",
      "Epoch: 3/100.. Loss: 0.0828.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 516.0000\n",
      "Epoch: 3/100.. Loss: 0.0928.. Test accuracy: 0.2787.. 0.0081 s/batch  steps 517.0000\n",
      "Epoch: 3/100.. Loss: 0.0873.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 518.0000\n",
      "Epoch: 3/100.. Loss: 0.0780.. Test accuracy: 0.2787.. 0.0109 s/batch  steps 519.0000\n",
      "Epoch: 3/100.. Loss: 0.0804.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 520.0000\n",
      "Epoch: 3/100.. Loss: 0.0631.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 521.0000\n",
      "Epoch: 3/100.. Loss: 0.0747.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 522.0000\n",
      "Epoch: 3/100.. Loss: 0.0769.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 523.0000\n",
      "Epoch: 3/100.. Loss: 0.0879.. Test accuracy: 0.2787.. 0.0110 s/batch  steps 524.0000\n",
      "Epoch: 3/100.. Loss: 0.0887.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 525.0000\n",
      "Epoch: 3/100.. Loss: 0.0952.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 526.0000\n",
      "Epoch: 3/100.. Loss: 0.0770.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 527.0000\n",
      "Epoch: 3/100.. Loss: 0.0885.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 528.0000\n",
      "Epoch: 3/100.. Loss: 0.0874.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 529.0000\n",
      "Epoch: 3/100.. Loss: 0.1015.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 530.0000\n",
      "Epoch: 3/100.. Loss: 0.0843.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 531.0000\n",
      "Epoch: 3/100.. Loss: 0.0839.. Test accuracy: 0.2787.. 0.0116 s/batch  steps 532.0000\n",
      "Epoch: 3/100.. Loss: 0.0785.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 533.0000\n",
      "Epoch: 3/100.. Loss: 0.0857.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 534.0000\n",
      "Epoch: 3/100.. Loss: 0.0893.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 535.0000\n",
      "Epoch: 3/100.. Loss: 0.1006.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 536.0000\n",
      "Epoch: 3/100.. Loss: 0.0963.. Test accuracy: 0.2787.. 0.0084 s/batch  steps 537.0000\n",
      "Epoch: 3/100.. Loss: 0.0825.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 538.0000\n",
      "Epoch: 3/100.. Loss: 0.0800.. Test accuracy: 0.2787.. 0.0098 s/batch  steps 539.0000\n",
      "Epoch: 3/100.. Loss: 0.0826.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 540.0000\n",
      "Epoch: 3/100.. Loss: 0.0831.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 541.0000\n",
      "Epoch: 3/100.. Loss: 0.0733.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 542.0000\n",
      "Epoch: 3/100.. Loss: 0.0807.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 543.0000\n",
      "Epoch: 3/100.. Loss: 0.0834.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 544.0000\n",
      "Epoch: 3/100.. Loss: 0.0807.. Test accuracy: 0.2787.. 0.0094 s/batch  steps 545.0000\n",
      "Epoch: 3/100.. Loss: 0.0956.. Test accuracy: 0.2787.. 0.0098 s/batch  steps 546.0000\n",
      "Epoch: 3/100.. Loss: 0.0740.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 547.0000\n",
      "Epoch: 3/100.. Loss: 0.0941.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 548.0000\n",
      "Epoch: 3/100.. Loss: 0.1014.. Test accuracy: 0.2787.. 0.0098 s/batch  steps 549.0000\n",
      "Epoch: 3/100.. Loss: 0.1004.. Test accuracy: 0.2787.. 0.0093 s/batch  steps 550.0000\n",
      "Epoch: 3/100.. Loss: 0.0963.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 551.0000\n",
      "Epoch: 3/100.. Loss: 0.0831.. Test accuracy: 0.2787.. 0.0098 s/batch  steps 552.0000\n",
      "Epoch: 3/100.. Loss: 0.1082.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 553.0000\n",
      "Epoch: 3/100.. Loss: 0.0900.. Test accuracy: 0.2787.. 0.0101 s/batch  steps 554.0000\n",
      "Epoch: 3/100.. Loss: 0.0826.. Test accuracy: 0.2787.. 0.0101 s/batch  steps 555.0000\n",
      "Epoch: 3/100.. Loss: 0.0837.. Test accuracy: 0.2787.. 0.0089 s/batch  steps 556.0000\n",
      "Epoch: 3/100.. Loss: 0.0882.. Test accuracy: 0.2787.. 0.0101 s/batch  steps 557.0000\n",
      "Epoch: 3/100.. Loss: 0.0947.. Test accuracy: 0.2787.. 0.0098 s/batch  steps 558.0000\n",
      "Epoch: 3/100.. Loss: 0.0928.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 559.0000\n",
      "Epoch: 3/100.. Loss: 0.0798.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 560.0000\n",
      "Epoch: 3/100.. Loss: 0.0883.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 561.0000\n",
      "Epoch: 3/100.. Loss: 0.0831.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 562.0000\n",
      "Epoch: 3/100.. Loss: 0.0854.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 563.0000\n",
      "Epoch: 3/100.. Loss: 0.0785.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 564.0000\n",
      "Epoch: 3/100.. Loss: 0.0961.. Test accuracy: 0.2787.. 0.0092 s/batch  steps 565.0000\n",
      "Epoch: 3/100.. Loss: 0.0859.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 566.0000\n",
      "Epoch: 3/100.. Loss: 0.0971.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 567.0000\n",
      "Epoch: 3/100.. Loss: 0.0891.. Test accuracy: 0.2787.. 0.0101 s/batch  steps 568.0000\n",
      "Epoch: 3/100.. Loss: 0.0913.. Test accuracy: 0.2787.. 0.0150 s/batch  steps 569.0000\n",
      "Epoch: 3/100.. Loss: 0.0880.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 570.0000\n",
      "Epoch: 4/100.. Loss: 0.0650.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 571.0000\n",
      "Epoch: 4/100.. Loss: 0.0896.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 572.0000\n",
      "Epoch: 4/100.. Loss: 0.0618.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 573.0000\n",
      "Epoch: 4/100.. Loss: 0.0836.. Test accuracy: 0.2787.. 0.0121 s/batch  steps 574.0000\n",
      "Epoch: 4/100.. Loss: 0.0907.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 575.0000\n",
      "Epoch: 4/100.. Loss: 0.0847.. Test accuracy: 0.2787.. 0.0096 s/batch  steps 576.0000\n",
      "Epoch: 4/100.. Loss: 0.0817.. Test accuracy: 0.2787.. 0.0083 s/batch  steps 577.0000\n",
      "Epoch: 4/100.. Loss: 0.0868.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 578.0000\n",
      "Epoch: 4/100.. Loss: 0.0808.. Test accuracy: 0.2787.. 0.0101 s/batch  steps 579.0000\n",
      "Epoch: 4/100.. Loss: 0.0641.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 580.0000\n",
      "Epoch: 4/100.. Loss: 0.0865.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 581.0000\n",
      "Epoch: 4/100.. Loss: 0.0782.. Test accuracy: 0.2787.. 0.0086 s/batch  steps 582.0000\n",
      "Epoch: 4/100.. Loss: 0.0878.. Test accuracy: 0.2787.. 0.0082 s/batch  steps 583.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100.. Loss: 0.0726.. Test accuracy: 0.2787.. 0.0107 s/batch  steps 584.0000\n",
      "Epoch: 4/100.. Loss: 0.0910.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 585.0000\n",
      "Epoch: 4/100.. Loss: 0.0849.. Test accuracy: 0.2787.. 0.0108 s/batch  steps 586.0000\n",
      "Epoch: 4/100.. Loss: 0.0744.. Test accuracy: 0.2787.. 0.0098 s/batch  steps 587.0000\n",
      "Epoch: 4/100.. Loss: 0.0815.. Test accuracy: 0.2787.. 0.0103 s/batch  steps 588.0000\n",
      "Epoch: 4/100.. Loss: 0.0873.. Test accuracy: 0.2787.. 0.0090 s/batch  steps 589.0000\n",
      "Epoch: 4/100.. Loss: 0.0748.. Test accuracy: 0.2787.. 0.0132 s/batch  steps 590.0000\n",
      "Epoch: 4/100.. Loss: 0.0722.. Test accuracy: 0.2787.. 0.0104 s/batch  steps 591.0000\n",
      "Epoch: 4/100.. Loss: 0.0789.. Test accuracy: 0.2787.. 0.0140 s/batch  steps 592.0000\n",
      "Epoch: 4/100.. Loss: 0.0863.. Test accuracy: 0.2787.. 0.0121 s/batch  steps 593.0000\n",
      "Epoch: 4/100.. Loss: 0.0975.. Test accuracy: 0.2787.. 0.0097 s/batch  steps 594.0000\n",
      "Epoch: 4/100.. Loss: 0.0858.. Test accuracy: 0.2787.. 0.0100 s/batch  steps 595.0000\n",
      "Epoch: 4/100.. Loss: 0.0787.. Test accuracy: 0.2787.. 0.0102 s/batch  steps 596.0000\n",
      "Epoch: 4/100.. Loss: 0.0838.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 597.0000\n",
      "Epoch: 4/100.. Loss: 0.0703.. Test accuracy: 0.2787.. 0.0114 s/batch  steps 598.0000\n",
      "Epoch: 4/100.. Loss: 0.0869.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 599.0000\n",
      "Epoch: 4/100.. Loss: 0.0955.. Test accuracy: 0.2787.. 0.0123 s/batch  steps 600.0000\n",
      "Epoch: 4/100.. Loss: 0.0769.. Test accuracy: 0.2787.. 0.0133 s/batch  steps 601.0000\n",
      "Epoch: 4/100.. Loss: 0.0834.. Test accuracy: 0.2786.. 0.0102 s/batch  steps 602.0000\n",
      "Epoch: 4/100.. Loss: 0.0812.. Test accuracy: 0.2786.. 0.0098 s/batch  steps 603.0000\n",
      "Epoch: 4/100.. Loss: 0.0814.. Test accuracy: 0.2786.. 0.0098 s/batch  steps 604.0000\n",
      "Epoch: 4/100.. Loss: 0.0871.. Test accuracy: 0.2786.. 0.0112 s/batch  steps 605.0000\n",
      "Epoch: 4/100.. Loss: 0.0824.. Test accuracy: 0.2786.. 0.0107 s/batch  steps 606.0000\n",
      "Epoch: 4/100.. Loss: 0.0962.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 607.0000\n",
      "Epoch: 4/100.. Loss: 0.0853.. Test accuracy: 0.2786.. 0.0088 s/batch  steps 608.0000\n",
      "Epoch: 4/100.. Loss: 0.0836.. Test accuracy: 0.2786.. 0.0098 s/batch  steps 609.0000\n",
      "Epoch: 4/100.. Loss: 0.0768.. Test accuracy: 0.2786.. 0.0090 s/batch  steps 610.0000\n",
      "Epoch: 4/100.. Loss: 0.0868.. Test accuracy: 0.2786.. 0.0127 s/batch  steps 611.0000\n",
      "Epoch: 4/100.. Loss: 0.0909.. Test accuracy: 0.2786.. 0.0161 s/batch  steps 612.0000\n",
      "Epoch: 4/100.. Loss: 0.0831.. Test accuracy: 0.2786.. 0.0136 s/batch  steps 613.0000\n",
      "Epoch: 4/100.. Loss: 0.0874.. Test accuracy: 0.2786.. 0.0118 s/batch  steps 614.0000\n",
      "Epoch: 4/100.. Loss: 0.0712.. Test accuracy: 0.2786.. 0.0107 s/batch  steps 615.0000\n",
      "Epoch: 4/100.. Loss: 0.0884.. Test accuracy: 0.2786.. 0.0109 s/batch  steps 616.0000\n",
      "Epoch: 4/100.. Loss: 0.0754.. Test accuracy: 0.2786.. 0.0139 s/batch  steps 617.0000\n",
      "Epoch: 4/100.. Loss: 0.0722.. Test accuracy: 0.2786.. 0.0103 s/batch  steps 618.0000\n",
      "Epoch: 4/100.. Loss: 0.0770.. Test accuracy: 0.2786.. 0.0112 s/batch  steps 619.0000\n",
      "Epoch: 4/100.. Loss: 0.0816.. Test accuracy: 0.2786.. 0.0118 s/batch  steps 620.0000\n",
      "Epoch: 4/100.. Loss: 0.0718.. Test accuracy: 0.2786.. 0.0111 s/batch  steps 621.0000\n",
      "Epoch: 4/100.. Loss: 0.0861.. Test accuracy: 0.2786.. 0.0100 s/batch  steps 622.0000\n",
      "Epoch: 4/100.. Loss: 0.0840.. Test accuracy: 0.2786.. 0.0116 s/batch  steps 623.0000\n",
      "Epoch: 4/100.. Loss: 0.0919.. Test accuracy: 0.2786.. 0.0124 s/batch  steps 624.0000\n",
      "Epoch: 4/100.. Loss: 0.0915.. Test accuracy: 0.2786.. 0.0120 s/batch  steps 625.0000\n",
      "Epoch: 4/100.. Loss: 0.0887.. Test accuracy: 0.2786.. 0.0120 s/batch  steps 626.0000\n",
      "Epoch: 4/100.. Loss: 0.0834.. Test accuracy: 0.2786.. 0.0111 s/batch  steps 627.0000\n",
      "Epoch: 4/100.. Loss: 0.0838.. Test accuracy: 0.2786.. 0.0101 s/batch  steps 628.0000\n",
      "Epoch: 4/100.. Loss: 0.0741.. Test accuracy: 0.2786.. 0.0114 s/batch  steps 629.0000\n",
      "Epoch: 4/100.. Loss: 0.0821.. Test accuracy: 0.2786.. 0.0109 s/batch  steps 630.0000\n",
      "Epoch: 4/100.. Loss: 0.0741.. Test accuracy: 0.2786.. 0.0104 s/batch  steps 631.0000\n",
      "Epoch: 4/100.. Loss: 0.0846.. Test accuracy: 0.2786.. 0.0093 s/batch  steps 632.0000\n",
      "Epoch: 4/100.. Loss: 0.0691.. Test accuracy: 0.2786.. 0.0106 s/batch  steps 633.0000\n",
      "Epoch: 4/100.. Loss: 0.0827.. Test accuracy: 0.2786.. 0.0098 s/batch  steps 634.0000\n",
      "Epoch: 4/100.. Loss: 0.0932.. Test accuracy: 0.2786.. 0.0089 s/batch  steps 635.0000\n",
      "Epoch: 4/100.. Loss: 0.0793.. Test accuracy: 0.2786.. 0.0090 s/batch  steps 636.0000\n",
      "Epoch: 4/100.. Loss: 0.0883.. Test accuracy: 0.2786.. 0.0097 s/batch  steps 637.0000\n",
      "Epoch: 4/100.. Loss: 0.0762.. Test accuracy: 0.2786.. 0.0103 s/batch  steps 638.0000\n",
      "Epoch: 4/100.. Loss: 0.0867.. Test accuracy: 0.2786.. 0.0108 s/batch  steps 639.0000\n",
      "Epoch: 4/100.. Loss: 0.0798.. Test accuracy: 0.2786.. 0.0099 s/batch  steps 640.0000\n",
      "Epoch: 4/100.. Loss: 0.0979.. Test accuracy: 0.2786.. 0.0086 s/batch  steps 641.0000\n",
      "Epoch: 4/100.. Loss: 0.0901.. Test accuracy: 0.2786.. 0.0103 s/batch  steps 642.0000\n",
      "Epoch: 4/100.. Loss: 0.0768.. Test accuracy: 0.2786.. 0.0107 s/batch  steps 643.0000\n",
      "Epoch: 4/100.. Loss: 0.0809.. Test accuracy: 0.2787.. 0.0106 s/batch  steps 644.0000\n",
      "Epoch: 4/100.. Loss: 0.0902.. Test accuracy: 0.2787.. 0.0095 s/batch  steps 645.0000\n",
      "Epoch: 4/100.. Loss: 0.0765.. Test accuracy: 0.2787.. 0.0111 s/batch  steps 646.0000\n",
      "Epoch: 4/100.. Loss: 0.0848.. Test accuracy: 0.2787.. 0.0105 s/batch  steps 647.0000\n",
      "Epoch: 4/100.. Loss: 0.0901.. Test accuracy: 0.2787.. 0.0099 s/batch  steps 648.0000\n",
      "Epoch: 4/100.. Loss: 0.0786.. Test accuracy: 0.2786.. 0.0102 s/batch  steps 649.0000\n",
      "Epoch: 4/100.. Loss: 0.0894.. Test accuracy: 0.2786.. 0.0105 s/batch  steps 650.0000\n",
      "Epoch: 4/100.. Loss: 0.0823.. Test accuracy: 0.2786.. 0.0103 s/batch  steps 651.0000\n",
      "Epoch: 4/100.. Loss: 0.0831.. Test accuracy: 0.2786.. 0.0094 s/batch  steps 652.0000\n",
      "Epoch: 4/100.. Loss: 0.0859.. Test accuracy: 0.2786.. 0.0097 s/batch  steps 653.0000\n",
      "Epoch: 4/100.. Loss: 0.0891.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 654.0000\n",
      "Epoch: 4/100.. Loss: 0.0765.. Test accuracy: 0.2786.. 0.0098 s/batch  steps 655.0000\n",
      "Epoch: 4/100.. Loss: 0.0780.. Test accuracy: 0.2786.. 0.0094 s/batch  steps 656.0000\n",
      "Epoch: 4/100.. Loss: 0.0719.. Test accuracy: 0.2786.. 0.0091 s/batch  steps 657.0000\n",
      "Epoch: 4/100.. Loss: 0.0567.. Test accuracy: 0.2786.. 0.0110 s/batch  steps 658.0000\n",
      "Epoch: 4/100.. Loss: 0.0709.. Test accuracy: 0.2786.. 0.0097 s/batch  steps 659.0000\n",
      "Epoch: 4/100.. Loss: 0.0832.. Test accuracy: 0.2786.. 0.0101 s/batch  steps 660.0000\n",
      "Epoch: 4/100.. Loss: 0.0705.. Test accuracy: 0.2786.. 0.0093 s/batch  steps 661.0000\n",
      "Epoch: 4/100.. Loss: 0.0882.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 662.0000\n",
      "Epoch: 4/100.. Loss: 0.0759.. Test accuracy: 0.2786.. 0.0089 s/batch  steps 663.0000\n",
      "Epoch: 4/100.. Loss: 0.0873.. Test accuracy: 0.2786.. 0.0095 s/batch  steps 664.0000\n",
      "Epoch: 4/100.. Loss: 0.0773.. Test accuracy: 0.2786.. 0.0104 s/batch  steps 665.0000\n",
      "Epoch: 4/100.. Loss: 0.0939.. Test accuracy: 0.2786.. 0.0110 s/batch  steps 666.0000\n",
      "Epoch: 4/100.. Loss: 0.0874.. Test accuracy: 0.2786.. 0.0111 s/batch  steps 667.0000\n",
      "Epoch: 4/100.. Loss: 0.0761.. Test accuracy: 0.2786.. 0.0107 s/batch  steps 668.0000\n",
      "Epoch: 4/100.. Loss: 0.0864.. Test accuracy: 0.2786.. 0.0089 s/batch  steps 669.0000\n",
      "Epoch: 4/100.. Loss: 0.0973.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 670.0000\n",
      "Epoch: 4/100.. Loss: 0.0800.. Test accuracy: 0.2786.. 0.0094 s/batch  steps 671.0000\n",
      "Epoch: 4/100.. Loss: 0.1019.. Test accuracy: 0.2786.. 0.0097 s/batch  steps 672.0000\n",
      "Epoch: 4/100.. Loss: 0.0923.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 673.0000\n",
      "Epoch: 4/100.. Loss: 0.0781.. Test accuracy: 0.2786.. 0.0091 s/batch  steps 674.0000\n",
      "Epoch: 4/100.. Loss: 0.0989.. Test accuracy: 0.2786.. 0.0103 s/batch  steps 675.0000\n",
      "Epoch: 4/100.. Loss: 0.0805.. Test accuracy: 0.2786.. 0.0104 s/batch  steps 676.0000\n",
      "Epoch: 4/100.. Loss: 0.0924.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 677.0000\n",
      "Epoch: 4/100.. Loss: 0.0805.. Test accuracy: 0.2786.. 0.0101 s/batch  steps 678.0000\n",
      "Epoch: 4/100.. Loss: 0.0860.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 679.0000\n",
      "Epoch: 4/100.. Loss: 0.0857.. Test accuracy: 0.2786.. 0.0112 s/batch  steps 680.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100.. Loss: 0.0944.. Test accuracy: 0.2786.. 0.0100 s/batch  steps 681.0000\n",
      "Epoch: 4/100.. Loss: 0.0753.. Test accuracy: 0.2786.. 0.0099 s/batch  steps 682.0000\n",
      "Epoch: 4/100.. Loss: 0.0822.. Test accuracy: 0.2786.. 0.0106 s/batch  steps 683.0000\n",
      "Epoch: 4/100.. Loss: 0.0752.. Test accuracy: 0.2786.. 0.0105 s/batch  steps 684.0000\n",
      "Epoch: 4/100.. Loss: 0.0892.. Test accuracy: 0.2786.. 0.0109 s/batch  steps 685.0000\n",
      "Epoch: 4/100.. Loss: 0.0883.. Test accuracy: 0.2786.. 0.0114 s/batch  steps 686.0000\n",
      "Epoch: 4/100.. Loss: 0.0846.. Test accuracy: 0.2786.. 0.0088 s/batch  steps 687.0000\n",
      "Epoch: 4/100.. Loss: 0.0796.. Test accuracy: 0.2786.. 0.0104 s/batch  steps 688.0000\n",
      "Epoch: 4/100.. Loss: 0.0873.. Test accuracy: 0.2786.. 0.0100 s/batch  steps 689.0000\n",
      "Epoch: 4/100.. Loss: 0.0824.. Test accuracy: 0.2786.. 0.0099 s/batch  steps 690.0000\n",
      "Epoch: 4/100.. Loss: 0.0858.. Test accuracy: 0.2786.. 0.0147 s/batch  steps 691.0000\n",
      "Epoch: 4/100.. Loss: 0.0882.. Test accuracy: 0.2786.. 0.0115 s/batch  steps 692.0000\n",
      "Epoch: 4/100.. Loss: 0.0922.. Test accuracy: 0.2786.. 0.0100 s/batch  steps 693.0000\n",
      "Epoch: 4/100.. Loss: 0.0799.. Test accuracy: 0.2786.. 0.0089 s/batch  steps 694.0000\n",
      "Epoch: 4/100.. Loss: 0.0827.. Test accuracy: 0.2786.. 0.0112 s/batch  steps 695.0000\n",
      "Epoch: 4/100.. Loss: 0.0795.. Test accuracy: 0.2786.. 0.0105 s/batch  steps 696.0000\n",
      "Epoch: 4/100.. Loss: 0.0751.. Test accuracy: 0.2786.. 0.0096 s/batch  steps 697.0000\n",
      "Epoch: 4/100.. Loss: 0.0927.. Test accuracy: 0.2786.. 0.0102 s/batch  steps 698.0000\n",
      "Epoch: 4/100.. Loss: 0.0795.. Test accuracy: 0.2786.. 0.0104 s/batch  steps 699.0000\n",
      "Epoch: 4/100.. Loss: 0.0922.. Test accuracy: 0.2786.. 0.0113 s/batch  steps 700.0000\n",
      "Epoch: 4/100.. Loss: 0.0725.. Test accuracy: 0.2786.. 0.0141 s/batch  steps 701.0000\n",
      "Epoch: 4/100.. Loss: 0.0767.. Test accuracy: 0.2786.. 0.0113 s/batch  steps 702.0000\n",
      "Epoch: 4/100.. Loss: 0.0939.. Test accuracy: 0.2786.. 0.0120 s/batch  steps 703.0000\n",
      "Epoch: 4/100.. Loss: 0.0779.. Test accuracy: 0.2786.. 0.0109 s/batch  steps 704.0000\n",
      "Epoch: 4/100.. Loss: 0.0821.. Test accuracy: 0.2786.. 0.0098 s/batch  steps 705.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-301b1622d856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7ed741e01739>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7ed741e01739>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# in order to reshape the tensor for as many columns we need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 168\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0m_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "epochs = 100\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 1\n",
    "vec_acc_ = np.zeros(epochs*25)\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Do not forget to transform the inputs and outputs into Variable        #\n",
    "        # which pytorch uses.                                                          #\n",
    "        ################################################################################\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        output = net.forward(inputs)\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        grad = loss.backward()\n",
    "        optimizer.step()\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            sum_accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                inputs = Variable(images)\n",
    "                targets = Variable(labels)\n",
    "                predicted = net.predict(inputs)\n",
    "                accuracy = criterion(predicted, targets)\n",
    "                accuracy = accuracy.data.numpy().tolist()[0]\n",
    "                #vec_acc_[steps-1] = accuracy/(ii+1)\n",
    "                sum_accuracy += accuracy\n",
    "                \n",
    "                #inputs = Variable(images, volatile=True)\n",
    "                #predicted = net.predict(inputs)\n",
    "                #equality = (labels == predicted.max(1)[1])\n",
    "                #accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "                \n",
    "                \n",
    "                #im = Variable(images)\n",
    "                #out = net.predict(im)\n",
    "                #_,prediction = torch.max(out, 1)\n",
    "                #pred_y = prediction.data.numpy().squeeze()\n",
    "                #target_y = labels.numpy()\n",
    "                #accuracy = np.mean(predicted == inputs)\n",
    "                #print(pred_y.shape,target_y.shape)\n",
    "                \n",
    "                \n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(loss.data[0]),\n",
    "                  \"Test accuracy: {:.4f}..\".format(sum_accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch \".format((stop - start)/print_every),\n",
    "                  \"steps {:.4f}\".format(steps)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
