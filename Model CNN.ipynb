{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import helper\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.unicode'] = True\n",
    "\n",
    "# For the notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biwi = pd.read_csv('./data/train/biwi/biwi_hotel.txt', header = None,\n",
    "                 names = ['frameNb','id', 'x','y'],delimiter=' ')\n",
    "id_unique = np.unique(np.array(biwi['id']))\n",
    "\n",
    "init = np.zeros(len(biwi)) \n",
    "biwi['Speed'] = init\n",
    "biwi['Angle'] = init\n",
    "biwi['Vx'] = init\n",
    "biwi['Vy'] = init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None ## Disable StettingWithCopy warning\n",
    "c = 0\n",
    "for i in id_unique:\n",
    "    a = biwi[biwi['id']==i]\n",
    "    ind = a.index\n",
    "    a.index = range(len(a))\n",
    "    dist = a['x'].iloc\n",
    "    dist1 = a.loc[0:len(a)-2,'x':'y']\n",
    "    dist1.index=range(len(dist1))\n",
    "    dist2 = a.loc[1:,'x':'y']\n",
    "    dist2.index=range(len(dist2))\n",
    "    dist = dist2-dist1\n",
    "    b = len(dist)\n",
    "    if c < b:\n",
    "        vector_speed = np.zeros((len(id_unique),b,2))\n",
    "        c=b\n",
    "b = 0\n",
    "for i in id_unique:\n",
    "    a = biwi[biwi['id']==i]\n",
    "    ind = a.index\n",
    "    a.index = range(len(a))\n",
    "    dist = a['x'].iloc\n",
    "    dist1 = a.loc[0:len(a)-2,'x':'y']\n",
    "    dist1.index=range(len(dist1))\n",
    "    dist2 = a.loc[1:,'x':'y']\n",
    "    dist2.index=range(len(dist2))\n",
    "    dist = dist2-dist1\n",
    "    speed = np.array(np.sqrt(dist['x']**2+dist['y']**2)/0.4)\n",
    "    biwi.loc[ind[1:],'Speed'] = speed\n",
    "    angle=np.zeros(len(dist)-1)\n",
    "    vx=np.zeros(len(dist))\n",
    "    vy=np.zeros(len(dist))\n",
    "    #vector_speed = np.zeros(2*len(dist))\n",
    "    #vector_speed[i][:][:]=biwi[biwi['id']==i]\n",
    "    for j in range(len(dist)-1):\n",
    "        if norm(dist.loc[j,:])==0 or norm(dist.loc[j+1,:])==0:\n",
    "            angle[j]=0\n",
    "        elif np.cross(dist.loc[j,:],dist.loc[j+1,:])/(norm(dist.loc[j,:])*norm(dist.loc[j+1,:]))>1:\n",
    "            angle[j]=np.arcsin(1)\n",
    "        else:\n",
    "            angle[j]=np.arcsin(np.cross(dist.loc[j,:],dist.loc[j+1,:])/(norm(dist.loc[j,:])*norm(dist.loc[j+1,:])))\n",
    "    \n",
    "    for j in range(len(dist)):\n",
    "        if j == 0:\n",
    "            vx[j] = 0\n",
    "            vy[j] = speed[j]\n",
    "            vector_speed[b][j][0]=vx[j]\n",
    "            vector_speed[b][j][1]=vy[j]\n",
    "        else:\n",
    "            vx[j] = speed[j]*np.sin(sum(angle[:j]))\n",
    "            vy[j] = speed[j]*np.cos(sum(angle[:j]))\n",
    "            vector_speed[b][j][0]=vx[j]\n",
    "            vector_speed[b][j][1]=vy[j]\n",
    "    \n",
    "    biwi.loc[ind[2:],'Angle'] = angle\n",
    "    biwi.loc[ind[1:],'Vx'] = vx\n",
    "    biwi.loc[ind[1:],'Vy'] = vy\n",
    "    b+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "#vector_train = pd.concat([biwi['Vx'],biwi['Vy']],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5510"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_train = np.zeros((len(vector_speed),2*len(vector_speed[0])))\n",
    "for i in range(len(vector_speed)):\n",
    "    vector_train[i][:] = np.reshape(vector_speed[3][:][:],2*19,'C')\n",
    "vector_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=3, n_output=10):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Define 2 or more different layers of the neural network                      #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_input_channels,8,5,padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True)\n",
    "     \n",
    "        self.fc1 = nn.Linear(19*2 * 8, 19*2 * 8)\n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Set up the forward pass that the input data will go through.                 #\n",
    "        # A good activation function betweent the layers is a ReLu function.           #\n",
    "        #                                                                              #\n",
    "        # Note that the output of the last convolution layer should be flattened       #\n",
    "        # before being inputted to the fully connected layer. We can flatten           #\n",
    "        # Variable `x` with `x.view`.                                                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        x = x.view(-1, 19*2 * 40) # in order to reshape the tensor for as many columns we need\n",
    "        x = self.fc1(x)\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConvNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2b7ae81d078c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# TODO:                                                                        #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Choose an Optimizer that will be used to minimize the loss function.         #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Choose a critera that measures the loss                                      #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ConvNet' is not defined"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 50\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Do not forget to transform the inputs and outputs into Variable        #\n",
    "        # which pytorch uses.                                                          #\n",
    "        ################################################################################\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        output = net.forward(inputs)\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        grad = loss.backward()\n",
    "        optimizer.step()\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                inputs = Variable(images, volatile=True)\n",
    "                \n",
    "                predicted = net.predict(inputs).data\n",
    "                equality = (labels == predicted.max(1)[1])\n",
    "                accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "                \n",
    "                \n",
    "                #im = Variable(images)\n",
    "                #out = net.predict(im)\n",
    "                #_,prediction = torch.max(out, 1)\n",
    "                #pred_y = prediction.data.numpy().squeeze()\n",
    "                #target_y = labels.numpy()\n",
    "                #accuracy = np.mean(pred_y == target_y)\n",
    "                #print(pred_y.shape,target_y.shape)\n",
    "                \n",
    "                \n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}..\".format(accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch\".format((stop - start)/print_every)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
