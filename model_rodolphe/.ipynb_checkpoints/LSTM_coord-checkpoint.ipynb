{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1104896d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from LSTM import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pdb\n",
    "\n",
    "# For the notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 5157, 2),\n",
       " torch.Size([5157, 11, 2]),\n",
       " (10, 5157, 2),\n",
       " torch.Size([5157, 10, 162]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_train_coord = pickle.load( open( \"../import_dataset_2/train/gt_train_coord.pkl\", \"rb\" ) )\n",
    "gt_train  = pickle.load( open( \"../import_dataset_2/train/gt_train.pkl\", \"rb\" ) )\n",
    "in_train_coord  = pickle.load( open( \"../import_dataset_2/train/in_train_coord.pkl\", \"rb\" ) )\n",
    "inputs_train = pickle.load( open( \"../import_dataset_2/train/inputs_train.pkl\", \"rb\" ) )\n",
    "\n",
    "coord_ind = np.append(np.arange(0,2),np.arange(4,164))\n",
    "inputs_train = inputs_train[:,:,coord_ind]\n",
    "gt_train = gt_train[:,:,:2]\n",
    "\n",
    "inputs_train = torch.from_numpy(inputs_train).float()\n",
    "gt_train = torch.from_numpy(gt_train).float()\n",
    "gt_train_coord.shape,gt_train.shape,in_train_coord.shape,inputs_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 1719, 2),\n",
       " torch.Size([1719, 11, 2]),\n",
       " (10, 1719, 2),\n",
       " torch.Size([1719, 10, 162]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_validation_coord = pickle.load( open( \"../import_dataset_2/validation/gt_validation_coord.pkl\", \"rb\" ) )\n",
    "gt_validation = pickle.load( open( \"../import_dataset_2/validation/gt_validation.pkl\", \"rb\" ) )\n",
    "in_validation_coord = pickle.load( open( \"../import_dataset_2/validation/in_validation_coord.pkl\", \"rb\" ) )\n",
    "inputs_validation = pickle.load( open( \"../import_dataset_2/validation/inputs_validation.pkl\", \"rb\" ) )\n",
    "\n",
    "coord_ind = np.append(np.arange(0,2),np.arange(4,164))\n",
    "inputs_validation = inputs_validation[:,:,coord_ind]\n",
    "gt_validation = gt_validation[:,:,:2]\n",
    "\n",
    "inputs_validation = torch.from_numpy(inputs_validation).float()\n",
    "gt_validation = torch.from_numpy(gt_validation).float()\n",
    "\n",
    "gt_validation_coord.shape,gt_validation.shape,in_validation_coord.shape,inputs_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "inp_size = np.int(inputs_train.shape[2]/4)\n",
    "lr = 0.01\n",
    "lstm = LSTM(input_size = inputs_train.shape[2], output_size = 2, num_layers=2, hidden_size=128)\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=lr,weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traindataset = utils.TensorDataset(inputs_train, gt_train[:,1:,:])\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=16, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(inputs_validation, gt_validation[:,1:,:])\n",
    "valloader = utils.DataLoader(valdataset, batch_size=16, shuffle=True)\n",
    "\n",
    "epochs = 2\n",
    "steps = 0\n",
    "print_every = 323\n",
    "running_loss = 0 #### DOD\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    total_train_loss=0\n",
    "    steps_bis = 0\n",
    "    if (e+1)%10==0:\n",
    "        lr /= 2\n",
    "        optimizer = optim.Adam(lstm.parameters(), lr=lr)\n",
    "\n",
    "    for train_coord, ground_tru in iter(trainloader):\n",
    "        steps += 1\n",
    "        steps_bis+=1\n",
    "        \n",
    "        train_coord = train_coord.permute([1,0,2])\n",
    "        ground_tru = ground_tru.permute([1,0,2])\n",
    "\n",
    "        in_train = Variable(train_coord)\n",
    "        targets = Variable(ground_tru)\n",
    "        optimizer.zero_grad()\n",
    "        #print(in_train.shape)\n",
    "        #print(targets.shape)\n",
    "        out = lstm.forward(in_train)\n",
    "    \n",
    "        #pdb.set_trace()\n",
    "        loss1 = (criterion(out[:,:,0:2], targets[:,:,0:2]))\n",
    "\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += (loss1).item()\n",
    "        total_train_loss += (loss1).item()\n",
    "    \n",
    "        if steps % print_every == 0:\n",
    "                stop = time.time()\n",
    "                val_loss=0\n",
    "                for ii, (valcoord, valgt) in enumerate(valloader):\n",
    "                    valcoord = valcoord.permute([1,0,2])\n",
    "                    valgt = valgt.permute([1,0,2])\n",
    "                    inputs = Variable(valcoord, volatile=True)\n",
    "                    predicted = lstm.predict(inputs)\n",
    "                    \n",
    "                    val_loss+= (criterion(predicted[:,:,0:2],valgt[:,:,0:2]).item())\n",
    "                    \n",
    "                print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Validation loss: {:.4f}..\".format(val_loss/ii),\n",
    "                  \"Training loss: {:.4f}..\".format(running_loss/print_every),\n",
    "                  \"{:.4f} s/batch\".format((stop - start)/print_every)\n",
    "                 )\n",
    "                loss_val.append(val_loss/ii)\n",
    "                running_loss = 0\n",
    "                start = time.time()\n",
    "    loss_train.append(total_train_loss/steps_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = np.arange(1,epochs+1)\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=20)\n",
    "\n",
    "plt.plot(epoch,loss_train,label='Training loss')\n",
    "plt.plot(epoch,loss_val,c='k',label='Validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE error')\n",
    "plt.legend()\n",
    "plt.savefig(r'./figures/loss_coord.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), 'coord_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,\n",
       "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "        30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
       "       160, 161, 162, 163, 164])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4,165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5157, 10, 164])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.arange(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.append(np.arange(0,2),np.arange(4,164))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
       "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "        54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "       158, 159, 160, 161, 162, 163])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "caca = inputs_train[:,:,vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5157, 10, 162])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(caca[:,:,2:4]-inputs_train[:,:,4:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_train.shape[2]+2)-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
