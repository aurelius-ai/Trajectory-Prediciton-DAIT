{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import helper\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.unicode'] = True\n",
    "\n",
    "# For the notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biwi = pd.read_csv('./data/train/biwi/biwi_hotel.txt', header = None,\n",
    "                 names = ['frameNb','id', 'x','y'],delimiter=' ')\n",
    "id_unique = np.unique(np.array(biwi['id']))\n",
    "\n",
    "init = np.zeros(len(biwi)) \n",
    "biwi['Speed'] = init\n",
    "biwi['Angle'] = init\n",
    "biwi['Vx'] = init\n",
    "biwi['Vy'] = init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None ## Disable StettingWithCopy warning\n",
    "c = 0\n",
    "for i in id_unique:\n",
    "    a = biwi[biwi['id']==i]\n",
    "    ind = a.index\n",
    "    a.index = range(len(a))\n",
    "    dist = a['x'].iloc\n",
    "    dist1 = a.loc[0:len(a)-2,'x':'y']\n",
    "    dist1.index=range(len(dist1))\n",
    "    dist2 = a.loc[1:,'x':'y']\n",
    "    dist2.index=range(len(dist2))\n",
    "    dist = dist2-dist1\n",
    "    b = len(dist)\n",
    "    if c < b:\n",
    "        vector_speed = np.zeros((len(id_unique),b,2))\n",
    "        c=b\n",
    "b = 0\n",
    "for i in id_unique:\n",
    "    a = biwi[biwi['id']==i]\n",
    "    ind = a.index\n",
    "    a.index = range(len(a))\n",
    "    dist = a['x'].iloc\n",
    "    dist1 = a.loc[0:len(a)-2,'x':'y']\n",
    "    dist1.index=range(len(dist1))\n",
    "    dist2 = a.loc[1:,'x':'y']\n",
    "    dist2.index=range(len(dist2))\n",
    "    dist = dist2-dist1\n",
    "    speed = np.array(np.sqrt(dist['x']**2+dist['y']**2)/0.4)\n",
    "    biwi.loc[ind[1:],'Speed'] = speed\n",
    "    angle=np.zeros(len(dist)-1)\n",
    "    vx=np.zeros(len(dist))\n",
    "    vy=np.zeros(len(dist))\n",
    "    for j in range(len(dist)-1):\n",
    "        if norm(dist.loc[j,:])==0 or norm(dist.loc[j+1,:])==0:\n",
    "            angle[j]=0\n",
    "        elif np.cross(dist.loc[j,:],dist.loc[j+1,:])/(norm(dist.loc[j,:])*norm(dist.loc[j+1,:]))>1:\n",
    "            angle[j]=np.arcsin(1)\n",
    "        else:\n",
    "            angle[j]=np.arcsin(np.cross(dist.loc[j,:],dist.loc[j+1,:])/(norm(dist.loc[j,:])*norm(dist.loc[j+1,:])))\n",
    "    \n",
    "    for j in range(len(dist)):\n",
    "        if j == 0:\n",
    "            vx[j] = 0\n",
    "            vy[j] = speed[j]\n",
    "            vector_speed[b][j][0]=vx[j]\n",
    "            vector_speed[b][j][1]=vy[j]\n",
    "        else:\n",
    "            vx[j] = speed[j]*np.sin(sum(angle[:j]))\n",
    "            vy[j] = speed[j]*np.cos(sum(angle[:j]))\n",
    "            vector_speed[b][j][0]=vx[j]\n",
    "            vector_speed[b][j][1]=vy[j]\n",
    "    \n",
    "    biwi.loc[ind[2:],'Angle'] = angle\n",
    "    biwi.loc[ind[1:],'Vx'] = vx\n",
    "    biwi.loc[ind[1:],'Vy'] = vy\n",
    "    b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.zeros((len(vector_speed),2*len(vector_speed[0])))\n",
    "x = np.zeros((len(vector_speed),18))\n",
    "y = np.zeros((len(vector_speed),18))\n",
    "x_train = np.zeros((len(vector_speed)-20,18))\n",
    "Y_train = np.zeros((len(vector_speed)-20,18))\n",
    "x_val = np.zeros((20,18))\n",
    "y_val = np.zeros((20,18))\n",
    "\n",
    "for i in range(len(vector_speed)):\n",
    "    vector[i][:] = np.reshape(vector_speed[i][:][:],2*19,'C')\n",
    "for i in range(len(vector)):\n",
    "    x[i][:] = vector[i][:18]\n",
    "    y[i][:] = vector[i][20:38]\n",
    "\n",
    "mask = list(range(len(vector)-20, len(vector)))\n",
    "x_val = x[mask]\n",
    "y_val = y[mask]\n",
    "mask = list(range(len(vector)-20))\n",
    "x_train = x[mask]\n",
    "y_train = y[mask]\n",
    "\n",
    "x_train,y_train = torch.from_numpy(x_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "x_val,y_val = torch.from_numpy(x_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.FloatTensor)\n",
    "\n",
    "x_train = x_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "y_train = y_train.unsqueeze(1) # add 1 dimension to the training set\n",
    "x_val = x_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "y_val = y_val.unsqueeze(1) # add 1 dimension to the validation set\n",
    "\n",
    "traindataset = utils.TensorDataset(x_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(x_val, y_val)\n",
    "valloader = utils.DataLoader(traindataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=1, n_output=None):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Define 2 or more different layers of the neural network                      #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_input_channels,1,4,padding=2)\n",
    "        #self.conv1_bn = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True)\n",
    "     \n",
    "        self.fc1 = nn.Linear(9*2 * 1, 9*2 * 1)\n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Set up the forward pass that the input data will go through.                 #\n",
    "        # A good activation function betweent the layers is a ReLu function.           #\n",
    "        #                                                                              #\n",
    "        # Note that the output of the last convolution layer should be flattened       #\n",
    "        # before being inputted to the fully connected layer. We can flatten           #\n",
    "        # Variable `x` with `x.view`.                                                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 9*2 * 1) # in order to reshape the tensor for as many columns we need\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/4romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4.. Loss: 0.8613.. Test accuracy: 0.0077.. 0.0010 s/batch\n",
      "Epoch: 1/4.. Loss: 0.8703.. Test accuracy: 0.0163.. 0.0007 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5527.. Test accuracy: 0.0183.. 0.0004 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5116.. Test accuracy: 0.0354.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.3737.. Test accuracy: 0.0105.. 0.0007 s/batch\n",
      "Epoch: 1/4.. Loss: 0.7124.. Test accuracy: 0.0276.. 0.0007 s/batch\n",
      "Epoch: 1/4.. Loss: 0.9205.. Test accuracy: 0.0269.. 0.0007 s/batch\n",
      "Epoch: 1/4.. Loss: 0.6515.. Test accuracy: 0.0159.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.7616.. Test accuracy: 0.0312.. 0.0004 s/batch\n",
      "Epoch: 1/4.. Loss: 1.0722.. Test accuracy: 0.0063.. 0.0004 s/batch\n",
      "Epoch: 1/4.. Loss: 0.1561.. Test accuracy: 0.0171.. 0.0005 s/batch\n",
      "Epoch: 1/4.. Loss: 0.6343.. Test accuracy: 0.0211.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5780.. Test accuracy: 0.0206.. 0.0007 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5056.. Test accuracy: 0.0139.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.3702.. Test accuracy: 0.0208.. 0.0005 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5016.. Test accuracy: 0.0090.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5651.. Test accuracy: 0.0344.. 0.0007 s/batch\n",
      "Epoch: 1/4.. Loss: 0.7417.. Test accuracy: 0.0227.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.1493.. Test accuracy: 0.0205.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.3548.. Test accuracy: 0.0200.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5002.. Test accuracy: 0.0540.. 0.0005 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5018.. Test accuracy: 0.0156.. 0.0008 s/batch\n",
      "Epoch: 1/4.. Loss: 0.5096.. Test accuracy: 0.0202.. 0.0008 s/batch\n",
      "Epoch: 1/4.. Loss: 0.4641.. Test accuracy: 0.0071.. 0.0006 s/batch\n",
      "Epoch: 1/4.. Loss: 0.7392.. Test accuracy: 0.0178.. 0.0004 s/batch\n",
      "Epoch: 2/4.. Loss: 0.9571.. Test accuracy: 0.0248.. 0.0007 s/batch\n",
      "Epoch: 2/4.. Loss: 0.2198.. Test accuracy: 0.0052.. 0.0006 s/batch\n",
      "Epoch: 2/4.. Loss: 0.6446.. Test accuracy: 0.0279.. 0.0006 s/batch\n",
      "Epoch: 2/4.. Loss: 0.1843.. Test accuracy: 0.0297.. 0.0007 s/batch\n",
      "Epoch: 2/4.. Loss: 0.5536.. Test accuracy: 0.0096.. 0.0007 s/batch\n",
      "Epoch: 2/4.. Loss: 0.8172.. Test accuracy: 0.0133.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.1169.. Test accuracy: 0.0113.. 0.0006 s/batch\n",
      "Epoch: 2/4.. Loss: 0.6838.. Test accuracy: 0.0188.. 0.0006 s/batch\n",
      "Epoch: 2/4.. Loss: 0.5234.. Test accuracy: 0.0264.. 0.0004 s/batch\n",
      "Epoch: 2/4.. Loss: 0.7167.. Test accuracy: 0.0100.. 0.0010 s/batch\n",
      "Epoch: 2/4.. Loss: 0.2524.. Test accuracy: 0.0234.. 0.0009 s/batch\n",
      "Epoch: 2/4.. Loss: 0.5580.. Test accuracy: 0.0206.. 0.0010 s/batch\n",
      "Epoch: 2/4.. Loss: 0.1796.. Test accuracy: 0.0122.. 0.0007 s/batch\n",
      "Epoch: 2/4.. Loss: 0.5674.. Test accuracy: 0.0102.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.7010.. Test accuracy: 0.0221.. 0.0007 s/batch\n",
      "Epoch: 2/4.. Loss: 0.4316.. Test accuracy: 0.0071.. 0.0006 s/batch\n",
      "Epoch: 2/4.. Loss: 0.5165.. Test accuracy: 0.0173.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.9418.. Test accuracy: 0.0229.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.6864.. Test accuracy: 0.0318.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.5184.. Test accuracy: 0.0167.. 0.0006 s/batch\n",
      "Epoch: 2/4.. Loss: 0.4777.. Test accuracy: 0.0235.. 0.0006 s/batch\n",
      "Epoch: 2/4.. Loss: 0.4999.. Test accuracy: 0.0272.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.6928.. Test accuracy: 0.0170.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.6594.. Test accuracy: 0.0297.. 0.0005 s/batch\n",
      "Epoch: 2/4.. Loss: 0.8250.. Test accuracy: 0.0262.. 0.0005 s/batch\n",
      "Epoch: 3/4.. Loss: 0.7587.. Test accuracy: 0.0077.. 0.0009 s/batch\n",
      "Epoch: 3/4.. Loss: 0.7891.. Test accuracy: 0.0190.. 0.0008 s/batch\n",
      "Epoch: 3/4.. Loss: 0.7773.. Test accuracy: 0.0084.. 0.0007 s/batch\n",
      "Epoch: 3/4.. Loss: 0.3050.. Test accuracy: 0.0185.. 0.0008 s/batch\n",
      "Epoch: 3/4.. Loss: 0.7112.. Test accuracy: 0.0253.. 0.0008 s/batch\n",
      "Epoch: 3/4.. Loss: 0.7430.. Test accuracy: 0.0137.. 0.0005 s/batch\n",
      "Epoch: 3/4.. Loss: 0.6717.. Test accuracy: 0.0242.. 0.0006 s/batch\n",
      "Epoch: 3/4.. Loss: 0.3853.. Test accuracy: 0.0179.. 0.0008 s/batch\n",
      "Epoch: 3/4.. Loss: 0.4980.. Test accuracy: 0.0063.. 0.0010 s/batch\n",
      "Epoch: 3/4.. Loss: 0.3101.. Test accuracy: 0.0198.. 0.0007 s/batch\n",
      "Epoch: 3/4.. Loss: 0.3444.. Test accuracy: 0.0213.. 0.0008 s/batch\n",
      "Epoch: 3/4.. Loss: 0.1690.. Test accuracy: 0.0199.. 0.0004 s/batch\n",
      "Epoch: 3/4.. Loss: 0.2585.. Test accuracy: 0.0148.. 0.0007 s/batch\n",
      "Epoch: 3/4.. Loss: 0.8076.. Test accuracy: 0.0183.. 0.0004 s/batch\n",
      "Epoch: 3/4.. Loss: 0.3872.. Test accuracy: 0.0439.. 0.0007 s/batch\n",
      "Epoch: 3/4.. Loss: 0.5268.. Test accuracy: 0.0111.. 0.0009 s/batch\n",
      "Epoch: 3/4.. Loss: 0.8957.. Test accuracy: 0.0164.. 0.0007 s/batch\n",
      "Epoch: 3/4.. Loss: 0.5991.. Test accuracy: 0.0186.. 0.0007 s/batch\n",
      "Epoch: 3/4.. Loss: 0.6465.. Test accuracy: 0.0261.. 0.0012 s/batch\n",
      "Epoch: 3/4.. Loss: 0.4582.. Test accuracy: 0.0229.. 0.0010 s/batch\n",
      "Epoch: 3/4.. Loss: 0.4416.. Test accuracy: 0.0253.. 0.0006 s/batch\n",
      "Epoch: 3/4.. Loss: 0.3533.. Test accuracy: 0.0373.. 0.0005 s/batch\n",
      "Epoch: 3/4.. Loss: 0.6727.. Test accuracy: 0.0257.. 0.0008 s/batch\n",
      "Epoch: 3/4.. Loss: 0.2665.. Test accuracy: 0.0117.. 0.0009 s/batch\n",
      "Epoch: 3/4.. Loss: 0.3212.. Test accuracy: 0.0298.. 0.0012 s/batch\n",
      "Epoch: 4/4.. Loss: 0.2284.. Test accuracy: 0.0187.. 0.0010 s/batch\n",
      "Epoch: 4/4.. Loss: 0.4673.. Test accuracy: 0.0337.. 0.0009 s/batch\n",
      "Epoch: 4/4.. Loss: 0.2999.. Test accuracy: 0.0249.. 0.0010 s/batch\n",
      "Epoch: 4/4.. Loss: 0.4667.. Test accuracy: 0.0327.. 0.0007 s/batch\n",
      "Epoch: 4/4.. Loss: 0.6645.. Test accuracy: 0.0173.. 0.0010 s/batch\n",
      "Epoch: 4/4.. Loss: 0.8666.. Test accuracy: 0.0057.. 0.0007 s/batch\n",
      "Epoch: 4/4.. Loss: 0.4620.. Test accuracy: 0.0224.. 0.0005 s/batch\n",
      "Epoch: 4/4.. Loss: 0.0263.. Test accuracy: 0.0354.. 0.0008 s/batch\n",
      "Epoch: 4/4.. Loss: 0.5161.. Test accuracy: 0.0215.. 0.0005 s/batch\n",
      "Epoch: 4/4.. Loss: 0.2200.. Test accuracy: 0.0226.. 0.0006 s/batch\n",
      "Epoch: 4/4.. Loss: 0.4691.. Test accuracy: 0.0175.. 0.0006 s/batch\n",
      "Epoch: 4/4.. Loss: 0.6734.. Test accuracy: 0.0502.. 0.0009 s/batch\n",
      "Epoch: 4/4.. Loss: 0.5861.. Test accuracy: 0.0123.. 0.0009 s/batch\n",
      "Epoch: 4/4.. Loss: 0.0463.. Test accuracy: 0.0195.. 0.0011 s/batch\n",
      "Epoch: 4/4.. Loss: 0.6952.. Test accuracy: 0.0272.. 0.0004 s/batch\n",
      "Epoch: 4/4.. Loss: 0.3155.. Test accuracy: 0.0368.. 0.0005 s/batch\n",
      "Epoch: 4/4.. Loss: 0.2328.. Test accuracy: 0.0203.. 0.0006 s/batch\n",
      "Epoch: 4/4.. Loss: 0.6369.. Test accuracy: 0.0173.. 0.0009 s/batch\n",
      "Epoch: 4/4.. Loss: 0.4425.. Test accuracy: 0.0194.. 0.0006 s/batch\n",
      "Epoch: 4/4.. Loss: 0.3514.. Test accuracy: 0.0221.. 0.0006 s/batch\n",
      "Epoch: 4/4.. Loss: 0.5241.. Test accuracy: 0.0334.. 0.0007 s/batch\n",
      "Epoch: 4/4.. Loss: 0.3587.. Test accuracy: 0.0188.. 0.0007 s/batch\n",
      "Epoch: 4/4.. Loss: 0.5666.. Test accuracy: 0.0192.. 0.0013 s/batch\n",
      "Epoch: 4/4.. Loss: 0.5074.. Test accuracy: 0.0288.. 0.0010 s/batch\n",
      "Epoch: 4/4.. Loss: 0.5325.. Test accuracy: 0.0219.. 0.0005 s/batch\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "epochs = 4\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 1\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Do not forget to transform the inputs and outputs into Variable        #\n",
    "        # which pytorch uses.                                                          #\n",
    "        ################################################################################\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        output = net.forward(inputs)\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        grad = loss.backward()\n",
    "        optimizer.step()\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                inputs = Variable(images)\n",
    "                targets = Variable(labels)\n",
    "                predicted = net.predict(inputs)\n",
    "                accuracy = criterion(predicted, targets)\n",
    "                accuracy = accuracy.data.numpy().tolist()[0]\n",
    "                \n",
    "                #inputs = Variable(images, volatile=True)\n",
    "                #predicted = net.predict(inputs)\n",
    "                #equality = (labels == predicted.max(1)[1])\n",
    "                #accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "                \n",
    "                \n",
    "                #im = Variable(images)\n",
    "                #out = net.predict(im)\n",
    "                #_,prediction = torch.max(out, 1)\n",
    "                #pred_y = prediction.data.numpy().squeeze()\n",
    "                #target_y = labels.numpy()\n",
    "                #accuracy = np.mean(predicted == inputs)\n",
    "                #print(pred_y.shape,target_y.shape)\n",
    "                \n",
    "                \n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}..\".format(accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch\".format((stop - start)/print_every)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-f70d5ca1a982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "np.float(accuracy)/(ii+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.0000  0.0000  0.0000  0.1820 -0.0069  0.0240 -0.0000  0.0000 -0.0000\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.0000 -0.0343  0.1202 -0.1133  0.3056 -0.0790  0.1854 -0.0069  0.0240\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -0.0484  1.6810  0.0544  1.7249  0.1391  1.4693 -0.1512  1.6371  0.1308\n",
       "\n",
       "Columns 9 to 17 \n",
       "   1.7453  0.2216  1.5895 -0.1762  1.6387  0.3993  1.6288  0.1376  1.4443\n",
       "\n",
       "(2 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -0.7916  1.1444 -0.5575  1.3200 -0.5190  1.2794 -0.6314  1.2192 -0.4451\n",
       "\n",
       "Columns 9 to 17 \n",
       "   1.3802 -0.5596  1.2410 -0.6553  1.2119 -0.5720  1.3678 -0.7510  1.1829\n",
       "\n",
       "(3 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.0968  0.5160  0.3793  0.6665  0.4730  0.6235  0.0015  0.6865 -0.0307\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.5145  0.2411  0.7433  0.3210  0.6266  0.0722  0.5206 -0.0323  0.6419\n",
       "\n",
       "(4 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 5x1x18]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eq received an invalid combination of arguments - got (Variable), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n * (torch.FloatTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-e42f0e93ca01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eq received an invalid combination of arguments - got (Variable), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n * (torch.FloatTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predicted == inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
